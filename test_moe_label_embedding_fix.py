#!/usr/bin/env python3
"""
æµ‹è¯•MOEæ¨¡å‹ä¸label embeddingçš„ä¿®å¤
"""

import sys
import os
import argparse
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.train_utils import create_model
from continual.label_embedding_manager import LabelEmbeddingManager

def test_moe_label_embedding_compat():
    """æµ‹è¯•MOEæ¨¡å‹ä¸label embeddingçš„å…¼å®¹æ€§"""
    print("å¼€å§‹æµ‹è¯•MOEæ¨¡å‹ä¸label embeddingçš„å…¼å®¹æ€§...")
    
    # æ„é€ å‚æ•°
    args = argparse.Namespace(
        text_model_name="microsoft/deberta-v3-base",
        image_model_name="google/vit-base-patch16-224-in21k",
        fusion_strategy="concat",
        num_heads=8,
        mode="text_only",
        task_name="masc",
        session_name="masc_1",
        num_labels=3,
        dropout_prob=0.1,
        moe_adapters=True,
        moe_num_experts=4,
        moe_top_k=2,
        use_label_embedding=True,
        label_emb_dim=128,
        use_similarity_reg=True,
        similarity_weight=0.1,
        pretrained_model_path=None,
        ddas=False,
        ddas_threshold=0.5,
        tam_cl=False,
        clap4clip=False,
    )

    device = "cpu"
    
    try:
        # åˆ›å»ºlabel embedding manager
        print("1. åˆ›å»ºLabelEmbeddingManager...")
        label_embedding_manager = LabelEmbeddingManager(
            emb_dim=args.label_emb_dim,
            use_similarity_regularization=args.use_similarity_reg,
            similarity_weight=args.similarity_weight
        )
        # åˆ›å»ºæˆ–åŠ è½½æ ‡ç­¾åµŒå…¥
        label_embedding_manager.create_or_load_embedding(device=device)
        print("   âœ“ LabelEmbeddingManageråˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ¨¡å‹
        print("2. åˆ›å»ºMOEæ¨¡å‹...")
        model = create_model(args, device, label_embedding_manager, logger=None)
        print("   âœ“ MOEæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥ä»»åŠ¡å¤´ç®¡ç†åŠŸèƒ½
        print("3. æ£€æŸ¥ä»»åŠ¡å¤´ç®¡ç†åŠŸèƒ½...")
        if hasattr(model, 'task_heads'):
            print(f"   âœ“ æ¨¡å‹æœ‰task_headså±æ€§ï¼ŒåŒ…å« {len(model.task_heads)} ä¸ªä»»åŠ¡å¤´")
        else:
            print("   âœ— æ¨¡å‹ç¼ºå°‘task_headså±æ€§")
            return False
        
        if hasattr(model, 'set_active_head'):
            print("   âœ“ æ¨¡å‹æœ‰set_active_headæ–¹æ³•")
        else:
            print("   âœ— æ¨¡å‹ç¼ºå°‘set_active_headæ–¹æ³•")
            return False
        
        # æµ‹è¯•è®¾ç½®æ´»åŠ¨å¤´
        print("4. æµ‹è¯•è®¾ç½®æ´»åŠ¨å¤´...")
        try:
            model.set_active_head(args.session_name)
            print("   âœ“ æˆåŠŸè®¾ç½®æ´»åŠ¨å¤´")
        except Exception as e:
            print(f"   âœ— è®¾ç½®æ´»åŠ¨å¤´å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥å½“å‰æ´»åŠ¨å¤´
        print("5. æ£€æŸ¥å½“å‰æ´»åŠ¨å¤´...")
        if hasattr(model, 'current_session'):
            print(f"   âœ“ å½“å‰æ´»åŠ¨å¤´: {model.current_session}")
        else:
            print("   âœ— æ¨¡å‹ç¼ºå°‘current_sessionå±æ€§")
            return False
        
        # æ£€æŸ¥MOEæ¨¡å‹æ˜¯å¦æœ‰fusion_output_dimå±æ€§
        print("6. æ£€æŸ¥MOEæ¨¡å‹å±æ€§...")
        if hasattr(model.base_model, 'fusion_output_dim'):
            print(f"   âœ“ MOEæ¨¡å‹æœ‰fusion_output_dimå±æ€§: {model.base_model.fusion_output_dim}")
        else:
            print("   âœ— MOEæ¨¡å‹ç¼ºå°‘fusion_output_dimå±æ€§")
            return False
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MOEæ¨¡å‹ä¸label embeddingå…¼å®¹æ€§è‰¯å¥½ã€‚")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=" * 60)
    print("MOEæ¨¡å‹ä¸Label Embeddingå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 60)
    
    success = test_moe_label_embedding_compat()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡ï¼MOEæ¨¡å‹ç°åœ¨å®Œå…¨æ”¯æŒlabel embeddingåŠŸèƒ½ã€‚")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
    print("=" * 60) 