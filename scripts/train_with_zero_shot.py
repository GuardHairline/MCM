#!/usr/bin/env python3
"""
æ”¯æŒ0æ ·æœ¬æ£€æµ‹çš„æŒç»­å­¦ä¹ è®­ç»ƒè„šæœ¬

ä½¿ç”¨ä»»åŠ¡é…ç½®æ–‡ä»¶è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥åœ¨è®­ç»ƒç¬¬iä¸ªä»»åŠ¡æ—¶å¯¹ç¬¬i+1ã€i+2ç­‰ä»»åŠ¡è¿›è¡Œ0æ ·æœ¬æ£€æµ‹ã€‚
"""

import json
import argparse
import sys
import torch
import torch.multiprocessing as mp
import glob
import os
from pathlib import Path
from typing import Dict, List, Any

# è®¾ç½®æ–‡ä»¶ç³»ç»Ÿå…±äº«ç­–ç•¥ï¼Œè§£å†³"Too many open files"é—®é¢˜
mp.set_sharing_strategy('file_system')

# å¯¼å…¥è®­ç»ƒæ¨¡å—
from modules.train_refactored import train
from modules.parser import create_train_parser, validate_args
from utils.logger import setup_logger


def load_task_config(config_file: str) -> Dict[str, Any]:
    """åŠ è½½ä»»åŠ¡é…ç½®æ–‡ä»¶"""
    with open(config_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def cleanup_experiment_files(config: Dict[str, Any], global_params: Dict[str, Any]):
    """
    æ¸…ç†æœ¬æ¬¡å®éªŒç”Ÿæˆçš„.ptæ–‡ä»¶
    
    åªåˆ é™¤å½“å‰å®éªŒçš„æ–‡ä»¶ï¼Œä¸å½±å“å…¶ä»–å®éªŒçš„æ–‡ä»¶
    æ ¹æ®é…ç½®æ–‡ä»¶åæ¥è¯†åˆ«ç›¸å…³æ–‡ä»¶
    
    Args:
        config: é…ç½®å­—å…¸
        global_params: å…¨å±€å‚æ•°å­—å…¸
    """
    try:
        save_checkpoints = global_params.get("save_checkpoints", False)
        if save_checkpoints:
            print("="*60)
            print("ğŸ§¹ æ¸…ç†å·²è·³è¿‡ï¼šsave_checkpoints=1ï¼Œä¿ç•™æ‰€æœ‰æ¨¡å‹æ–‡ä»¶")
            print("="*60 + "\n")
            return

        print("="*60)
        print("ğŸ§¹ å¼€å§‹æ¸…ç†å®éªŒæ–‡ä»¶...")
        print("="*60)
        
        # ä»global_paramsä¸­æå–æ–‡ä»¶åæ¨¡å¼
        # ä¾‹å¦‚: checkpoints/twitter2015_none_t2m_hp1.pt
        model_path = global_params.get("output_model_path", "")
        if not model_path:
            print("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹è·¯å¾„ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        # æå–base_name: twitter2015_none_t2m_hp1
        model_file = Path(model_path)
        base_name = model_file.stem  # ä¸å«.ptæ‰©å±•å
        checkpoint_dir = model_file.parent
        
        print(f"ğŸ“ è¯†åˆ«æ¨¡å¼: {base_name}")
        print(f"ğŸ“ æ£€æŸ¥ç›®å½•: {checkpoint_dir}")
        
        # éœ€è¦å¤„ç†çš„æ–‡ä»¶æ¨¡å¼
        patterns_to_handle = [
            f"{base_name}.pt",                      # ä¸»æ¨¡å‹æ–‡ä»¶
            f"{base_name}_*.pt",                    # å…¶ä»–ç›¸å…³æ¨¡å‹æ–‡ä»¶
            f"model_{base_name}*.pt",               # å¸¦modelå‰ç¼€çš„æ–‡ä»¶
            f"*{base_name}_task_heads.pt",          # ä»»åŠ¡å¤´æ–‡ä»¶
            f"label_embedding_{base_name}.pt",      # æ ‡ç­¾åµŒå…¥æ–‡ä»¶
        ]
        
        processed_count = 0
        
        # åœ¨checkpoint_dirä¸­æŸ¥æ‰¾å¹¶å¤„ç†åŒ¹é…çš„æ–‡ä»¶
        for pattern in patterns_to_handle:
            full_pattern = os.path.join(checkpoint_dir, pattern)
            matching_files = glob.glob(full_pattern)
            
            for file_path in matching_files:
                file_name = os.path.basename(file_path)
                # ç¡®ä¿base_nameåœ¨æ–‡ä»¶åä¸­ï¼ˆé¢å¤–å®‰å…¨æ£€æŸ¥ï¼‰
                if base_name in file_name:
                    try:
                        os.remove(file_path)
                        print(f"  âœ“ åˆ é™¤: {file_name}")
                        processed_count += 1
                    except Exception as del_err:
                        print(f"  âœ— åˆ é™¤å¤±è´¥: {file_name} ({del_err})")
        
        # æ¸…ç†EWCå‚æ•°
        ewc_dir = global_params.get("ewc_dir", "")
        if ewc_dir and os.path.exists(ewc_dir):
            ewc_pattern = os.path.join(ewc_dir, f"*{base_name}*.pt")
            for file_path in glob.glob(ewc_pattern):
                if base_name in os.path.basename(file_path):
                    try:
                        os.remove(file_path)
                        print(f"  âœ“ åˆ é™¤EWC: {os.path.basename(file_path)}")
                        processed_count += 1
                    except Exception as del_err:
                        print(f"  âœ— åˆ é™¤EWCå¤±è´¥: {os.path.basename(file_path)} ({del_err})")
        
        # æ¸…ç†GEMè®°å¿†
        gem_dir = global_params.get("gem_mem_dir", "")
        if gem_dir and os.path.exists(gem_dir):
            gem_pattern = os.path.join(gem_dir, f"*{base_name}*.pt")
            for file_path in glob.glob(gem_pattern):
                if base_name in os.path.basename(file_path):
                    try:
                        os.remove(file_path)
                        print(f"  âœ“ åˆ é™¤GEM: {os.path.basename(file_path)}")
                        processed_count += 1
                    except Exception as del_err:
                        print(f"  âœ— åˆ é™¤GEMå¤±è´¥: {os.path.basename(file_path)} ({del_err})")
        
        print(f"\nâœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {processed_count} ä¸ªæ–‡ä»¶")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"âŒ æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        print("="*60 + "\n")


def _build_args(task_config: Dict[str, Any], global_params: Dict[str, Any], pretrained_model_path: str) -> argparse.Namespace:
    """
    ä¾æ® parser å®šä¹‰æ„é€ å®Œæ•´ argsï¼šparseré»˜è®¤ -> global_params -> task_config
    """
    parser = create_train_parser()
    defaults = {action.dest: action.default for action in parser._actions if action.dest != "help"}
    args_dict = defaults.copy()

    def update_from(source: Dict[str, Any]):
        for k, v in source.items():
            if k in args_dict:
                args_dict[k] = v

    # å…¨å±€è¦†ç›–é»˜è®¤ï¼Œå†ç”±ä»»åŠ¡è¦†ç›–
    update_from(global_params)
    update_from(task_config)

    # å¿…å¡«/ç‰¹æ®Šå­—æ®µ
    args_dict["task_name"] = task_config["task_name"]
    args_dict["session_name"] = task_config["session_name"]
    args_dict["task_config_file"] = global_params.get("task_config_file", "")
    args_dict["train_info_json"] = global_params["train_info_json"]
    args_dict["output_model_path"] = task_config.get("output_model_path", global_params.get("output_model_path"))
    args_dict["pretrained_model_path"] = task_config.get("pretrained_model_path", pretrained_model_path)
    args_dict["data_dir"] = global_params.get("data_dir", args_dict.get("data_dir"))
    args_dict["dataset_name"] = global_params.get("dataset_name", args_dict.get("dataset_name"))
    args_dict["num_workers"] = global_params.get("num_workers", args_dict.get("num_workers", 4))

    # å…¼å®¹ç›®å½•/æè¿°å­—æ®µ
    if "gem_mem_dir" in global_params:
        args_dict["gem_mem_dir"] = global_params["gem_mem_dir"]
    if "ewc_dir" in global_params:
        args_dict["ewc_dir"] = global_params["ewc_dir"]
    if "description_file" in task_config:
        args_dict["description_file"] = task_config["description_file"]

    args = argparse.Namespace(**args_dict)
    validate_args(args)
    return args


def run_single_task(task_config: Dict[str, Any], global_params: Dict[str, Any], 
                   task_idx: int, total_tasks: int, pretrained_model_path: str = "", all_tasks: List[Dict[str, Any]] = []) -> str:
    """è¿è¡Œå•ä¸ªä»»åŠ¡"""
    
    print(f"Running task {task_idx + 1}/{total_tasks}: {task_config['task_name']} ({task_config['session_name']})")
    
    # æ„é€ å®Œæ•´å‚æ•°
    args = _build_args(task_config, global_params, pretrained_model_path)
    
    print(f"Task parameters:")
    print(f"  Task: {args.task_name}")
    print(f"  Session: {args.session_name}")
    print(f"  Epochs: {args.epochs}")
    print(f"  Batch size: {args.batch_size}")
    print(f"  Learning rate: {args.lr}")
    print(f"  Strategy: {task_config.get('strategy', 'none')}")
    if args.use_label_embedding:
        print(f"  Label embedding: enabled")
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(args=args)
    
    try:
        # ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°
        best_metrics = train(args, logger, all_tasks=all_tasks)
        print(f"Task {task_idx + 1} completed successfully")
        print(f"Best metrics: {best_metrics}")
        return args.output_model_path
    except Exception as e:
        print(f"Task {task_idx + 1} failed with error: {e}")
        raise


def main():
    parser = argparse.ArgumentParser(description="æŒç»­å­¦ä¹ è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒ0æ ·æœ¬æ£€æµ‹ï¼‰")
    parser.add_argument("--config", type=str, required=True, default="scripts/task_config.json",
                       help="ä»»åŠ¡é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--start_task", type=int, default=0,
                       help="å¼€å§‹ä»»åŠ¡ç´¢å¼•ï¼ˆ0-basedï¼‰")
    parser.add_argument("--end_task", type=int, default=8,
                       help="ç»“æŸä»»åŠ¡ç´¢å¼•ï¼ˆ0-basedï¼Œä¸åŒ…å«ï¼‰")
    
    args = parser.parse_args()
    
    # åŠ è½½ä»»åŠ¡é…ç½®
    print(f"Loading task configuration from: {args.config}")
    config = load_task_config(args.config)
    
    tasks = config["tasks"]
    global_params = config["global_params"]
    global_params["task_config_file"] = args.config  # æ·»åŠ é…ç½®æ–‡ä»¶è·¯å¾„
    
    global_params["kaggle_mode"] = config.get("kaggle_mode", global_params.get("kaggle_mode", False))
    
    # ç¡®å®šä»»åŠ¡èŒƒå›´
    start_idx = args.start_task
    end_idx = args.end_task if args.end_task is not None else len(tasks)
    # ç¡®ä¿end_idxä¸è¶…è¿‡å®é™…ä»»åŠ¡æ•°é‡
    end_idx = min(end_idx, len(tasks))
    
    print(f"Total tasks: {len(tasks)}")
    print(f"Running tasks: {start_idx + 1} to {end_idx} (requested: {args.end_task})")
    
    # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆå…¼å®¹ä¸åŒé…ç½®æ ¼å¼ï¼‰
    if "env" in config:
        print(f"Environment: {config['env']}")
    if "strategy" in config:
        print(f"Strategy: {config['strategy']}")
    if "mode_suffix" in config:
        print(f"Mode: {config['mode_suffix']}")
    if "dataset" in config:
        print(f"Dataset: {config['dataset']}")
    print(f"Label embedding: {'Yes' if config.get('use_label_embedding', False) else 'No'}")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    Path(global_params["train_info_json"]).parent.mkdir(parents=True, exist_ok=True)
    Path(global_params["output_model_path"]).parent.mkdir(parents=True, exist_ok=True)
    
    # æŒ‰é¡ºåºæ‰§è¡Œä»»åŠ¡
    pretrained_model_path = ""
    for i in range(start_idx, end_idx):
        task_config = tasks[i]
        
        # è¿è¡Œä»»åŠ¡
        model_path = run_single_task(task_config, global_params, i, len(tasks), pretrained_model_path, all_tasks=tasks)
        
        # æ›´æ–°é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        pretrained_model_path = model_path
        
        print(f"Completed task {i + 1}/{len(tasks)}: {task_config['task_name']}")
        print(f"Model saved to: {model_path}")
        print("-" * 50)
    
    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰ä»»åŠ¡è®­ç»ƒå®Œæˆï¼")
    print("="*80)
    print(f"Final model: {pretrained_model_path}")
    print(f"Training info: {global_params['train_info_json']}")
    
    # ========== è‡ªåŠ¨ç»˜åˆ¶çƒ­åŠ›å›¾ ==========
    try:
        print("\n" + "="*80)
        print("ğŸ“Š è‡ªåŠ¨ç»˜åˆ¶æŒç»­å­¦ä¹ çƒ­åŠ›å›¾")
        print("="*80)
        
        from utils.plot import plot_accuracy_matrix_from_train_info
        import json
        import os
        
        train_info_path = global_params['train_info_json']
        output_dir = os.path.dirname(train_info_path)
        
        if os.path.exists(train_info_path):
            # è¯»å–train_info
            with open(train_info_path, 'r', encoding='utf-8') as f:
                train_info = json.load(f)
            
            # ä»train_infoæ–‡ä»¶åæå–é…ç½®IDï¼ˆé¿å…ä¸åŒé…ç½®çš„å›¾ç‰‡äº’ç›¸è¦†ç›–ï¼‰
            train_info_basename = os.path.basename(train_info_path)  # e.g., train_info_kaggle_mate_twitter2015_config_default.json
            config_id = train_info_basename.replace('train_info_', '').replace('.json', '')  # e.g., kaggle_mate_twitter2015_config_default
            
            # ç»˜åˆ¶æ‰€æœ‰ä¸‰ç§æŒ‡æ ‡çš„çƒ­åŠ›å›¾
            print("\n1. ç»˜åˆ¶ Accuracy (Acc) çƒ­åŠ›å›¾...")
            if 'acc_matrix' in train_info and train_info['acc_matrix']:
                acc_save_path = os.path.join(output_dir, f'accuracy_heatmap_{config_id}.png')
                plot_accuracy_matrix_from_train_info(
                    train_info_path=train_info_path,
                    output_path=acc_save_path,
                    show_values=True,
                    metric='acc'
                )
                print(f"   âœ“ Accuracyçƒ­åŠ›å›¾: {acc_save_path}")
            else:
                print("   âš ï¸ acc_matrix ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            
            # ç»˜åˆ¶ Chunk F1 çƒ­åŠ›å›¾
            print("\n2. ç»˜åˆ¶ Chunk F1 (Span F1) çƒ­åŠ›å›¾...")
            if 'chunk_f1_matrix' in train_info and train_info['chunk_f1_matrix']:
                chunk_f1_save_path = os.path.join(output_dir, f'chunk_f1_heatmap_{config_id}.png')
                plot_accuracy_matrix_from_train_info(
                    train_info_path=train_info_path,
                    output_path=chunk_f1_save_path,
                    show_values=True,
                    metric='chunk_f1'
                )
                print(f"   âœ“ Chunk F1çƒ­åŠ›å›¾: {chunk_f1_save_path}")
            else:
                print("   âš ï¸ chunk_f1_matrix ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            
            # ç»˜åˆ¶ Token Micro F1 çƒ­åŠ›å›¾
            print("\n3. ç»˜åˆ¶ Token Micro F1 (no O) çƒ­åŠ›å›¾...")
            if 'token_micro_f1_no_o_matrix' in train_info and train_info['token_micro_f1_no_o_matrix']:
                token_f1_save_path = os.path.join(output_dir, f'token_micro_f1_heatmap_{config_id}.png')
                plot_accuracy_matrix_from_train_info(
                    train_info_path=train_info_path,
                    output_path=token_f1_save_path,
                    show_values=True,
                    metric='token_micro_f1_no_o'
                )
                print(f"   âœ“ Token Micro F1çƒ­åŠ›å›¾: {token_f1_save_path}")
            else:
                print("   âš ï¸ token_micro_f1_no_o_matrix ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            
            print("\nâœ… çƒ­åŠ›å›¾ç»˜åˆ¶å®Œæˆï¼")
        else:
            print(f"âš ï¸ train_infoæ–‡ä»¶ä¸å­˜åœ¨: {train_info_path}")
            
    except Exception as e:
        print(f"âš ï¸ ç»˜åˆ¶çƒ­åŠ›å›¾å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # ========== æ¸…ç†å®éªŒæ–‡ä»¶ ==========
    cleanup_experiment_files(config, global_params)


if __name__ == "__main__":
    main() 
