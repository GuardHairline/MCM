# Kaggle å…¨é‡å®éªŒéƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—ç”¨äºåœ¨ Kaggle ä¸Šè¿è¡Œ MCM é¡¹ç›®çš„ 60 ç»„å…¨é‡å¯¹æ¯”å®éªŒã€‚

## ç›®å½•ç»“æ„å‡†å¤‡

åœ¨æœ¬åœ°è¿è¡Œ `scripts/generate_kaggle_full_configs.py` åï¼Œä½ ä¼šå¾—åˆ° `scripts/configs/kaggle_full_experiment/` æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å« 60 ä¸ª JSON æ–‡ä»¶ã€‚

### 1. åˆ›å»º Config æ•°æ®é›†
ä½ éœ€è¦å°†è¿™äº›ç”Ÿæˆçš„ JSON æ–‡ä»¶ä¸Šä¼ åˆ° Kaggle ä½œä¸ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ã€‚
1. åœ¨ Kaggle ç‚¹å‡» "Create New Dataset"ã€‚
2. æ‹–å…¥ `scripts/configs/kaggle_full_experiment/` æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬ JSON å’Œ indexï¼‰ã€‚
3. å‘½åä¸º `mcm-full-configs`ã€‚

### 2. å‡†å¤‡ Notebook ç¯å¢ƒ

åˆ›å»ºä¸€ä¸ªæ–°çš„ Kaggle Notebookï¼Œå¹¶æ·»åŠ ä»¥ä¸‹**ä¸‰ä¸ª**æ•°æ®é›†ï¼š
1. **mcm-code**: åŒ…å«ä»£ç ï¼ˆmodules, scripts ç­‰ï¼‰ã€‚
2. **mcm-data**: åŒ…å« `data`, `downloaded_model`, `reference` æ–‡ä»¶å¤¹ã€‚
3. **mcm-full-configs**: åŒ…å«åˆšæ‰ç”Ÿæˆçš„ 60 ä¸ª JSON é…ç½®æ–‡ä»¶ã€‚

è®¾ç½® Accelerator ä¸º **GPU P100**ã€‚

## è¿è¡Œè„šæœ¬æ¨¡æ¿

å°†ä»¥ä¸‹ä»£ç å¤åˆ¶åˆ° Notebook çš„ç¬¬ä¸€ä¸ªå•å…ƒæ ¼ä¸­ã€‚è¿™æ®µä»£ç ä¼šè‡ªåŠ¨è®¾ç½®ç¯å¢ƒã€è¯»å–é…ç½®å¹¶è¿è¡ŒæŒ‡å®šçš„å®éªŒã€‚

**æ³¨æ„ä¿®æ”¹ `EXP_ID_START` å’Œ `EXP_ID_END` æ¥æ§åˆ¶æœ¬æ¬¡è¿è¡Œçš„ä»»åŠ¡ã€‚**

```python
# ==========================================
# MCM Kaggle Full Experiment Runner
# ==========================================

# >>> è®¾ç½®æœ¬æ¬¡è¿è¡Œçš„å®éªŒ ID èŒƒå›´ (0-59) <<<
# å»ºè®®ä¸€æ¬¡è¿è¡Œ 1-2 ä¸ªå®éªŒ (æ¯ä¸ªå®éªŒçº¦ 4-6 å°æ—¶)
EXP_ID_START = 0  
EXP_ID_END = 1    # è¿è¡ŒèŒƒå›´ [START, END)

# ==========================================

import os
import sys
import json
import shutil
import subprocess
import time
from pathlib import Path

print("="*80)
print("STAGE 1: Environment Setup")
print("="*80)

# å®šä¹‰è·¯å¾„
KAGGLE_INPUT = Path("/kaggle/input")
PROJECT_ROOT = Path("/MCM")
CONFIG_SRC = None
CODE_SRC = None
DATA_SRC = None

# 1. è‡ªåŠ¨å¯»æ‰¾èµ„æºç›®å½•
print("ğŸ” Searching for datasets...")
for d in KAGGLE_INPUT.iterdir():
    d_name = d.name.lower()
    # æ‰¾é…ç½®
    if "config" in d_name and (d / "experiment_index.json").exists():
        CONFIG_SRC = d
        print(f"  âœ“ Configs found: {d}")
    # æ‰¾ä»£ç 
    elif "code" in d_name and (d / "modules").exists():
        CODE_SRC = d
        print(f"  âœ“ Code found: {d}")
    # æ‰¾æ•°æ®
    elif "data" in d_name and (d / "downloaded_model").exists():
        DATA_SRC = d
        print(f"  âœ“ Data found: {d}")

if not all([CONFIG_SRC, CODE_SRC, DATA_SRC]):
    print("âŒ Error: Missing datasets. Please check inputs.")
    # Fallback logic if needed...

# 2. æ„å»ºè¿è¡Œç¯å¢ƒ /MCM
if not PROJECT_ROOT.exists():
    print(f"ğŸš€ Building project root at {PROJECT_ROOT}...")
    shutil.copytree(CODE_SRC, PROJECT_ROOT, dirs_exist_ok=True)
    
    # é“¾æ¥æ•°æ®æ–‡ä»¶
    print("ğŸ”— Linking data files...")
    for item in DATA_SRC.iterdir():
        if item.name.startswith("."): continue
        target = PROJECT_ROOT / item.name
        if not target.exists():
            if item.is_dir():
                try:
                    shutil.copytree(item, target)
                except:
                    os.symlink(item, target)
            else:
                shutil.copy2(item, target)

# 3. å®‰è£…ä¾èµ–
os.chdir(PROJECT_ROOT)
sys.path.insert(0, str(PROJECT_ROOT))
print("ğŸ“¦ Installing dependencies...")
os.system(f"{sys.executable} -m pip install -r requirements_kaggle.txt -q")

# ==========================================
# STAGE 2: Execution Loop
# ==========================================
print("\n" + "="*80)
print("STAGE 2: Running Experiments")
print("="*80)

# è¯»å–ç´¢å¼•
with open(CONFIG_SRC / "experiment_index.json") as f:
    index = json.load(f)

for exp in index:
    eid = exp['id']
    if eid < EXP_ID_START or eid >= EXP_ID_END:
        continue
        
    print(f"\nâ–¶ï¸  Running Exp ID {eid}: {exp['seq']} | {exp['dataset']} | {exp['strategy']}")
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶åˆ°å·¥ä½œç›®å½•
    config_file_name = exp['file']
    src_config = CONFIG_SRC / config_file_name
    local_config = PROJECT_ROOT / "current_task_config.json"
    shutil.copy2(src_config, local_config)
    
    # è¿è¡Œå‘½ä»¤
    start_time = time.time()
    cmd = [
        sys.executable, "-m", "scripts.train_with_zero_shot",
        "--config", str(local_config)
    ]
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path("/kaggle/working") / f"ID{eid}_{exp['seq']}_{exp['dataset']}_{exp['strategy']}"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    with open(log_dir / "run.log", "w") as log_file:
        proc = subprocess.run(
            cmd,
            cwd=str(PROJECT_ROOT),
            env={**os.environ, "PYTHONPATH": str(PROJECT_ROOT)},
            stdout=log_file,
            stderr=subprocess.STDOUT
        )
    
    status = "âœ… Success" if proc.returncode == 0 else "âŒ Failed"
    duration = (time.time() - start_time) / 60
    print(f"   Status: {status} (Time: {duration:.1f} min)")
    
    if proc.returncode != 0:
        print(f"   âš ï¸ Check logs at: {log_dir}/run.log")
        os.system(f"tail -n 20 {log_dir}/run.log")

# ==========================================
# STAGE 3: Pack Results
# ==========================================
print("\nğŸ“¦ Packing results...")
zip_name = f"results_ID{EXP_ID_START}_to_{EXP_ID_END}"
shutil.make_archive(f"/kaggle/working/{zip_name}", 'zip', root_dir="/kaggle/working")
print(f"âœ“ Done. Download {zip_name}.zip")