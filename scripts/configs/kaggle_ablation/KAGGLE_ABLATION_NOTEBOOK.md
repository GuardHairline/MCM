# CRF & Span Loss æ¶ˆèå®éªŒ - Kaggle Notebook

æœ¬æ–‡æ¡£æä¾›äº†åœ¨ Kaggle ä¸Šè¿è¡Œæ¶ˆèå®éªŒçš„å®Œæ•´ Notebook ä»£ç ã€‚

## ğŸ“‹ å®éªŒæ¦‚è¿°

**ç›®æ ‡**: å¯¹æ¯” 4 ç§é…ç½®åœ¨ MATEã€MNERã€MABSA ä»»åŠ¡ä¸Šçš„æ•ˆæœ
- **Baseline**: æ—  CRF å’Œ Span Loss
- **CRF Only**: ä»…å¯ç”¨ CRF
- **Span Only**: ä»…å¯ç”¨ Span Loss
- **Both**: åŒæ—¶å¯ç”¨ CRF å’Œ Span Loss

**è´¦å·åˆ†é…**:
- Account 1: MATE (Baseline + Both)
- Account 2: MATE (CRF Only + Span Only)
- Account 3: MNER (Baseline + Both)
- Account 4: MNER (CRF Only + Span Only)
- Account 5: MABSA (Baseline + Both)
- Account 6: MABSA (CRF Only + Span Only)

## ğŸš€ ä½¿ç”¨æ–¹æ³•

1. åœ¨ Kaggle åˆ›å»ºæ–° Notebook
2. å¤åˆ¶ä»¥ä¸‹æ‰€æœ‰ Cell ä»£ç 
3. **ä»…ä¿®æ”¹ Cell 1 ä¸­çš„è´¦å·ç¼–å·**
4. æ·»åŠ æ•°æ®é›†ï¼ˆmcm-code å’Œ mcm-dataï¼‰
5. å¯ç”¨ GPU (P100 æˆ– T4)
6. è¿è¡Œ "Run All"

---

## ğŸ“ Notebook Cells

### Cell 1: é…ç½®è´¦å·ç¼–å· âš™ï¸ ï¼ˆ**å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹**ï¼‰

```python
"""
âš ï¸âš ï¸âš ï¸ é‡è¦ï¼šè¿™æ˜¯å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ï¼âš ï¸âš ï¸âš ï¸

åœ¨ä¸åŒçš„ Kaggle è´¦å·ä¸Šè¿è¡Œæ—¶ï¼Œä¿®æ”¹ä¸‹é¢çš„ ACCOUNT_IDï¼š
- Account 1 â†’ ACCOUNT_ID = 1
- Account 2 â†’ ACCOUNT_ID = 2
- Account 3 â†’ ACCOUNT_ID = 3
- Account 4 â†’ ACCOUNT_ID = 4
- Account 5 â†’ ACCOUNT_ID = 5
- Account 6 â†’ ACCOUNT_ID = 6
"""

# ============ ä¿®æ”¹è¿™é‡Œï¼ ============
ACCOUNT_ID = 1  # ğŸ‘ˆ æ ¹æ®å½“å‰è´¦å·ä¿®æ”¹ä¸º 1-6
# ==================================

print("="*80)
print("CRF & Span Loss æ¶ˆèå®éªŒ")
print("="*80)
print(f"\nâœ… è´¦å·é…ç½®: Account {ACCOUNT_ID}")
print(f"ğŸ“‚ é…ç½®ç›®å½•: account_{ACCOUNT_ID}/")

# è´¦å·ä»»åŠ¡æ˜ å°„
ACCOUNT_TASKS = {
    1: ("MATE", ["baseline", "crf_and_span"]),
    2: ("MATE", ["crf_only", "span_only"]),
    3: ("MNER", ["baseline", "crf_and_span"]),
    4: ("MNER", ["crf_only", "span_only"]),
    5: ("MABSA", ["baseline", "crf_and_span"]),
    6: ("MABSA", ["crf_only", "span_only"]),
}

task_name, configs = ACCOUNT_TASKS[ACCOUNT_ID]
print(f"ğŸ“‹ ä»»åŠ¡: {task_name}")
print(f"ğŸ§ª å®éªŒé…ç½®: {', '.join(configs)}")
print(f"ğŸ“Š å®éªŒæ•°é‡: {len(configs)}")

print("\nâœ… é…ç½®å®Œæˆ")
```

---

### Cell 2: ç¯å¢ƒæ£€æŸ¥

```python
import os
import sys
import shutil
from pathlib import Path

print("="*80)
print("ç¯å¢ƒæ£€æŸ¥")
print("="*80)

# æ£€æŸ¥Kaggleç¯å¢ƒ
print("\nğŸ“¦ å¯ç”¨æ•°æ®é›†:")
for dataset in os.listdir("/kaggle/input"):
    print(f"  - {dataset}")

# è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
use_split_mode = False
code_path = None
data_path = None

# æ£€æµ‹åˆ†ç¦»æ¨¡å¼
if os.path.exists("/kaggle/input/mcm-code"):
    use_split_mode = True
    code_path = Path("/kaggle/input/mcm-code")
    print("\nâœ“ æ£€æµ‹åˆ°åˆ†ç¦»æ¨¡å¼")
    print(f"  ä»£ç è·¯å¾„: {code_path}")
  
    if os.path.exists("/kaggle/input/mcm-data"):
        data_path = Path("/kaggle/input/mcm-data")
        print(f"  æ•°æ®è·¯å¾„: {data_path}")
    else:
        print("  âš ï¸ æœªæ‰¾åˆ° mcm-dataï¼Œè¯·åœ¨Dataé¢æ¿æ·»åŠ ")

# æ£€æµ‹å®Œæ•´æ¨¡å¼
else:
    possible_paths = [
        Path("/kaggle/input/mcm-project/MCM"),
        Path("/kaggle/input/mcm-project"),
    ]
  
    for path in possible_paths:
        if path.exists() and (path / "scripts").exists():
            code_path = path
            print(f"\nâœ“ æ£€æµ‹åˆ°å®Œæ•´æ¨¡å¼")
            print(f"  é¡¹ç›®è·¯å¾„: {path}")
            break

if code_path is None:
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ°é¡¹ç›®ï¼è¯·æ£€æŸ¥æ•°æ®é›†é…ç½®")

# åˆ—å‡ºé¡¹ç›®å†…å®¹
print("\nğŸ“ é¡¹ç›®å†…å®¹ï¼ˆå‰10é¡¹ï¼‰:")
items = sorted(list(code_path.iterdir()))[:10]
for item in items:
    print(f"  - {item.name}{'/' if item.is_dir() else ''}")

print("\nâœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
```

---

### Cell 3: å¤åˆ¶é¡¹ç›®åˆ°å·¥ä½œç›®å½•

```python
# å¤åˆ¶é¡¹ç›®åˆ°å¯å†™ç›®å½•
work_project_path = Path("/MCM")

print("="*80)
print("å¤åˆ¶é¡¹ç›®åˆ°å·¥ä½œç›®å½•")
print("="*80)

if not work_project_path.exists():
    print(f"\nğŸ“‹ å¤åˆ¶ä»£ç ...")
    print(f"  æº: {code_path}")
    print(f"  ç›®æ ‡: {work_project_path}")
    shutil.copytree(code_path, work_project_path, dirs_exist_ok=True)
    print("âœ“ ä»£ç å¤åˆ¶å®Œæˆ")
else:
    print("âš ï¸ å·¥ä½œç›®å½•å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶")

# å¦‚æœæ˜¯åˆ†ç¦»æ¨¡å¼ï¼Œé“¾æ¥æ•°æ®ç›®å½•
if use_split_mode and data_path:
    print("\nğŸ“‹ é“¾æ¥æ•°æ®ç›®å½•ï¼ˆåˆ†ç¦»æ¨¡å¼ï¼‰...")
  
    target_data = work_project_path / "data"
    target_model = work_project_path / "downloaded_model"
  
    # é“¾æ¥data
    if not target_data.exists():
        source_data = data_path / "data" if (data_path / "data").exists() else data_path
        print(f"  data: {source_data} â†’ {target_data}")
        try:
            os.symlink(source_data, target_data)
            print("  âœ“ dataé“¾æ¥æˆåŠŸï¼ˆç¬¦å·é“¾æ¥ï¼‰")
        except:
            print("  âš ï¸ ç¬¦å·é“¾æ¥å¤±è´¥ï¼Œæ”¹ç”¨å¤åˆ¶...")
            shutil.copytree(source_data, target_data, dirs_exist_ok=True)
            print("  âœ“ dataå¤åˆ¶å®Œæˆ")
    else:
        print(f"  âœ“ dataç›®å½•å·²å­˜åœ¨")
  
    # é“¾æ¥æ¨¡å‹
    source_model = data_path / "downloaded_model"
    if source_model.exists() and not target_model.exists():
        print(f"  downloaded_model: {source_model} â†’ {target_model}")
        try:
            os.symlink(source_model, target_model)
            print("  âœ“ downloaded_modelé“¾æ¥æˆåŠŸï¼ˆç¬¦å·é“¾æ¥ï¼‰")
        except:
            shutil.copytree(source_model, target_model, dirs_exist_ok=True)
            print("  âœ“ downloaded_modelå¤åˆ¶å®Œæˆ")
    else:
        print(f"  âœ“ downloaded_modelç›®å½•å·²å­˜åœ¨")

# åˆ‡æ¢å·¥ä½œç›®å½•
os.chdir(work_project_path)
sys.path.insert(0, str(work_project_path))

print(f"\nğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"ğŸ Pythonè·¯å¾„: {sys.path[0]}")

# éªŒè¯æ•°æ®é›†
data_dir = work_project_path / "data"
print(f"\nğŸ“ æ•°æ®ç›®å½•: {data_dir}")
print(f"   å­˜åœ¨: {data_dir.exists()}")

if data_dir.exists():
    print("\nğŸ“¦ å¯ç”¨æ•°æ®é›†:")
    for item in sorted(data_dir.iterdir()):
        if item.is_dir():
            file_count = len(list(item.iterdir()))
            print(f"  - {item.name}/ ({file_count} files)")

# éªŒè¯é…ç½®ç›®å½•
config_dir = work_project_path / "scripts/configs/kaggle_ablation" / f"account_{ACCOUNT_ID}"
print(f"\nğŸ“‚ è´¦å·é…ç½®ç›®å½•: {config_dir}")
print(f"   å­˜åœ¨: {config_dir.exists()}")

if config_dir.exists():
    print("\nğŸ“„ é…ç½®æ–‡ä»¶:")
    for item in sorted(config_dir.iterdir()):
        if item.suffix == ".json":
            print(f"  - {item.name}")

print("\nâœ… é¡¹ç›®å‡†å¤‡å®Œæˆ")
```

---

### Cell 4: å®‰è£…ä¾èµ–

```python
import subprocess

print("="*80)
print("å®‰è£…ä¾èµ–")
print("="*80)

# æ£€æŸ¥ä¾èµ–æ–‡ä»¶
kaggle_req = work_project_path / "requirements_kaggle.txt"
regular_req = work_project_path / "requirements.txt"

print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–æ–‡ä»¶...")

if kaggle_req.exists():
    print("âœ“ æ‰¾åˆ° requirements_kaggle.txtï¼ˆKaggleä¼˜åŒ–ç‰ˆï¼‰")
    print("\nå®‰è£…Kaggleç‰¹å®šä¾èµ–...")
    !pip install -q -r {str(kaggle_req)}
    print("âœ“ ä¾èµ–å®‰è£…å®Œæˆ")
  
elif regular_req.exists():
    print("âœ“ æ‰¾åˆ° requirements.txtï¼ˆæ ‡å‡†ç‰ˆï¼‰")
    print("\nâš ï¸ å¯èƒ½æœ‰ç‰ˆæœ¬å†²çªè­¦å‘Šï¼ˆå¯ä»¥å¿½ç•¥ï¼‰")
    !pip install -q -r {str(regular_req)}
    print("\nâœ“ ä¾èµ–å®‰è£…å®Œæˆï¼ˆç‰ˆæœ¬å†²çªè­¦å‘Šå¯å¿½ç•¥ï¼‰")
  
else:
    print("âš ï¸ æœªæ‰¾åˆ°ä¾èµ–æ–‡ä»¶ï¼Œå®‰è£…æœ€å°ä¾èµ–é›†...")
    !pip install -q pytorch_crf sentencepiece protobuf==3.20.3
    print("âœ“ æœ€å°ä¾èµ–å®‰è£…å®Œæˆ")

# éªŒè¯å…³é”®åŒ…
print("\nğŸ” éªŒè¯å…³é”®ä¾èµ–...")
try:
    import torch
    print(f"  âœ“ torch: {torch.__version__}")
except:
    print("  âœ— torchå¯¼å…¥å¤±è´¥")

try:
    import transformers
    print(f"  âœ“ transformers: {transformers.__version__}")
except:
    print("  âœ— transformerså¯¼å…¥å¤±è´¥")

try:
    from torchcrf import CRF
    print(f"  âœ“ torchcrf: å¯ç”¨")
except:
    print("  âš ï¸ torchcrfä¸å¯ç”¨ï¼ˆå°†ä½¿ç”¨å†…ç½®SimpleCRFï¼‰")

print("\nğŸ’¡ è¯´æ˜:")
print("  â€¢ Kaggleå·²é¢„è£…å¤§éƒ¨åˆ†åŒ…")
print("  â€¢ ç‰ˆæœ¬å†²çªè­¦å‘Šé€šå¸¸å¯ä»¥å¿½ç•¥")
print("  â€¢ torchcrfä¸å¯ç”¨æ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨SimpleCRF")

print("\nâœ… ä¾èµ–æ£€æŸ¥å®Œæˆ")
```

---

### Cell 5: æ£€æŸ¥GPUå’ŒéªŒè¯ä¿®å¤

```python
import torch

print("="*80)
print("GPUä¿¡æ¯ & ä¿®å¤éªŒè¯")
print("="*80)

# GPUä¿¡æ¯
print("\nğŸ–¥ï¸ GPUçŠ¶æ€:")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
  
    print(f"  âœ“ GPU: {gpu_name}")
    print(f"  âœ“ æ€»æ˜¾å­˜: {gpu_memory:.1f} GB")
    print(f"  âœ“ CUDA: {torch.version.cuda}")
    print(f"  âœ“ PyTorch: {torch.__version__}")
else:
    print("  âŒ æœªæ£€æµ‹åˆ°GPU")
    print("  è¯·åœ¨Settings â†’ Acceleratorä¸­é€‰æ‹©GPU")

# éªŒè¯CRFå’ŒSpan Lossä¿®å¤
print("\nğŸ”§ éªŒè¯ä¿®å¤æ˜¯å¦å·²é›†æˆ:")

# 1. æ£€æŸ¥CRFæ˜¯å¦å¯ç”¨
try:
    from models.task_heads.mate_head import MATEHead
    head = MATEHead(768, 3, use_crf=True)
    if hasattr(head, 'crf') and head.crf is not None:
        print("  âœ“ CRFå±‚: å·²é›†æˆ")
        print(f"    ç±»å‹: {type(head.crf).__name__}")
    else:
        print("  âœ— CRFå±‚: æœªæ‰¾åˆ°")
except Exception as e:
    print(f"  âœ— CRFå±‚æ£€æŸ¥å¤±è´¥: {e}")

# 2. æ£€æŸ¥Span Loss
try:
    from utils.span_loss import SpanLoss
    span_loss = SpanLoss('mate')
    print("  âœ“ Span Loss: å·²é›†æˆ")
except Exception as e:
    print(f"  âœ— Span Lossæ£€æŸ¥å¤±è´¥: {e}")

# 3. æ£€æŸ¥è®­ç»ƒå¾ªç¯
try:
    with open(work_project_path / "modules/training_loop_fixed.py", "r") as f:
        content = f.read()
        if "span_loss" in content.lower():
            print("  âœ“ è®­ç»ƒå¾ªç¯: å·²é›†æˆSpan Loss")
        else:
            print("  âš ï¸ è®­ç»ƒå¾ªç¯: æœªæ‰¾åˆ°Span Loss")
except:
    print("  âš ï¸ æ— æ³•æ£€æŸ¥è®­ç»ƒå¾ªç¯")

print("\nâœ… ç³»ç»Ÿå‡†å¤‡å®Œæˆ")
```

---

### Cell 6: æ˜¾ç¤ºå®éªŒé…ç½®

```python
import json

print("="*80)
print(f"Account {ACCOUNT_ID} æ¶ˆèå®éªŒé…ç½®")
print("="*80)

# åŠ è½½ç´¢å¼•æ–‡ä»¶
index_file = work_project_path / "scripts/configs/kaggle_ablation" / f"account_{ACCOUNT_ID}" / f"account_{ACCOUNT_ID}_index.json"

if index_file.exists():
    with open(index_file) as f:
        index_data = json.load(f)
    
    # ä»ç¬¬ä¸€ä¸ªé…ç½®ä¸­è·å–æ•°æ®é›†åç§°
    dataset_name = index_data['configs'][0]['dataset'] if index_data['configs'] else 'twitter2015'
    
    print(f"\nğŸ“‹ å®éªŒä¿¡æ¯:")
    print(f"  è´¦å·: Account {index_data['account_id']}")
    print(f"  ä»»åŠ¡: {index_data['task'].upper()}")
    print(f"  æ•°æ®é›†: {dataset_name}")
    print(f"  é…ç½®æ•°é‡: {index_data['total_configs']}")
    
    print(f"\nğŸ§ª å®éªŒé…ç½®:")
    for i, cfg in enumerate(index_data['configs'], 1):
        print(f"\n  é…ç½® {i}/{index_data['total_configs']}:")
        print(f"    ç±»å‹: {cfg['ablation_type']}")
        print(f"    æ–‡ä»¶: {cfg['file']}")
        
        # è¯»å–é…ç½®è¯¦æƒ…
        cfg_file = work_project_path / "scripts/configs/kaggle_ablation" / f"account_{ACCOUNT_ID}" / cfg['file']
        if cfg_file.exists():
            with open(cfg_file) as f:
                cfg_data = json.load(f)
            
            # æ˜¾ç¤ºsessionæ•°é‡å’Œæ¨¡å¼åºåˆ—
            total_tasks = cfg_data.get('total_tasks', 1)
            mode_seq = cfg_data.get('mode_sequence', ['multimodal'])
            print(f"    Sessions: {total_tasks}")
            print(f"    æ¨¡å¼åºåˆ—: {' â†’ '.join(mode_seq)}")
            
            # æ˜¾ç¤ºCRFå’ŒSpan Lossé…ç½®ï¼ˆä»ç¬¬ä¸€ä¸ªtaskè·å–ï¼‰
            if cfg_data.get('tasks') and len(cfg_data['tasks']) > 0:
                first_task = cfg_data['tasks'][0]
                print(f"    CRF: {'âœ…' if first_task.get('use_crf', 0) else 'âŒ'}")
                print(f"    Span Loss: {'âœ…' if first_task.get('use_span_loss', 0) else 'âŒ'}")
    
    # æ—¶é—´ä¼°ç®— - æ¯ä¸ªé…ç½®åŒ…å«2ä¸ªsessions (text_only + multimodal)
    time_per_config = 3.5  # å°æ—¶ï¼ˆæ¯ä¸ªé…ç½®ï¼ŒåŒ…å«2ä¸ªsessionsï¼‰
    total_time = index_data['total_configs'] * time_per_config
    
    print(f"\nâ±ï¸ é¢„è®¡æ—¶é—´:")
    print(f"  æ¯ä¸ªé…ç½®: ~{time_per_config} å°æ—¶ (text_only + multimodal)")
    print(f"  æ€»è®¡: ~{total_time} å°æ—¶")
    print(f"  Kaggleé™åˆ¶: 12 å°æ—¶")
    
    if total_time > 12:
        print(f"  âš ï¸ é¢„è®¡æ—¶é—´å¯èƒ½è¶…è¿‡Kaggleé™åˆ¶")
    else:
        print(f"  âœ… é¢„è®¡åœ¨æ—¶é—´é™åˆ¶å†…")
    
else:
    print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
    raise FileNotFoundError(f"é…ç½®ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨")

print("\nâœ… é…ç½®æ£€æŸ¥å®Œæˆ")
```

---

### Cell 7: è¿è¡Œæ¶ˆèå®éªŒ ğŸš€

```python
import json
import subprocess
import time
from datetime import datetime

print("="*80)
print(f"å¼€å§‹è¿è¡Œ Account {ACCOUNT_ID} æ¶ˆèå®éªŒ")
print("="*80)
print()

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
output_dir = Path("/kaggle/working/checkpoints")
output_dir.mkdir(parents=True, exist_ok=True)

# åŠ è½½å®éªŒç´¢å¼•
index_file = work_project_path / "scripts/configs/kaggle_ablation" / f"account_{ACCOUNT_ID}" / f"account_{ACCOUNT_ID}_index.json"

with open(index_file) as f:
    index_data = json.load(f)

total_configs = index_data['total_configs']
task_name = index_data['task'].upper()  # æ‰€æœ‰é…ç½®éƒ½æ˜¯åŒä¸€ä¸ªä»»åŠ¡
print(f"ğŸ“Š æ€»é…ç½®æ•°: {total_configs}")
print(f"ğŸ“‹ ä»»åŠ¡: {task_name}")
print(f"ğŸ’¡ è¯´æ˜: æ¯ä¸ªé…ç½®åŒ…å« text_only å’Œ multimodal ä¸¤ä¸ªsession")
print()

# è¿è¡Œæ¯ä¸ªå®éªŒ
results = []
overall_start = time.time()

for i, cfg_info in enumerate(index_data['configs'], 1):
    config_name = cfg_info['ablation_type']  # baseline, crf_only, span_only, crf_and_span
    config_file = work_project_path / "scripts/configs/kaggle_ablation" / f"account_{ACCOUNT_ID}" / cfg_info['file']
    
    print("="*80)
    print(f"å®éªŒ [{i}/{total_configs}]: {task_name} - {config_name}")
    print("="*80)
    print(f"é…ç½®æ–‡ä»¶: {cfg_info['file']}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„åˆ°Kaggleè¾“å‡ºç›®å½•
    print("ğŸ“ æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„...")
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    # æ›´æ–°è¾“å‡ºè·¯å¾„
    original_output = config["global_params"]["output_model_path"]
    original_train_info = config["global_params"]["train_info_json"]
    
    config["global_params"]["output_model_path"] = f"/kaggle/working/checkpoints/{Path(original_output).name}"
    config["global_params"]["train_info_json"] = f"/kaggle/working/checkpoints/{Path(original_train_info).name}"
    
    # æ›´æ–°å…¶ä»–è·¯å¾„
    if "ewc_dir" in config["global_params"]:
        config["global_params"]["ewc_dir"] = "/kaggle/working/checkpoints/ewc"
    if "gem_mem_dir" in config["global_params"]:
        config["global_params"]["gem_mem_dir"] = "/kaggle/working/checkpoints/gem"
    
    # ä¿å­˜æ›´æ–°åçš„é…ç½®
    temp_config = Path("/kaggle/working") / f"temp_config_{config_name}.json"
    with open(temp_config, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"  âœ“ è¾“å‡ºè·¯å¾„æ›´æ–°åˆ°: /kaggle/working/checkpoints/")
    print()
    
    # è¿è¡Œå®éªŒ
    exp_start = time.time()
    
    # è¯»å–é…ç½®è·å–å®é™…ä»»åŠ¡æ•°
    with open(temp_config, 'r') as f:
        temp_cfg = json.load(f)
    total_tasks_in_config = temp_cfg.get('total_tasks', 2)
    
    cmd = [
        "python", "-m", "scripts.train_with_zero_shot",
        "--config", str(temp_config),
        "--start_task", "0",
        "--end_task", str(total_tasks_in_config)  # ä½¿ç”¨å®é™…ä»»åŠ¡æ•°
    ]
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    import os
    env = os.environ.copy()
    env['PYTHONPATH'] = str(work_project_path)
    
    try:
        print(f"ğŸš€ è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print(f"   å·¥ä½œç›®å½•: {work_project_path}")
        print(f"   PYTHONPATH: {env['PYTHONPATH']}")
        print()
        
        result = subprocess.run(cmd, check=True, capture_output=False, 
                               cwd=str(work_project_path), env=env)
        success = True
        print()
        print(f"âœ… {config_name} å®éªŒå®Œæˆ")
    except subprocess.CalledProcessError as e:
        success = False
        print()
        print(f"âŒ {config_name} å®éªŒå¤±è´¥: {e}")
    
    exp_time = time.time() - exp_start
    
    # éªŒè¯è¾“å‡ºæ–‡ä»¶
    output_files = list(output_dir.glob("**/*"))
    output_files = [f for f in output_files if f.is_file()]
    
    print(f"â±ï¸ è€—æ—¶: {exp_time/60:.1f} åˆ†é’Ÿ")
    print(f"ğŸ“ å½“å‰è¾“å‡ºæ–‡ä»¶æ•°: {len(output_files)}")
    
    # è®°å½•ç»“æœ
    results.append({
        "config": config_name,
        "file": cfg_info['file'],
        "success": success,
        "time_minutes": round(exp_time/60, 1),
        "output_files": len(output_files)
    })
    
    # ä¿å­˜è¿›åº¦
    progress_file = Path("/kaggle/working/ablation_progress.json")
    with open(progress_file, 'w') as f:
        json.dump({
            "account_id": ACCOUNT_ID,
            "completed": i,
            "total": total_configs,
            "results": results,
            "timestamp": datetime.now().isoformat()
        }, f, indent=2)
    
    print()

# æ€»ç»“
total_time = time.time() - overall_start
success_count = sum(1 for r in results if r['success'])

print("="*80)
print("ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
print("="*80)
print(f"\nğŸ“Š å®éªŒç»Ÿè®¡:")
print(f"  è´¦å·: Account {ACCOUNT_ID}")
print(f"  ä»»åŠ¡: {task_name}")
print(f"  æ€»å®éªŒæ•°: {total_configs}")
print(f"  æˆåŠŸ: {success_count}")
print(f"  å¤±è´¥: {total_configs - success_count}")
print(f"  æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")

print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
for r in results:
    status = "âœ…" if r['success'] else "âŒ"
    print(f"  {status} {r['config']}: {r['time_minutes']:.1f} åˆ†é’Ÿ")

print(f"\nğŸ’¾ ç»“æœä¿å­˜åœ¨: /kaggle/working/checkpoints/")
print(f"ğŸ“ è¿›åº¦æ–‡ä»¶: /kaggle/working/ablation_progress.json")

print("\nâœ… å®éªŒå®Œæˆ")
```

---

### Cell 8: æ‰“åŒ…ç»“æœï¼ˆä¸è¿›è¡Œåˆ†æï¼‰

```python
import shutil
from pathlib import Path
from datetime import datetime

print("="*80)
print("æ‰“åŒ…å®éªŒç»“æœ")
print("="*80)

output_dir = Path("/kaggle/working/checkpoints")
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_zip = Path(f"/kaggle/working/account_{ACCOUNT_ID}_results_{timestamp}.zip")

if output_dir.exists():
    # ç»Ÿè®¡æ–‡ä»¶
    all_files = list(output_dir.rglob("*"))
    files = [f for f in all_files if f.is_file()]
    train_info_files = [f for f in files if "train_info" in f.name and f.suffix == ".json"]
    model_files = [f for f in files if f.suffix == ".pt"]
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  æ€»æ–‡ä»¶æ•°: {len(files)}")
    print(f"  train_info: {len(train_info_files)}")
    print(f"  æ¨¡å‹æ–‡ä»¶: {len(model_files)}")
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in files) / (1024 * 1024)
    print(f"  æ€»å¤§å°: {total_size:.1f} MB")
    
    print("\nğŸ“¦ æ­£åœ¨æ‰“åŒ…...")
    print(f"  æºç›®å½•: {output_dir}")
    print(f"  ç›®æ ‡æ–‡ä»¶: {output_zip.name}")
    
    # åˆ›å»ºå‹ç¼©åŒ…
    shutil.make_archive(
        str(output_zip.with_suffix('')),
        'zip',
        output_dir
    )
    
    if output_zip.exists():
        zip_size = output_zip.stat().st_size / (1024 * 1024)
        print(f"\nâœ… ç»“æœå·²æ‰“åŒ…!")
        print(f"  æ–‡ä»¶: {output_zip.name}")
        print(f"  å¤§å°: {zip_size:.1f} MB")
        
        print(f"\nğŸ“¥ ä¸‹è½½æ–¹å¼:")
        print(f"  1. ç‚¹å‡»å³ä¾§ 'Output' æ ‡ç­¾")
        print(f"  2. æ‰¾åˆ° {output_zip.name}")
        print(f"  3. ç‚¹å‡»ä¸‹è½½æŒ‰é’®")
        
        print(f"\nğŸ’¡ æ–‡ä»¶å‘½åè¯´æ˜:")
        print(f"  account_{ACCOUNT_ID}_results_{timestamp}.zip")
        print(f"  â””â”€ è´¦å·{ACCOUNT_ID}çš„å®éªŒç»“æœ")
        print(f"     â””â”€ æ—¶é—´æˆ³: {timestamp}")
    else:
        print("âŒ æ‰“åŒ…å¤±è´¥")
else:
    print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæ— å†…å®¹å¯æ‰“åŒ…")

print("\n" + "="*80)
print("ğŸ“Œ åç»­æ­¥éª¤:")
print("="*80)
print(f"  1. âœ… ä¸‹è½½ account_{ACCOUNT_ID}_results_{timestamp}.zip")
print(f"  2. â¸ï¸ ç‚¹å‡»å³ä¸Šè§’ 'Stop Session' åœæ­¢Notebookï¼ˆèŠ‚çœGPUé…é¢ï¼‰")
print(f"  3. ğŸ”„ é‡å¤ä»¥ä¸Šæ­¥éª¤åœ¨å…¶ä»–è´¦å·ä¸Šè¿è¡Œ")
print(f"  4. ğŸ“Š æ‰€æœ‰è´¦å·å®Œæˆåï¼Œä½¿ç”¨æœ¬åœ°çš„ analyze_results.py åˆ†æ")
print("="*80)

print("\nğŸ’¡ åˆ†æè¯´æ˜:")
print("  â€¢ æœ¬æ¬¡è¿è¡Œä¸è¿›è¡Œæ€§èƒ½åˆ†æ")
print("  â€¢ ç­‰æ‰€æœ‰6ä¸ªè´¦å·éƒ½å®Œæˆå")
print("  â€¢ å°†æ‰€æœ‰ç»“æœzipæ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°")
print("  â€¢ è¿è¡Œ scripts/configs/kaggle_ablation/analyze_results.py è¿›è¡Œç»¼åˆåˆ†æ")

print("\nâœ… æ‰“åŒ…å®Œæˆ")
```

---

## ğŸ“Š åç»­åˆ†ææ­¥éª¤

å½“æ‰€æœ‰ 6 ä¸ªè´¦å·éƒ½å®Œæˆåï¼š

### 1. ä¸‹è½½æ‰€æœ‰ç»“æœ

å°† 6 ä¸ªè´¦å·çš„ç»“æœ zip æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°ï¼š
```
results/
  â”œâ”€â”€ account_1_results_YYYYMMDD_HHMMSS.zip
  â”œâ”€â”€ account_2_results_YYYYMMDD_HHMMSS.zip
  â”œâ”€â”€ account_3_results_YYYYMMDD_HHMMSS.zip
  â”œâ”€â”€ account_4_results_YYYYMMDD_HHMMSS.zip
  â”œâ”€â”€ account_5_results_YYYYMMDD_HHMMSS.zip
  â””â”€â”€ account_6_results_YYYYMMDD_HHMMSS.zip
```

### 2. è§£å‹æ‰€æœ‰æ–‡ä»¶

```bash
cd /path/to/MCM/results
for zip in account_*.zip; do
    unzip -q "$zip" -d "${zip%.zip}"
done
```

### 3. è¿è¡Œç»¼åˆåˆ†æ

```bash
cd /path/to/MCM
python scripts/configs/kaggle_ablation/analyze_results.py --results_dir ./results
```

è¿™å°†ç”Ÿæˆï¼š
- ğŸ“Š å¯¹æ¯”è¡¨æ ¼ï¼ˆå„ä»»åŠ¡åœ¨4ç§é…ç½®ä¸‹çš„æ€§èƒ½ï¼‰
- ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨ï¼ˆChunk F1, Token F1 ç­‰ï¼‰
- ğŸ“ è¯¦ç»†åˆ†ææŠ¥å‘Š

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### æ¯ä¸ªè´¦å·çš„ä¿®æ”¹

1. **ä»…ä¿®æ”¹ Cell 1 ä¸­çš„ `ACCOUNT_ID`**
2. **å…¶ä»– Cell å®Œå…¨ä¸éœ€è¦ä¿®æ”¹**

### æ—¶é—´ç®¡ç†

- æ¯ä¸ªå®éªŒçº¦ 2.5 å°æ—¶
- æ¯ä¸ªè´¦å· 2 ä¸ªå®éªŒ = çº¦ 5 å°æ—¶
- è¿œä½äº Kaggle 12 å°æ—¶é™åˆ¶ âœ…

### GPU é…é¢

- ä½¿ç”¨ P100 æˆ– T4
- å®éªŒå®Œæˆåç«‹å³åœæ­¢ Session
- èŠ‚çœ GPU é…é¢

### æ•°æ®é›†

ç¡®ä¿æ·»åŠ ä»¥ä¸‹æ•°æ®é›†åˆ° Notebookï¼š
- `mcm-code` (ä»£ç )
- `mcm-data` (æ•°æ®å’Œæ¨¡å‹)

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### è¿è¡Œå‰
- [ ] åœ¨ 6 ä¸ªè´¦å·ä¸Šåˆ†åˆ«åˆ›å»º Notebook
- [ ] æ¯ä¸ª Notebook ä¿®æ”¹æ­£ç¡®çš„ `ACCOUNT_ID`
- [ ] æ·»åŠ  `mcm-code` å’Œ `mcm-data` æ•°æ®é›†
- [ ] å¯ç”¨ GPU (P100 æˆ– T4)
- [ ] å¯ç”¨ Internet

### è¿è¡Œä¸­
- [ ] Cell 1: è´¦å·é…ç½®æ­£ç¡®
- [ ] Cell 2: ç¯å¢ƒæ£€æŸ¥é€šè¿‡
- [ ] Cell 3: é¡¹ç›®å¤åˆ¶æˆåŠŸ
- [ ] Cell 4: ä¾èµ–å®‰è£…å®Œæˆ
- [ ] Cell 5: GPU å’Œä¿®å¤éªŒè¯é€šè¿‡
- [ ] Cell 6: é…ç½®æ˜¾ç¤ºæ­£ç¡®
- [ ] Cell 7: å®éªŒè¿è¡Œå®Œæˆ
- [ ] Cell 8: ç»“æœæ‰“åŒ…æˆåŠŸ

### è¿è¡Œå
- [ ] ä¸‹è½½å¯¹åº”è´¦å·çš„ç»“æœ zip
- [ ] åœæ­¢ Session
- [ ] æ‰€æœ‰ 6 ä¸ªè´¦å·å®Œæˆåè¿›è¡Œç»¼åˆåˆ†æ

---

Good luck with your ablation study! ğŸš€

