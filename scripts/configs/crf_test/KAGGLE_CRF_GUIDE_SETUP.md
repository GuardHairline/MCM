# CRFä¿®å¤æµ‹è¯• - Kaggleå®Œæ•´éƒ¨ç½²æŒ‡å—

## ğŸ“Œ æµ‹è¯•ç›®æ ‡

éªŒè¯ä¸‰ä¸ªå…³é”®ä¿®å¤åœ¨åºåˆ—æ ‡æ³¨ä»»åŠ¡ä¸Šçš„æ•ˆæœï¼š

1. **CRFå±‚** - å¼ºåˆ¶BIOçº¦æŸ
2. **valid_lenä¿®å¤** - è¾¹ç•Œå‡†ç¡®æ€§
3. **Span Loss** - è¾¹ç•Œå¼ºåŒ–

**æµ‹è¯•ä»»åŠ¡**ï¼šMATEã€MNERã€MABSAï¼ˆå„1ä¸ªå®éªŒï¼Œå…±3ä¸ªï¼‰

**é¢„æœŸæ”¹è¿›**ï¼šChunk F1ä»30%æå‡åˆ°60-75%

---

## ğŸ”§ æ­¥éª¤1ï¼šæœ¬åœ°å‡†å¤‡

### 1.1 ç”Ÿæˆæµ‹è¯•é…ç½®

```bash
cd /path/to/MCM

# ç”Ÿæˆæœ¬åœ°æµ‹è¯•é…ç½®
python scripts/generate_crf_test_configs.py

# ç”ŸæˆKaggleæµ‹è¯•é…ç½®
python scripts/generate_crf_test_configs.py --kaggle
```

ç”Ÿæˆçš„æ–‡ä»¶ï¼š

- âœ… `scripts/configs/crf_test/crf_test_twitter2015_*.json` - é…ç½®æ–‡ä»¶
- âœ… `scripts/configs/crf_test/test_index.json` - ç´¢å¼•
- âœ… `scripts/configs/crf_test/run_crf_tests.sh` - æœ¬åœ°è¿è¡Œè„šæœ¬

### 1.2 æ‰“åŒ…é¡¹ç›®

**é€‰æ‹©æ¨¡å¼**ï¼š

**æ¨¡å¼Aï¼šå®Œæ•´æ¨¡å¼**ï¼ˆé¦–æ¬¡æ¨èï¼‰

```bash
# ä½¿ç”¨ç°æœ‰çš„æ‰“åŒ…è„šæœ¬
bash scripts/configs/kaggle_hyperparam_search/prepare_for_kaggle.sh
# ç”Ÿæˆ MCM_kaggle.zip
```

**æ¨¡å¼Bï¼šåˆ†ç¦»æ¨¡å¼**ï¼ˆæ¨èï¼Œä»£ç æ›´æ–°å¿«ï¼‰

```bash
# 1. æ‰“åŒ…æ•°æ®ï¼ˆä¸€æ¬¡æ€§ï¼‰
bash scripts/configs/kaggle_hyperparam_search/prepare_data_only.sh
# ç”Ÿæˆ MCM_data.zip

# 2. æ‰“åŒ…ä»£ç 
bash scripts/configs/kaggle_hyperparam_search/prepare_code_only.sh
# ç”Ÿæˆ MCM_code.zip
```

---

## ğŸ“¦ æ­¥éª¤2ï¼šä¸Šä¼ åˆ°Kaggle

### å®Œæ•´æ¨¡å¼

1. ä¸Šä¼  `MCM_kaggle.zip` åˆ°Kaggle Datasets
2. å‘½åä¸º `mcm-project`

### åˆ†ç¦»æ¨¡å¼ï¼ˆæ¨èï¼‰

1. ä¸Šä¼  `MCM_data.zip` â†’ å‘½åä¸º `mcm-data`
2. ä¸Šä¼  `MCM_code.zip` â†’ å‘½åä¸º `mcm-code`

è¯¦ç»†æ­¥éª¤å‚è€ƒï¼š`scripts/configs/kaggle_hyperparam_search/KAGGLE_SETUP_GUIDE.md`

---

## ğŸ““ æ­¥éª¤3ï¼šåˆ›å»ºKaggle Notebook

### 3.1 æ–°å»ºNotebook

1. è®¿é—® [https://www.kaggle.com/code](https://www.kaggle.com/code)
2. ç‚¹å‡» **"New Notebook"**
3. æ ‡é¢˜ï¼š`CRF Fix Test - MATE MNER MABSA`

### 3.2 é…ç½®Notebook

**Accelerator**: GPU P100 æˆ– T4**Internet**: å¼€å¯**Data**:

- å®Œæ•´æ¨¡å¼ï¼šæ·»åŠ  `mcm-project`
- åˆ†ç¦»æ¨¡å¼ï¼šæ·»åŠ  `mcm-code` å’Œ `mcm-data`

### 3.3 Notebookä»£ç 

#### Cell 1: ç¯å¢ƒæ£€æŸ¥ï¼ˆè‡ªåŠ¨æ£€æµ‹æ¨¡å¼ï¼‰

```python
import os
import sys
import shutil
from pathlib import Path

print("="*80)
print("CRFä¿®å¤æµ‹è¯• - ç¯å¢ƒæ£€æŸ¥")
print("="*80)

# æ£€æŸ¥Kaggleç¯å¢ƒ
print("\nğŸ“¦ å¯ç”¨æ•°æ®é›†:")
for dataset in os.listdir("/kaggle/input"):
    print(f"  - {dataset}")

# è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
use_split_mode = False
code_path = None
data_path = None

# æ£€æµ‹åˆ†ç¦»æ¨¡å¼
if os.path.exists("/kaggle/input/mcm-code"):
    use_split_mode = True
    code_path = Path("/kaggle/input/mcm-code")
    print("\nâœ“ æ£€æµ‹åˆ°åˆ†ç¦»æ¨¡å¼")
    print(f"  ä»£ç è·¯å¾„: {code_path}")
  
    if os.path.exists("/kaggle/input/mcm-data"):
        data_path = Path("/kaggle/input/mcm-data")
        print(f"  æ•°æ®è·¯å¾„: {data_path}")
    else:
        print("  âš ï¸ æœªæ‰¾åˆ° mcm-dataï¼Œè¯·åœ¨Dataé¢æ¿æ·»åŠ ")

# æ£€æµ‹å®Œæ•´æ¨¡å¼
else:
    possible_paths = [
        Path("/kaggle/input/mcm-project/MCM"),
        Path("/kaggle/input/mcm-project"),
    ]
  
    for path in possible_paths:
        if path.exists() and (path / "scripts").exists():
            code_path = path
            print(f"\nâœ“ æ£€æµ‹åˆ°å®Œæ•´æ¨¡å¼")
            print(f"  é¡¹ç›®è·¯å¾„: {path}")
            break

if code_path is None:
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ°é¡¹ç›®ï¼è¯·æ£€æŸ¥æ•°æ®é›†é…ç½®")

# åˆ—å‡ºé¡¹ç›®å†…å®¹
print("\nğŸ“ é¡¹ç›®å†…å®¹ï¼ˆå‰10é¡¹ï¼‰:")
items = sorted(list(code_path.iterdir()))[:10]
for item in items:
    print(f"  - {item.name}{'/' if item.is_dir() else ''}")

print("\nâœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
```

#### Cell 2: å¤åˆ¶é¡¹ç›®åˆ°å·¥ä½œç›®å½•

```python
# å¤åˆ¶é¡¹ç›®åˆ°å¯å†™ç›®å½•
work_project_path = Path("/MCM")

print("="*80)
print("å¤åˆ¶é¡¹ç›®åˆ°å·¥ä½œç›®å½•")
print("="*80)

if not work_project_path.exists():
    print(f"\nğŸ“‹ å¤åˆ¶ä»£ç ...")
    print(f"  æº: {code_path}")
    print(f"  ç›®æ ‡: {work_project_path}")
    shutil.copytree(code_path, work_project_path, dirs_exist_ok=True)
    print("âœ“ ä»£ç å¤åˆ¶å®Œæˆ")
else:
    print("âš ï¸ å·¥ä½œç›®å½•å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶")

# å¦‚æœæ˜¯åˆ†ç¦»æ¨¡å¼ï¼Œé“¾æ¥æ•°æ®ç›®å½•
if use_split_mode and data_path:
    print("\nğŸ“‹ é“¾æ¥æ•°æ®ç›®å½•ï¼ˆåˆ†ç¦»æ¨¡å¼ï¼‰...")
  
    target_data = work_project_path / "data"
    target_model = work_project_path / "downloaded_model"
  
    # é“¾æ¥data
    if not target_data.exists():
        source_data = data_path / "data" if (data_path / "data").exists() else data_path
        print(f"  data: {source_data} â†’ {target_data}")
        try:
            os.symlink(source_data, target_data)
            print("  âœ“ dataé“¾æ¥æˆåŠŸï¼ˆç¬¦å·é“¾æ¥ï¼‰")
        except:
            print("  âš ï¸ ç¬¦å·é“¾æ¥å¤±è´¥ï¼Œæ”¹ç”¨å¤åˆ¶...")
            shutil.copytree(source_data, target_data, dirs_exist_ok=True)
            print("  âœ“ dataå¤åˆ¶å®Œæˆ")
    else:
        print(f"  âœ“ dataç›®å½•å·²å­˜åœ¨")
  
    # é“¾æ¥æ¨¡å‹
    source_model = data_path / "downloaded_model"
    if source_model.exists() and not target_model.exists():
        print(f"  downloaded_model: {source_model} â†’ {target_model}")
        try:
            os.symlink(source_model, target_model)
            print("  âœ“ downloaded_modelé“¾æ¥æˆåŠŸï¼ˆç¬¦å·é“¾æ¥ï¼‰")
        except:
            shutil.copytree(source_model, target_model, dirs_exist_ok=True)
            print("  âœ“ downloaded_modelå¤åˆ¶å®Œæˆ")
    else:
        print(f"  âœ“ downloaded_modelç›®å½•å·²å­˜åœ¨")

# åˆ‡æ¢å·¥ä½œç›®å½•
os.chdir(work_project_path)
sys.path.insert(0, str(work_project_path))

print(f"\nğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"ğŸ Pythonè·¯å¾„: {sys.path[0]}")

# éªŒè¯æ•°æ®é›†
data_dir = work_project_path / "data"
print(f"\nğŸ“ æ•°æ®ç›®å½•: {data_dir}")
print(f"   å­˜åœ¨: {data_dir.exists()}")

if data_dir.exists():
    print("\nğŸ“¦ å¯ç”¨æ•°æ®é›†:")
    for item in sorted(data_dir.iterdir()):
        if item.is_dir():
            file_count = len(list(item.iterdir()))
            print(f"  - {item.name}/ ({file_count} files)")

print("\nâœ… é¡¹ç›®å‡†å¤‡å®Œæˆ")
```

#### Cell 3: å®‰è£…ä¾èµ–

```python
import subprocess

print("="*80)
print("å®‰è£…ä¾èµ–")
print("="*80)

# æ£€æŸ¥ä¾èµ–æ–‡ä»¶
kaggle_req = work_project_path / "requirements_kaggle.txt"
regular_req = work_project_path / "requirements.txt"

print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–æ–‡ä»¶...")

if kaggle_req.exists():
    print("âœ“ æ‰¾åˆ° requirements_kaggle.txtï¼ˆKaggleä¼˜åŒ–ç‰ˆï¼‰")
    print("\nå®‰è£…Kaggleç‰¹å®šä¾èµ–...")
    !pip install -q -r {str(kaggle_req)}
    print("âœ“ ä¾èµ–å®‰è£…å®Œæˆ")
  
elif regular_req.exists():
    print("âœ“ æ‰¾åˆ° requirements.txtï¼ˆæ ‡å‡†ç‰ˆï¼‰")
    print("\nâš ï¸ å¯èƒ½æœ‰ç‰ˆæœ¬å†²çªè­¦å‘Šï¼ˆå¯ä»¥å¿½ç•¥ï¼‰")
    !pip install -q -r {str(regular_req)}
    print("\nâœ“ ä¾èµ–å®‰è£…å®Œæˆï¼ˆç‰ˆæœ¬å†²çªè­¦å‘Šå¯å¿½ç•¥ï¼‰")
  
else:
    print("âš ï¸ æœªæ‰¾åˆ°ä¾èµ–æ–‡ä»¶ï¼Œå®‰è£…æœ€å°ä¾èµ–é›†...")
    !pip install -q pytorch_crf sentencepiece protobuf==3.20.3
    print("âœ“ æœ€å°ä¾èµ–å®‰è£…å®Œæˆ")

# éªŒè¯å…³é”®åŒ…
print("\nğŸ” éªŒè¯å…³é”®ä¾èµ–...")
try:
    import torch
    print(f"  âœ“ torch: {torch.__version__}")
except:
    print("  âœ— torchå¯¼å…¥å¤±è´¥")

try:
    import transformers
    print(f"  âœ“ transformers: {transformers.__version__}")
except:
    print("  âœ— transformerså¯¼å…¥å¤±è´¥")

try:
    from torchcrf import CRF
    print(f"  âœ“ torchcrf: å¯ç”¨")
except:
    print("  âš ï¸ torchcrfä¸å¯ç”¨ï¼ˆå°†ä½¿ç”¨å†…ç½®SimpleCRFï¼‰")

print("\nğŸ’¡ è¯´æ˜:")
print("  â€¢ Kaggleå·²é¢„è£…å¤§éƒ¨åˆ†åŒ…")
print("  â€¢ ç‰ˆæœ¬å†²çªè­¦å‘Šé€šå¸¸å¯ä»¥å¿½ç•¥")
print("  â€¢ torchcrfä¸å¯ç”¨æ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨SimpleCRF")

print("\nâœ… ä¾èµ–æ£€æŸ¥å®Œæˆ")
```

#### Cell 4: æ£€æŸ¥GPUå’Œæµ‹è¯•ä¿®å¤

```python
import torch

print("="*80)
print("GPUä¿¡æ¯ & ä¿®å¤éªŒè¯")
print("="*80)

# GPUä¿¡æ¯
print("\nğŸ–¥ï¸ GPUçŠ¶æ€:")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
  
    print(f"  âœ“ GPU: {gpu_name}")
    print(f"  âœ“ æ€»æ˜¾å­˜: {gpu_memory:.1f} GB")
    print(f"  âœ“ CUDA: {torch.version.cuda}")
    print(f"  âœ“ PyTorch: {torch.__version__}")
else:
    print("  âŒ æœªæ£€æµ‹åˆ°GPU")
    print("  è¯·åœ¨Settings â†’ Acceleratorä¸­é€‰æ‹©GPU")

# éªŒè¯CRFä¿®å¤
print("\nğŸ”§ éªŒè¯ä¿®å¤æ˜¯å¦å·²é›†æˆ:")

# 1. æ£€æŸ¥CRFæ˜¯å¦å¯ç”¨
try:
    from models.task_heads.mate_head import MATEHead
    head = MATEHead(768, 3, use_crf=True)
    if hasattr(head, 'crf') and head.crf is not None:
        print("  âœ“ CRFå±‚: å·²é›†æˆ")
        print(f"    ç±»å‹: {type(head.crf).__name__}")
    else:
        print("  âœ— CRFå±‚: æœªæ‰¾åˆ°")
except Exception as e:
    print(f"  âœ— CRFå±‚æ£€æŸ¥å¤±è´¥: {e}")

# 2. æ£€æŸ¥Span Loss
try:
    from utils.span_loss import SpanLoss
    span_loss = SpanLoss('mate')
    print("  âœ“ Span Loss: å·²é›†æˆ")
except Exception as e:
    print(f"  âœ— Span Lossæ£€æŸ¥å¤±è´¥: {e}")

# 3. æ£€æŸ¥è®­ç»ƒå¾ªç¯
try:
    with open(work_project_path / "modules/training_loop_fixed.py", "r") as f:
        content = f.read()
        if "span_loss" in content.lower():
            print("  âœ“ è®­ç»ƒå¾ªç¯: å·²é›†æˆSpan Loss")
        else:
            print("  âš ï¸ è®­ç»ƒå¾ªç¯: æœªæ‰¾åˆ°Span Loss")
except:
    print("  âš ï¸ æ— æ³•æ£€æŸ¥è®­ç»ƒå¾ªç¯")

print("\nâœ… ç³»ç»Ÿå‡†å¤‡å®Œæˆ")
```

#### Cell 5: é…ç½®æµ‹è¯•å‚æ•°

```python
print("="*80)
print("CRFä¿®å¤æµ‹è¯•é…ç½®")
print("="*80)

# æµ‹è¯•é…ç½®
TEST_TASKS = ["mate", "mner", "mabsa"]
DATASET = "twitter2015"

print("\nğŸ“‹ æµ‹è¯•ä»»åŠ¡:")
for i, task in enumerate(TEST_TASKS, 1):
    print(f"  {i}. {task.upper()}")

print(f"\nğŸ“Š æ•°æ®é›†: {DATASET}")
print(f"ğŸ“¦ æ€»æµ‹è¯•æ•°: {len(TEST_TASKS)}")

# æ—¶é—´ä¼°ç®—
time_per_test = 0.5  # å°æ—¶ï¼ˆCRFæµ‹è¯•è¾ƒå¿«ï¼Œå› ä¸ºåªæ˜¯éªŒè¯ï¼Œä¸æ˜¯å®Œæ•´è®­ç»ƒï¼‰
total_time = len(TEST_TASKS) * time_per_test

print(f"\nâ±ï¸ é¢„è®¡æ—¶é—´: {total_time:.1f} å°æ—¶")
print(f"   (æ¯ä¸ªæµ‹è¯•çº¦ {time_per_test} å°æ—¶)")

print("\nğŸ¯ æµ‹è¯•ç›®æ ‡:")
print("  éªŒè¯ä¿®å¤æ•ˆæœ:")
print("  1. CRFå±‚ â†’ å¼ºåˆ¶BIOçº¦æŸ")
print("  2. valid_lenä¿®å¤ â†’ è¾¹ç•Œå‡†ç¡®")
print("  3. Span Loss â†’ è¾¹ç•Œå¼ºåŒ–")

print("\nğŸ“ˆ é¢„æœŸæ”¹è¿›:")
print("  Chunk F1: 30% â†’ 60-75% (+30-45%)")

print("\nâœ… é…ç½®å®Œæˆ")
```

#### Cell 6: è¿è¡ŒCRFæµ‹è¯•

```python
import json
import subprocess
import time
from datetime import datetime

print("="*80)
print("å¼€å§‹è¿è¡ŒCRFä¿®å¤æµ‹è¯•")
print("="*80)
print()

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
output_dir = Path("/kaggle/working/checkpoints")
output_dir.mkdir(parents=True, exist_ok=True)

# åŠ è½½æµ‹è¯•ç´¢å¼•
index_file = work_project_path / "scripts/configs/crf_test/test_index.json"
if not index_file.exists():
    print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
    print("è¯·ç¡®ä¿é…ç½®æ–‡ä»¶å·²æ­£ç¡®ç”Ÿæˆ")
else:
    with open(index_file) as f:
        test_index = json.load(f)
  
    total_tests = test_index['total_configs']
    print(f"ğŸ“Š åŠ è½½æµ‹è¯•ç´¢å¼•: {total_tests} ä¸ªæµ‹è¯•")
    print()
  
    # è¿è¡Œæ¯ä¸ªæµ‹è¯•
    results = []
    overall_start = time.time()
  
    for i, config_info in enumerate(test_index['configs'], 1):
        task = config_info['task']
        config_file = work_project_path / "scripts/configs/crf_test" / config_info['file']
      
        print("="*80)
        print(f"æµ‹è¯• [{i}/{total_tests}]: {task.upper()}")
        print("="*80)
        print(f"é…ç½®: {config_info['file']}")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
      
        # æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„åˆ°Kaggleè¾“å‡ºç›®å½•
        print("ğŸ“ æ›´æ–°é…ç½®æ–‡ä»¶è·¯å¾„...")
        with open(config_file, 'r') as f:
            config = json.load(f)
      
        # æ›´æ–°è¾“å‡ºè·¯å¾„
        original_output = config["global_params"]["output_model_path"]
        original_train_info = config["global_params"]["train_info_json"]
      
        config["global_params"]["output_model_path"] = f"/kaggle/working/checkpoints/{Path(original_output).name}"
        config["global_params"]["train_info_json"] = f"/kaggle/working/checkpoints/{Path(original_train_info).name}"
      
        # æ›´æ–°å…¶ä»–è·¯å¾„
        if "ewc_dir" in config["global_params"]:
            config["global_params"]["ewc_dir"] = "/kaggle/working/checkpoints/ewc"
        if "gem_mem_dir" in config["global_params"]:
            config["global_params"]["gem_mem_dir"] = "/kaggle/working/checkpoints/gem"
      
        # ä¿å­˜æ›´æ–°åçš„é…ç½®
        temp_config = Path("/kaggle/working") / f"temp_config_{task}.json"
        with open(temp_config, 'w') as f:
            json.dump(config, f, indent=2)
      
        print(f"  âœ“ è¾“å‡ºè·¯å¾„æ›´æ–°åˆ°: /kaggle/working/checkpoints/")
        print()
      
        # è¿è¡Œæµ‹è¯•
        test_start = time.time()
        cmd = [
            "python", "-m", "scripts.train_with_zero_shot",
            "--config", str(temp_config)
        ]
      
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿Pythonèƒ½æ‰¾åˆ°æ¨¡å—
        import os
        env = os.environ.copy()
        env['PYTHONPATH'] = str(work_project_path)
      
        try:
            print(f"ğŸš€ è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
            print(f"   å·¥ä½œç›®å½•: {work_project_path}")
            print(f"   PYTHONPATH: {env['PYTHONPATH']}")
            print()
            # åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¹¶è®¾ç½®PYTHONPATH
            result = subprocess.run(cmd, check=True, capture_output=False, 
                                   cwd=str(work_project_path), env=env)
            success = True
            print()
            print(f"âœ… {task.upper()} æµ‹è¯•å®Œæˆ")
        except subprocess.CalledProcessError as e:
            success = False
            print()
            print(f"âŒ {task.upper()} æµ‹è¯•å¤±è´¥: {e}")
      
        test_time = time.time() - test_start
      
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        output_files = list(output_dir.glob("**/*"))
        output_files = [f for f in output_files if f.is_file()]
      
        print(f"â±ï¸ è€—æ—¶: {test_time/60:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶æ•°: {len(output_files)}")
      
        # è®°å½•ç»“æœ
        results.append({
            "task": task,
            "config": config_info['file'],
            "success": success,
            "time_minutes": round(test_time/60, 1),
            "output_files": len(output_files)
        })
      
        # ä¿å­˜è¿›åº¦
        progress_file = Path("/kaggle/working/crf_test_progress.json")
        with open(progress_file, 'w') as f:
            json.dump({
                "completed": i,
                "total": total_tests,
                "results": results,
                "timestamp": datetime.now().isoformat()
            }, f, indent=2)
      
        print()
  
    # æ€»ç»“
    total_time = time.time() - overall_start
    success_count = sum(1 for r in results if r['success'])
  
    print("="*80)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("="*80)
    print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
    print(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"  æˆåŠŸ: {success_count}")
    print(f"  å¤±è´¥: {total_tests - success_count}")
    print(f"  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
  
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for r in results:
        status = "âœ…" if r['success'] else "âŒ"
        print(f"  {status} {r['task'].upper()}: {r['time_minutes']:.1f} åˆ†é’Ÿ")
  
    print(f"\nğŸ’¾ ç»“æœä¿å­˜åœ¨: /kaggle/working/checkpoints/")
    print(f"ğŸ“ è¿›åº¦æ–‡ä»¶: /kaggle/working/crf_test_progress.json")
```

#### Cell 7: æ£€æŸ¥ç»“æœå’Œæ€§èƒ½å¯¹æ¯”

```python
import json
from pathlib import Path

print("="*80)
print("ç»“æœæ£€æŸ¥ & æ€§èƒ½å¯¹æ¯”")
print("="*80)

output_dir = Path("/kaggle/working/checkpoints")

if output_dir.exists():
    # ç»Ÿè®¡æ–‡ä»¶
    all_files = list(output_dir.rglob("*"))
    files = [f for f in all_files if f.is_file()]
    train_info_files = [f for f in files if "train_info" in f.name and f.suffix == ".json"]
    model_files = [f for f in files if f.suffix == ".pt"]
  
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  æ€»æ–‡ä»¶æ•°: {len(files)}")
    print(f"  train_info: {len(train_info_files)}")
    print(f"  æ¨¡å‹æ–‡ä»¶: {len(model_files)}")
  
    # åˆ†ææ€§èƒ½
    print(f"\nğŸ“Š æ€§èƒ½åˆ†æ:")
    print("-" * 80)
  
    for train_info in sorted(train_info_files):
        try:
            with open(train_info, 'r') as f:
                data = json.load(f)
          
            # æå–ä»»åŠ¡å
            task_name = "unknown"
            if "sessions" in data and len(data["sessions"]) > 0:
                task_name = data["sessions"][0].get("task_name", "unknown")
          
            print(f"\nğŸ” {task_name.upper()}")
          
            # æå–æŒ‡æ ‡
            if "sessions" in data and len(data["sessions"]) > 0:
                session = data["sessions"][0]
                details = session.get("details", {})
              
                # æœ€ç»ˆæŒ‡æ ‡
                final_dev = details.get("final_dev_metrics", {})
                final_test = details.get("final_test_metrics", {})
              
                if final_test:
                    print(f"  ğŸ“ˆ Test Set:")
                  
                    # æ˜¾ç¤ºä¸»æŒ‡æ ‡
                    if "chunk_f1" in final_test:
                        chunk_f1 = final_test["chunk_f1"]
                        print(f"    Chunk F1: {chunk_f1:.2f}% â­ (ä¸»æŒ‡æ ‡1)")
                  
                    if "token_micro_f1_no_o" in final_test:
                        token_f1 = final_test["token_micro_f1_no_o"]
                        print(f"    Token Micro F1 (æ— O): {token_f1:.2f}% (ä¸»æŒ‡æ ‡2)")
                  
                    if "token_acc" in final_test:
                        token_acc = final_test["token_acc"]
                        print(f"    Token Accuracy: {token_acc:.2f}% (å‚è€ƒ)")
                  
                    # è¾¹ç•Œæ£€æµ‹æŒ‡æ ‡
                    if "chunk_precision" in final_test:
                        print(f"    Chunk Precision: {final_test['chunk_precision']:.2f}%")
                    if "chunk_recall" in final_test:
                        print(f"    Chunk Recall: {final_test['chunk_recall']:.2f}%")
              
                # CRFä½¿ç”¨ä¿¡æ¯
                if "args" in session:
                    args = session["args"]
                    use_crf = args.get("use_crf", False)
                    use_span_loss = args.get("use_span_loss", False)
                    print(f"\n  ğŸ”§ ä¿®å¤å¯ç”¨çŠ¶æ€:")
                    print(f"    CRF: {'âœ… å·²å¯ç”¨' if use_crf else 'âŒ æœªå¯ç”¨'}")
                    print(f"    Span Loss: {'âœ… å·²å¯ç”¨' if use_span_loss else 'âŒ æœªå¯ç”¨'}")
      
        except Exception as e:
            print(f"  âš ï¸ è¯»å–å¤±è´¥: {e}")
  
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(f.stat().st_size for f in files) / (1024 * 1024)
    print(f"\nğŸ’¾ æ€»å¤§å°: {total_size:.1f} MB")
  
    print("\n" + "="*80)
    print("ğŸ’¡ å¯¹æ¯”è¯´æ˜:")
    print("="*80)
    print("  ä¿®å¤å‰ï¼ˆé¢„æœŸï¼‰:")
    print("    - Token Accuracy: ~90%")
    print("    - Chunk F1: ~30%")
    print("    - é—®é¢˜: tokenå‡†ç¡®ä½†è¾¹ç•Œè¯†åˆ«å¤±è´¥")
    print()
    print("  ä¿®å¤åï¼ˆç›®æ ‡ï¼‰:")
    print("    - Token Accuracy: ~90%")
    print("    - Chunk F1: 60-75% (+30-45%)")
    print("    - CRFå¼ºåˆ¶BIOçº¦æŸï¼Œspan losså¼ºåŒ–è¾¹ç•Œ")
    print("="*80)
  
else:
    print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨")

print("\nâœ… ç»“æœæ£€æŸ¥å®Œæˆ")
```

#### Cell 8: æ‰“åŒ…ç»“æœ

```python
import shutil
from pathlib import Path

print("="*80)
print("æ‰“åŒ…å®éªŒç»“æœ")
print("="*80)

output_dir = Path("/kaggle/working/checkpoints")
output_zip = Path("/kaggle/working/crf_test_results.zip")

if output_dir.exists():
    print("\nğŸ“¦ æ­£åœ¨æ‰“åŒ…...")
    print(f"  æºç›®å½•: {output_dir}")
    print(f"  ç›®æ ‡æ–‡ä»¶: {output_zip}")
  
    # åˆ›å»ºå‹ç¼©åŒ…
    shutil.make_archive(
        str(output_zip.with_suffix('')),
        'zip',
        output_dir
    )
  
    if output_zip.exists():
        zip_size = output_zip.stat().st_size / (1024 * 1024)
        print(f"\nâœ… ç»“æœå·²æ‰“åŒ…!")
        print(f"  æ–‡ä»¶: {output_zip.name}")
        print(f"  å¤§å°: {zip_size:.1f} MB")
        print(f"\nğŸ“¥ ä¸‹è½½æ–¹å¼:")
        print(f"  1. ç‚¹å‡»å³ä¾§ 'Output' æ ‡ç­¾")
        print(f"  2. æ‰¾åˆ° {output_zip.name}")
        print(f"  3. ç‚¹å‡»ä¸‹è½½æŒ‰é’®")
    else:
        print("âŒ æ‰“åŒ…å¤±è´¥")
else:
    print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæ— å†…å®¹å¯æ‰“åŒ…")

print("\n" + "="*80)
print("âš ï¸ ä¸ºèŠ‚çœGPUé…é¢ï¼Œè¯·å®Œæˆä»¥ä¸‹æ“ä½œ:")
print("="*80)
print("  1. ä¸‹è½½ crf_test_results.zip")
print("  2. ç‚¹å‡»å³ä¸Šè§’ 'Stop Session' åœæ­¢Notebook")
print("  3. æˆ–ç­‰å¾…è„šæœ¬è‡ªåŠ¨é€€å‡ºåæ‰‹åŠ¨åœæ­¢")
print("="*80)

print("\nâœ… æ‰“åŒ…å®Œæˆ")
```

---

## ğŸš€ æ­¥éª¤4ï¼šè¿è¡Œæµ‹è¯•

### 4.1 æ‰§è¡Œæ–¹å¼

ç‚¹å‡» **"Run All"** æˆ–é€ä¸ªè¿è¡ŒCell

### 4.2 ç›‘æ§è¿›åº¦

- è§‚å¯ŸCell 6çš„è¾“å‡º
- æŸ¥çœ‹ `/kaggle/working/crf_test_progress.json`

### 4.3 æ—¶é—´ä¼°ç®—

- æ¯ä¸ªæµ‹è¯•ï¼š~30åˆ†é’Ÿ
- æ€»è®¡ï¼š~1.5å°æ—¶ï¼ˆ3ä¸ªæµ‹è¯•ï¼‰

---

## ğŸ’¾ æ­¥éª¤5ï¼šåˆ†æç»“æœ

### 5.1 ä¸‹è½½ç»“æœ

1. ç¡®ä¿Cell 8å·²æ‰§è¡Œ
2. åœ¨ **Output** æ ‡ç­¾ä¸‹è½½ `crf_test_results.zip`

### 5.2 æœ¬åœ°åˆ†æ

```bash
# è§£å‹
unzip crf_test_results.zip -d ./crf_test_results

# æŸ¥çœ‹ç»“æœ
cat crf_test_results/train_info_*.json | jq '.sessions[0].details.final_test_metrics'
```

### 5.3 å¯¹æ¯”éªŒè¯

æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é¢„æœŸæ”¹è¿›ï¼š

- Chunk F1æå‡ +30-45%
- è¾¹ç•ŒPrecision/Recallæå‡
- CRFå’ŒSpan Lossæ˜¯å¦å¯ç”¨

---

## ğŸ“Š é¢„æœŸç»“æœ

### æˆåŠŸæ ‡å¿—

Cell 7åº”è¯¥æ˜¾ç¤ºç±»ä¼¼ï¼š

```
ğŸ“Š æ€§èƒ½åˆ†æ:
--------------------------------------------------------------------------------

ğŸ” MATE
  ğŸ“ˆ Test Set:
    Chunk F1: 65.34% â­ (ä¸»æŒ‡æ ‡1)          â† æå‡ï¼
    Token Micro F1 (æ— O): 88.23% (ä¸»æŒ‡æ ‡2)
    Token Accuracy: 90.12% (å‚è€ƒ)
    Chunk Precision: 67.45%
    Chunk Recall: 63.28%

  ğŸ”§ ä¿®å¤å¯ç”¨çŠ¶æ€:
    CRF: âœ… å·²å¯ç”¨
    Span Loss: âœ… å·²å¯ç”¨

ğŸ” MNER
  ğŸ“ˆ Test Set:
    Chunk F1: 72.56% â­ (ä¸»æŒ‡æ ‡1)          â† æå‡ï¼
    ...

ğŸ” MABSA
  ğŸ“ˆ Test Set:
    Chunk F1: 68.91% â­ (ä¸»æŒ‡æ ‡1)          â† æå‡ï¼
    ...
```

---

## âš ï¸ å¸¸è§é—®é¢˜

è¯¦ç»†é—®é¢˜è§£å†³å‚è€ƒï¼š`scripts/configs/kaggle_hyperparam_search/KAGGLE_SETUP_GUIDE.md`

### å¿«é€Ÿè§£å†³

1. **æ‰¾ä¸åˆ°é¡¹ç›®** â†’ æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²æ·»åŠ 
2. **CUDA out of memory** â†’ å‡å°batch_size
3. **ModuleNotFoundError** â†’ ç¡®è®¤Cell 2å·²æ‰§è¡Œ
4. **è¾“å‡ºæ–‡ä»¶ä¸ºç©º** â†’ æ£€æŸ¥è·¯å¾„æ˜¯å¦æ›´æ–°åˆ° `/kaggle/working/checkpoints`

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### è¿è¡Œå‰

- [ ] ç”Ÿæˆäº†æµ‹è¯•é…ç½®
- [ ] é¡¹ç›®å·²æ‰“åŒ…å¹¶ä¸Šä¼ 
- [ ] Notebookå·²é…ç½®GPU
- [ ] æ•°æ®é›†å·²æ·»åŠ åˆ°Notebook

### è¿è¡Œä¸­

- [ ] Cell 1: ç¯å¢ƒæ£€æŸ¥é€šè¿‡
- [ ] Cell 2: é¡¹ç›®å¤åˆ¶æˆåŠŸ
- [ ] Cell 3: ä¾èµ–å®‰è£…å®Œæˆ
- [ ] Cell 4: GPUå’Œä¿®å¤éªŒè¯é€šè¿‡
- [ ] Cell 6: æµ‹è¯•è¿è¡Œå®Œæˆ
- [ ] Cell 7: æ€§èƒ½å¯¹æ¯”æ˜¾ç¤ºæ”¹è¿›

### è¿è¡Œå

- [ ] Chunk F1æå‡30-45%
- [ ] ç»“æœå·²æ‰“åŒ…ä¸‹è½½
- [ ] Sessionå·²åœæ­¢ï¼ˆèŠ‚çœé…é¢ï¼‰

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- ğŸ“– è¯¦ç»†KaggleæŒ‡å—: `scripts/configs/kaggle_hyperparam_search/KAGGLE_SETUP_GUIDE.md`
- ğŸ”§ ä¿®å¤è¯¦æƒ…: `doc/FIXES_GUIDE.md`
- ğŸ“ å¿«é€Ÿå‚è€ƒ: `doc/FIXES_SUMMARY.md`

---

Good luck with testing! ğŸš€
