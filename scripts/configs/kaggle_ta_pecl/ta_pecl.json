{
    "experiment_name": "TA_PECL",
    "global_params": {
        "output_model_path": "/kaggle/working/output/ta_pecl/model.pt",
        "train_info_json": "/kaggle/working/output/ta_pecl/train_info.json",
        "output_root": "/kaggle/working/output/ta_pecl",
        "dataset_root": "/MCM/data",
        "log_file": "/kaggle/working/output/ta_pecl/TA_PECL.log",
        "save_checkpoints": 0,
        "ewc_dir": "/kaggle/working/output/ta_pecl/ewc",
        "gem_mem_dir": "/kaggle/working/output/ta_pecl/gem",
        "checkpoint_dir": "/kaggle/working/output/ta_pecl"
    },
    "tasks": [
        {
            "task_name": "masc",
            "session_name": "step1_masc_text_only",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "text_only",
            "num_labels": 3,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "masc",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mate",
            "session_name": "step2_mate_text_only",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "text_only",
            "num_labels": 3,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mate",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mner",
            "session_name": "step3_mner_text_only",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "text_only",
            "num_labels": 9,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MNER/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MNER/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MNER/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mner",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mabsa",
            "session_name": "step4_mabsa_text_only",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "text_only",
            "num_labels": 7,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mabsa",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "masc",
            "session_name": "step5_masc_multimodal",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "multimodal",
            "num_labels": 3,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "masc",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mate",
            "session_name": "step6_mate_multimodal",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "multimodal",
            "num_labels": 3,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mate",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mner",
            "session_name": "step7_mner_multimodal",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "multimodal",
            "num_labels": 9,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MNER/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MNER/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MNER/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mner",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        },
        {
            "task_name": "mabsa",
            "session_name": "step8_mabsa_multimodal",
            "dataset": "twitter2015",
            "env": "kaggle",
            "strategy": "ta_pecl",
            "mode": "multimodal",
            "num_labels": 7,
            "epochs": 20,
            "lr": 1e-05,
            "batch_size": 16,
            "step_size": 0,
            "gamma": 0.5,
            "weight_decay": 1e-05,
            "dropout_prob": 0.3,
            "patience": 5,
            "fusion_strategy": "concat",
            "num_heads": 8,
            "hidden_dim": 768,
            "text_model_name": "microsoft/deberta-v3-base",
            "image_model_name": "google/vit-base-patch16-224-in21k",
            "image_dir": "/MCM/data/img",
            "train_text_file": "/MCM/data/MASC/twitter2015/train.txt",
            "test_text_file": "/MCM/data/MASC/twitter2015/test.txt",
            "dev_text_file": "/MCM/data/MASC/twitter2015/dev.txt",
            "description_file": "reference/DEQA/DEQA/datasets/release/twitter2015/description_roberta.jsonl",
            "use_label_embedding": false,
            "use_hierarchical_head": false,
            "label_emb_dim": 128,
            "use_similarity_reg": false,
            "similarity_weight": 0.1,
            "triaffine": 0,
            "span_hidden": 256,
            "use_crf": 1,
            "use_span_loss": 0,
            "boundary_weight": 0.2,
            "span_f1_weight": 0.0,
            "transition_weight": 0.0,
            "graph_smooth": 0,
            "graph_tau": 0.5,
            "use_bilstm": 0,
            "bilstm_hidden_size": 256,
            "bilstm_num_layers": 2,
            "lstm_lr": 0.0001,
            "crf_lr": 0.001,
            "num_workers": 4,
            "head_key": "mabsa",
            "save_checkpoints": 0,
            "debug_samples": 100,
            "data_dir": "/MCM/data",
            "ta_pecl": 1,
            "ta_pecl_top_k": 4,
            "pretrained_model_path": "/kaggle/working/output/ta_pecl/model.pt",
            "output_model_path": "/kaggle/working/output/ta_pecl/model.pt"
        }
    ]
}