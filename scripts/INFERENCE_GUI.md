# å¤šæ¨¡æ€æ¨¡å‹æ¨ç†æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

`inference_complete.py` æ˜¯åŸºäºè®­ç»ƒæµç¨‹ï¼ˆ`train_with_zero_shot.py`ï¼‰è®¾è®¡çš„å®Œæ•´æ¨ç†æ¥å£ï¼Œæ”¯æŒæ‰€æœ‰è®­ç»ƒçš„ä»»åŠ¡ã€‚

### æ”¯æŒçš„ä»»åŠ¡

| ä»»åŠ¡ | ç±»å‹ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| **MATE** | åºåˆ—æ ‡æ³¨ | æ–‡æœ¬ + å›¾åƒ | æ–¹é¢æœ¯è¯­ä½ç½®å’Œæ–‡æœ¬ |
| **MNER** | åºåˆ—æ ‡æ³¨ | æ–‡æœ¬ + å›¾åƒ | å‘½åå®ä½“ï¼ˆPER/ORG/LOC/MISCï¼‰ |
| **MABSA** | åºåˆ—æ ‡æ³¨ | æ–‡æœ¬ + å›¾åƒ | æ–¹é¢æœ¯è¯­ + æƒ…æ„Ÿï¼ˆPOS/NEU/NEGï¼‰ |
| **MASC** | å¥å­åˆ†ç±» | æ–‡æœ¬ + æ–¹é¢è¯ + å›¾åƒ | æƒ…æ„Ÿï¼ˆ-1/0/1ï¼‰ |

---

## ğŸ—‚ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„æ–‡ä»¶

è®­ç»ƒè„šæœ¬ä¼šä¿å­˜ä»¥ä¸‹æ–‡ä»¶ï¼ˆä»¥`twitter2015_none_t2m_seq1`ä¸ºä¾‹ï¼‰ï¼š

```
checkpoints/
â”œâ”€â”€ twitter2015_none_t2m_seq1.pt                      # å®Œæ•´æ¨¡å‹ â­ å¿…éœ€
â”œâ”€â”€ twitter2015_none_t2m_seq1_task_heads.pt           # ä»»åŠ¡å¤´ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ train_info_twitter2015_none_t2m_seq1.json         # è®­ç»ƒä¿¡æ¯ â­ å¿…éœ€
â””â”€â”€ label_embedding_twitter2015_none_t2m_seq1.pt      # æ ‡ç­¾åµŒå…¥ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
```

### æ¨ç†éœ€è¦çš„æ–‡ä»¶

âœ… **å¿…éœ€ï¼š**
1. **æ¨¡å‹æ–‡ä»¶**ï¼š`{base_name}.pt`
2. **è®­ç»ƒä¿¡æ¯**ï¼š`train_info_{base_name}.json`

âŒ **å¯é€‰ï¼š**
- `{base_name}_task_heads.pt` - å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸­å·²åŒ…å«ä»»åŠ¡å¤´ï¼Œåˆ™ä¸éœ€è¦
- `label_embedding_{base_name}.pt` - æ¨ç†æ—¶ä¸éœ€è¦

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. MASCï¼ˆå¥å­çº§æƒ…æ„Ÿåˆ†ç±»ï¼‰

```bash
python scripts/inference_complete.py \
    --model_path checkpoints/twitter2015_none_t2m_seq1.pt \
    --train_info_path checkpoints/train_info_twitter2015_none_t2m_seq1.json \
    --task masc \
    --text "The $T$ is great but service sucks" \
    --aspect "food" \
    --image data/twitter2015/images/12345.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
é¢„æµ‹ç»“æœï¼ˆMASC - å¥å­çº§åˆ†ç±»ï¼‰
================================================================================
æ–‡æœ¬: The $T$ is great but service sucks
æ–¹é¢è¯: food
æƒ…æ„Ÿ: positive (1)
ç½®ä¿¡åº¦: 0.8923

æ¦‚ç‡åˆ†å¸ƒ:
  negative: 0.0512
  neutral: 0.0565
  positive: 0.8923
================================================================================
```

### 2. MATEï¼ˆæ–¹é¢æœ¯è¯­æå–ï¼‰

```bash
python scripts/inference_complete.py \
    --model_path checkpoints/twitter2015_none_t2m_seq1.pt \
    --train_info_path checkpoints/train_info_twitter2015_none_t2m_seq1.json \
    --task mate \
    --text "The food is great but service sucks" \
    --image data/twitter2015/images/12345.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
é¢„æµ‹ç»“æœï¼ˆMATE - åºåˆ—æ ‡æ³¨ï¼‰
================================================================================
æ–‡æœ¬: The food is great but service sucks

è¯†åˆ«çš„å®ä½“:
  [4:8] ENTITY: food
  [24:31] ENTITY: service

Tokençº§åˆ«é¢„æµ‹:
  The -> O
  food -> B
  is -> O
  great -> O
  but -> O
  service -> B
  sucks -> I
================================================================================
```

### 3. MNERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰

```bash
python scripts/inference_complete.py \
    --model_path checkpoints/twitter2015_none_t2m_seq1.pt \
    --train_info_path checkpoints/train_info_twitter2015_none_t2m_seq1.json \
    --task mner \
    --text "Barack Obama visited New York yesterday" \
    --image data/twitter2015/images/12345.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
é¢„æµ‹ç»“æœï¼ˆMNER - åºåˆ—æ ‡æ³¨ï¼‰
================================================================================
æ–‡æœ¬: Barack Obama visited New York yesterday

è¯†åˆ«çš„å®ä½“:
  [0:12] PER: Barack Obama
  [21:29] LOC: New York
================================================================================
```

### 4. MABSAï¼ˆæ–¹é¢æƒ…æ„Ÿåˆ†æï¼‰

```bash
python scripts/inference_complete.py \
    --model_path checkpoints/twitter2015_none_t2m_seq1.pt \
    --train_info_path checkpoints/train_info_twitter2015_none_t2m_seq1.json \
    --task mabsa \
    --text "The food is great but service sucks" \
    --image data/twitter2015/images/12345.jpg
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
================================================================================
é¢„æµ‹ç»“æœï¼ˆMABSA - åºåˆ—æ ‡æ³¨ï¼‰
================================================================================
æ–‡æœ¬: The food is great but service sucks

è¯†åˆ«çš„å®ä½“:
  [4:8] POS: food
  [24:31] NEG: service
================================================================================
```

---

## ğŸ“– Python APIä½¿ç”¨

### ç¤ºä¾‹1ï¼šMASCæƒ…æ„Ÿåˆ†ç±»

```python
from scripts.inference_complete import MultimodalInference

# åˆ›å»ºæ¨ç†å™¨
predictor = MultimodalInference(
    model_path="checkpoints/twitter2015_none_t2m_seq1.pt",
    train_info_path="checkpoints/train_info_twitter2015_none_t2m_seq1.json",
    task_name="masc",
    session_name="twitter2015_masc_multimodal"  # å¯é€‰ï¼Œè‡ªåŠ¨æ¨æ–­
)

# é¢„æµ‹
result = predictor.predict_sentence(
    text="The $T$ is amazing",
    aspect="food",
    image_path="data/twitter2015/images/12345.jpg"
)

print(f"æƒ…æ„Ÿ: {result['sentiment_name']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f}")
```

### ç¤ºä¾‹2ï¼šMATEå®ä½“æå–

```python
from scripts.inference_complete import MultimodalInference

# åˆ›å»ºæ¨ç†å™¨
predictor = MultimodalInference(
    model_path="checkpoints/twitter2015_none_t2m_seq1.pt",
    train_info_path="checkpoints/train_info_twitter2015_none_t2m_seq1.json",
    task_name="mate"
)

# é¢„æµ‹
result = predictor.predict_sequence(
    text="The food is great but service sucks",
    image_path="data/twitter2015/images/12345.jpg",
    return_tokens=True
)

# æ‰“å°å®ä½“
for start, end, label, text in result['entities']:
    print(f"{label}: {text} [{start}:{end}]")

# æ‰“å°tokençº§åˆ«é¢„æµ‹
for token, label in result['token_predictions']:
    print(f"{token} -> {label}")
```

### ç¤ºä¾‹3ï¼šæ‰¹é‡é¢„æµ‹

```python
from scripts.inference_complete import MultimodalInference
import json

# åˆ›å»ºæ¨ç†å™¨
predictor = MultimodalInference(
    model_path="checkpoints/twitter2015_none_t2m_seq1.pt",
    train_info_path="checkpoints/train_info_twitter2015_none_t2m_seq1.json",
    task_name="mate"
)

# æ‰¹é‡æ•°æ®
samples = [
    {"text": "The food is great", "image": "data/images/1.jpg"},
    {"text": "Nice restaurant", "image": "data/images/2.jpg"},
    # ... æ›´å¤šæ ·æœ¬
]

# æ‰¹é‡é¢„æµ‹
results = []
for sample in samples:
    result = predictor.predict_sequence(
        text=sample['text'],
        image_path=sample['image']
    )
    results.append(result)

# ä¿å­˜ç»“æœ
with open("predictions.json", 'w') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### 1. æŒ‡å®šä¼šè¯åç§°

å¦‚æœè®­ç»ƒä¿¡æ¯ä¸­æœ‰å¤šä¸ªä¼šè¯ï¼Œå¯ä»¥æŒ‡å®šï¼š

```python
predictor = MultimodalInference(
    model_path="checkpoints/model.pt",
    train_info_path="checkpoints/train_info.json",
    task_name="mate",
    session_name="twitter2015_mate_text_only"  # ä½¿ç”¨ç‰¹å®šä¼šè¯
)
```

### 2. ä½¿ç”¨CPUæ¨ç†

```python
predictor = MultimodalInference(
    model_path="checkpoints/model.pt",
    train_info_path="checkpoints/train_info.json",
    task_name="mate",
    device="cpu"  # å¼ºåˆ¶ä½¿ç”¨CPU
)
```

### 3. å¤„ç†æ— å›¾åƒæƒ…å†µ

å¦‚æœæ¨¡å‹æ˜¯text_onlyæ¨¡å¼è®­ç»ƒçš„ï¼š

```python
# æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†ï¼Œæä¾›ä»»æ„å›¾åƒè·¯å¾„æˆ–åˆ›å»ºé›¶å¼ é‡
result = predictor.predict_sequence(
    text="The food is great",
    image_path="data/dummy.jpg"  # å³ä½¿ä¸å­˜åœ¨ä¹Ÿä¼šè‡ªåŠ¨å¤„ç†
)
```

---

## ğŸ“ è¿”å›æ ¼å¼è¯¦è§£

### MASCè¿”å›æ ¼å¼

```python
{
    'text': str,                    # è¾“å…¥æ–‡æœ¬
    'aspect': str,                  # æ–¹é¢è¯
    'sentiment': int,               # -1(è´Ÿ), 0(ä¸­), 1(æ­£)
    'sentiment_name': str,          # 'negative', 'neutral', 'positive'
    'probabilities': {
        'negative': float,
        'neutral': float,
        'positive': float
    },
    'confidence': float             # æœ€é«˜æ¦‚ç‡
}
```

### åºåˆ—æ ‡æ³¨ä»»åŠ¡è¿”å›æ ¼å¼ï¼ˆMATE/MNER/MABSAï¼‰

```python
{
    'text': str,                    # è¾“å…¥æ–‡æœ¬
    'entities': [                   # è¯†åˆ«çš„å®ä½“åˆ—è¡¨
        (start_pos, end_pos, label, entity_text),
        ...
    ],
    'token_predictions': [          # Tokençº§åˆ«é¢„æµ‹ï¼ˆå¦‚æœreturn_tokens=Trueï¼‰
        (token, label),
        ...
    ]
}
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ¨¡å‹å’Œè®­ç»ƒä¿¡æ¯å¿…é¡»åŒ¹é…

ç¡®ä¿æ¨¡å‹æ–‡ä»¶å’Œè®­ç»ƒä¿¡æ¯æ–‡ä»¶æ¥è‡ªåŒä¸€æ¬¡è®­ç»ƒï¼š

```bash
# âœ… æ­£ç¡®ï¼šåŒä¸€ä¸ªbase_name
--model_path checkpoints/twitter2015_none_t2m_seq1.pt
--train_info_path checkpoints/train_info_twitter2015_none_t2m_seq1.json

# âŒ é”™è¯¯ï¼šä¸åŒçš„base_name
--model_path checkpoints/twitter2015_none_t2m_seq1.pt
--train_info_path checkpoints/train_info_twitter2017_moe_t2m_seq1.json
```

### 2. ä»»åŠ¡åç§°å¿…é¡»å­˜åœ¨äºè®­ç»ƒä¿¡æ¯ä¸­

```python
# æ£€æŸ¥å¯ç”¨çš„ä»»åŠ¡
with open("checkpoints/train_info.json") as f:
    info = json.load(f)
    print("Available sessions:")
    for session in info['sessions']:
        print(f"  - {session['task_name']} ({session['session_name']})")
```

### 3. CRFæ¨¡å‹çš„ç‰¹æ®Šå¤„ç†

ä½¿ç”¨CRFè®­ç»ƒçš„æ¨¡å‹ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨Viterbiè§£ç ï¼š

```python
# æ¨ç†å™¨ä¼šè‡ªåŠ¨æ£€æµ‹CRF
predictor = MultimodalInference(...)  # è‡ªåŠ¨å¤„ç†CRF

# è¾“å‡ºä¼šä½¿ç”¨CRFè§£ç è€Œä¸æ˜¯ç®€å•çš„argmax
result = predictor.predict_sequence(...)
```

### 4. å›¾åƒè·¯å¾„

- å›¾åƒæ–‡ä»¶å¿…é¡»å­˜åœ¨ä¸”å¯è¯»
- å¦‚æœå›¾åƒåŠ è½½å¤±è´¥ï¼Œä¼šä½¿ç”¨é›¶å¼ é‡ï¼ˆå¯èƒ½å½±å“æ€§èƒ½ï¼‰
- å¯¹äºtext_onlyæ¨¡å¼ï¼Œå›¾åƒè¾“å…¥ä¼šè¢«å¿½ç•¥

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°session

```
ValueError: Could not find session for task 'mate' in train_info
```

**è§£å†³æ–¹æ³•ï¼š**
```python
# æ‰‹åŠ¨æŒ‡å®šsession_name
predictor = MultimodalInference(
    ...,
    session_name="twitter2015_mate_multimodal"  # æ˜ç¡®æŒ‡å®š
)

# æˆ–æŸ¥çœ‹train_info.jsonä¸­çš„å¯ç”¨session
```

### é—®é¢˜2ï¼šç»´åº¦ä¸åŒ¹é…

```
RuntimeError: size mismatch
```

**å¯èƒ½åŸå› ï¼š**
- æ¨¡å‹å’Œä»»åŠ¡ä¸åŒ¹é…
- num_labelsè®¾ç½®é”™è¯¯

**è§£å†³æ–¹æ³•ï¼š**
æ£€æŸ¥train_info.jsonä¸­çš„num_labelsæ˜¯å¦æ­£ç¡®

### é—®é¢˜3ï¼šCRFè§£ç é”™è¯¯

```
ValueError: mask of the first timestep must all be on
```

**è§£å†³æ–¹æ³•ï¼š**
è¿™ä¸ªé”™è¯¯å·²åœ¨æ¨ç†å™¨ä¸­å¤„ç†ï¼Œå¦‚æœä»ç„¶å‡ºç°ï¼Œè¯·æŠ¥å‘Šissue

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡æ¨ç†

è™½ç„¶å½“å‰æ¥å£æ˜¯å•æ ·æœ¬çš„ï¼Œä½†å¯ä»¥å¾ªç¯è°ƒç”¨ï¼š

```python
import torch

predictor = MultimodalInference(...)

results = []
for sample in samples:
    with torch.no_grad():  # ç¡®ä¿ä¸è®¡ç®—æ¢¯åº¦
        result = predictor.predict_sequence(sample['text'], sample['image'])
        results.append(result)
```

### 2. ä½¿ç”¨GPU

```python
# è‡ªåŠ¨é€‰æ‹©GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
predictor = MultimodalInference(..., device=None)  # è‡ªåŠ¨é€‰æ‹©

# æˆ–æ˜¾å¼æŒ‡å®š
predictor = MultimodalInference(..., device='cuda:0')
```

### 3. åŠç²¾åº¦æ¨ç†

```python
# åˆ›å»ºæ¨ç†å™¨åè½¬æ¢ä¸ºhalf precision
predictor = MultimodalInference(...)
predictor.model = predictor.model.half()

# æ³¨æ„ï¼šè¾“å…¥ä¹Ÿéœ€è¦half
# è¿™ä¼šåŠ å¿«æ¨ç†ä½†å¯èƒ½ç•¥å¾®é™ä½ç²¾åº¦
```

---

## ğŸ¯ æ€»ç»“

- âœ… æ”¯æŒæ‰€æœ‰è®­ç»ƒçš„ä»»åŠ¡ï¼ˆMATE/MNER/MABSA/MASCï¼‰
- âœ… è‡ªåŠ¨ä»è®­ç»ƒä¿¡æ¯æ¨æ–­é…ç½®
- âœ… æ”¯æŒCRFæ¨¡å‹çš„æ­£ç¡®è§£ç 
- âœ… çµæ´»çš„APIï¼ˆå‘½ä»¤è¡Œå’ŒPythonï¼‰
- âœ… è¯¦ç»†çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

**æ¨èå·¥ä½œæµï¼š**
1. è®­ç»ƒæ¨¡å‹ â†’ ç”Ÿæˆ `.pt` å’Œ `train_info.json`
2. ä½¿ç”¨ `inference_complete.py` è¿›è¡Œæ¨ç†
3. æ ¹æ®éœ€è¦è°ƒç”¨Python APIè¿›è¡Œæ‰¹é‡å¤„ç†

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹ä»£ç ä¸­çš„docstringæˆ–æissueï¼

