# models/task_head_manager.py
"""
ç»Ÿä¸€çš„ä»»åŠ¡å¤´ç®¡ç†å™¨
è§£å†³é—®é¢˜ï¼š
1. é¢„åˆ›å»ºæ‰€æœ‰ä»»åŠ¡å¤´ï¼ˆåŒ…æ‹¬æœªæ¥ä»»åŠ¡ï¼‰
2. TAM-CLå’Œå…¶ä»–æ¨¡å‹é€»è¾‘ä¸ä¸€è‡´
3. headåˆ‡æ¢ç¼ºå°‘é”™è¯¯å¤„ç†
4. headçŠ¶æ€éªŒè¯ç¼ºå¤±
"""

import os
import torch
import torch.nn as nn
from typing import Dict, Optional, Any, List
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class TaskHeadInfo:
    """ä»»åŠ¡å¤´ä¿¡æ¯"""
    session_name: str
    task_name: str
    head: nn.Module
    args: Any
    created_at: str
    is_frozen: bool = False
    
    def freeze(self):
        """å†»ç»“ä»»åŠ¡å¤´å‚æ•°"""
        for param in self.head.parameters():
            param.requires_grad = False
        self.is_frozen = True
        
    def unfreeze(self):
        """è§£å†»ä»»åŠ¡å¤´å‚æ•°"""
        for param in self.head.parameters():
            param.requires_grad = True
        self.is_frozen = False


class TaskHeadManager:
    """
    ç»Ÿä¸€çš„ä»»åŠ¡å¤´ç®¡ç†å™¨
    
    ç‰¹æ€§ï¼š
    1. å»¶è¿Ÿåˆ›å»ºï¼šåªåœ¨éœ€è¦æ—¶åˆ›å»ºhead
    2. çŠ¶æ€éªŒè¯ï¼šç¡®ä¿headæ­£ç¡®åˆ‡æ¢
    3. ç»Ÿä¸€æ¥å£ï¼šæ”¯æŒæ‰€æœ‰æ¨¡å‹ç±»å‹
    4. é”™è¯¯å¤„ç†ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    """
    
    def __init__(self, base_model, label_embedding_manager=None, device='cuda'):
        self.base_model = base_model
        self.label_embedding_manager = label_embedding_manager
        self.device = device
        
        # å­˜å‚¨æ‰€æœ‰ä»»åŠ¡å¤´
        self._task_heads: Dict[str, TaskHeadInfo] = {}
        
        # å½“å‰æ´»åŠ¨çš„ä»»åŠ¡å¤´
        self._current_session: Optional[str] = None
        self._current_head: Optional[nn.Module] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._head_usage_count: Dict[str, int] = {}
        
    def register_head(self, session_name: str, task_name: str, 
                     head: nn.Module, args: Any, freeze: bool = False) -> bool:
        """
        æ³¨å†Œä¸€ä¸ªä»»åŠ¡å¤´
        
        Args:
            session_name: ä¼šè¯åç§°ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
            task_name: ä»»åŠ¡åç§°
            head: ä»»åŠ¡å¤´æ¨¡å—
            args: ä»»åŠ¡å‚æ•°
            freeze: æ˜¯å¦ç«‹å³å†»ç»“
            
        Returns:
            æ˜¯å¦æ³¨å†ŒæˆåŠŸ
        """
        if session_name in self._task_heads:
            logger.warning(f"Session '{session_name}' already registered, skipping")
            return False
        
        # ç¡®ä¿headåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        head = head.to(self.device)
        
        # åˆ›å»ºå¤´ä¿¡æ¯
        import time
        head_info = TaskHeadInfo(
            session_name=session_name,
            task_name=task_name,
            head=head,
            args=args,
            created_at=time.strftime("%Y-%m-%d %H:%M:%S"),
            is_frozen=freeze
        )
        
        if freeze:
            head_info.freeze()
        
        self._task_heads[session_name] = head_info
        self._head_usage_count[session_name] = 0
        
        logger.info(f"Registered task head: {session_name} ({task_name}), frozen={freeze}")
        return True
    
    def create_and_register_head(self, session_name: str, task_name: str, 
                                args: Any, use_label_embedding: bool = False) -> Optional[nn.Module]:
        """
        åˆ›å»ºå¹¶æ³¨å†Œä»»åŠ¡å¤´ï¼ˆå»¶è¿Ÿåˆ›å»ºæ¨¡å¼ï¼‰
        
        Args:
            session_name: ä¼šè¯åç§°
            task_name: ä»»åŠ¡åç§°
            args: ä»»åŠ¡å‚æ•°
            use_label_embedding: æ˜¯å¦ä½¿ç”¨æ ‡ç­¾åµŒå…¥
            
        Returns:
            åˆ›å»ºçš„ä»»åŠ¡å¤´ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if session_name in self._task_heads:
            logger.info(f"Task head '{session_name}' already exists, reusing")
            return self._task_heads[session_name].head
        
        try:
            # é€‰æ‹©åˆé€‚çš„headåˆ›å»ºå‡½æ•°
            if use_label_embedding:
                from models.task_heads.get_head_new import get_head
            else:
                from models.task_heads.get_head import get_head
            
            # è·å–æ ‡ç­¾åµŒå…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
            label_emb = None
            if self.label_embedding_manager and use_label_embedding:
                label_emb = self.label_embedding_manager.get_embedding()
            
            # åˆ›å»ºhead
            head = get_head(task_name, self.base_model, args, label_emb=label_emb)
            
            # æ³¨å†Œ
            self.register_head(session_name, task_name, head, args)
            
            return head
            
        except Exception as e:
            logger.error(f"Failed to create head for '{session_name}': {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def set_active_head(self, session_name: str, strict: bool = True) -> bool:
        """
        è®¾ç½®æ´»åŠ¨ä»»åŠ¡å¤´
        
        Args:
            session_name: ä¼šè¯åç§°
            strict: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆæ‰¾ä¸åˆ°headæ—¶æŠ¥é”™ï¼‰
            
        Returns:
            æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        if session_name not in self._task_heads:
            msg = f"Session '{session_name}' not found in registered heads: {list(self._task_heads.keys())}"
            if strict:
                raise ValueError(msg)
            else:
                logger.warning(msg)
                return False
        
        # åˆ‡æ¢head
        head_info = self._task_heads[session_name]
        self._current_session = session_name
        self._current_head = head_info.head
        
        # æ›´æ–°ä½¿ç”¨è®¡æ•°
        self._head_usage_count[session_name] += 1
        
        logger.debug(f"Switched to head: {session_name} ({head_info.task_name})")
        return True
    
    def get_current_head(self) -> Optional[nn.Module]:
        """è·å–å½“å‰æ´»åŠ¨çš„ä»»åŠ¡å¤´"""
        return self._current_head
    
    def get_current_session(self) -> Optional[str]:
        """è·å–å½“å‰æ´»åŠ¨çš„ä¼šè¯åç§°"""
        return self._current_session
    
    def get_head(self, session_name: str) -> Optional[nn.Module]:
        """è·å–æŒ‡å®šä¼šè¯çš„ä»»åŠ¡å¤´"""
        if session_name not in self._task_heads:
            return None
        return self._task_heads[session_name].head
    
    def get_task_name(self, session_name: str) -> Optional[str]:
        """è·å–æŒ‡å®šä¼šè¯çš„ä»»åŠ¡åç§°"""
        if session_name not in self._task_heads:
            return None
        return self._task_heads[session_name].task_name
    
    def has_head(self, session_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒ‡å®šä¼šè¯çš„ä»»åŠ¡å¤´"""
        return session_name in self._task_heads
    
    def remove_head(self, session_name: str) -> bool:
        """
        ç§»é™¤æŒ‡å®šçš„ä»»åŠ¡å¤´
        
        Args:
            session_name: ä¼šè¯åç§°
            
        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        if session_name not in self._task_heads:
            logger.warning(f"Cannot remove non-existent head: {session_name}")
            return False
        
        # å¦‚æœæ­£åœ¨ä½¿ç”¨è¿™ä¸ªheadï¼Œæ¸…é™¤å½“å‰çŠ¶æ€
        if self._current_session == session_name:
            self._current_session = None
            self._current_head = None
        
        # åˆ é™¤head
        del self._task_heads[session_name]
        if session_name in self._head_usage_count:
            del self._head_usage_count[session_name]
        
        logger.info(f"Removed task head: {session_name}")
        return True
    
    def freeze_head(self, session_name: str) -> bool:
        """å†»ç»“æŒ‡å®šä»»åŠ¡å¤´"""
        if session_name not in self._task_heads:
            logger.warning(f"Cannot freeze non-existent head: {session_name}")
            return False
        
        self._task_heads[session_name].freeze()
        logger.info(f"Frozen task head: {session_name}")
        return True
    
    def freeze_all_except(self, session_name: str) -> int:
        """å†»ç»“é™¤æŒ‡å®šä¼šè¯å¤–çš„æ‰€æœ‰ä»»åŠ¡å¤´"""
        count = 0
        for sess_name in self._task_heads:
            if sess_name != session_name:
                if self.freeze_head(sess_name):
                    count += 1
        logger.info(f"Frozen {count} task heads (except {session_name})")
        return count
    
    def unfreeze_head(self, session_name: str) -> bool:
        """è§£å†»æŒ‡å®šä»»åŠ¡å¤´"""
        if session_name not in self._task_heads:
            logger.warning(f"Cannot unfreeze non-existent head: {session_name}")
            return False
        
        self._task_heads[session_name].unfreeze()
        logger.info(f"Unfrozen task head: {session_name}")
        return True
    
    def get_all_sessions(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²æ³¨å†Œä¼šè¯çš„åç§°"""
        return list(self._task_heads.keys())
    
    def get_head_count(self) -> int:
        """è·å–å·²æ³¨å†Œä»»åŠ¡å¤´çš„æ•°é‡"""
        return len(self._task_heads)
    
    def save_heads(self, save_path: str) -> bool:
        """
        ä¿å­˜æ‰€æœ‰ä»»åŠ¡å¤´
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            heads_state = {}
            for session_name, head_info in self._task_heads.items():
                heads_state[session_name] = {
                    'task_name': head_info.task_name,
                    'args': head_info.args,
                    'head_state_dict': head_info.head.state_dict(),
                    'created_at': head_info.created_at,
                    'is_frozen': head_info.is_frozen
                }
            
            torch.save(heads_state, save_path)
            logger.info(f"Saved {len(heads_state)} task heads to: {save_path}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to save task heads: {e}")
            return False
    
    def load_heads(self, load_path: str, strict: bool = False) -> int:
        """
        åŠ è½½ä»»åŠ¡å¤´
        
        Args:
            load_path: åŠ è½½è·¯å¾„
            strict: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆåŠ è½½å¤±è´¥æ—¶æŠ¥é”™ï¼‰
            
        Returns:
            æˆåŠŸåŠ è½½çš„ä»»åŠ¡å¤´æ•°é‡
        """
        if not os.path.exists(load_path):
            msg = f"Task heads file not found: {load_path}"
            if strict:
                raise FileNotFoundError(msg)
            else:
                logger.warning(msg)
                return 0
        
        try:
            heads_state = torch.load(load_path, map_location=self.device)
            loaded_count = 0
            
            for session_name, head_data in heads_state.items():
                try:
                    # é‡æ–°åˆ›å»ºä»»åŠ¡å¤´
                    task_name = head_data['task_name']
                    args = head_data['args']
                    use_label_embedding = getattr(args, 'use_label_embedding', False)
                    
                    # åˆ›å»ºhead
                    head = self.create_and_register_head(
                        session_name, task_name, args, use_label_embedding
                    )
                    
                    if head is not None:
                        # åŠ è½½å‚æ•°
                        head.load_state_dict(head_data['head_state_dict'])
                        
                        # æ¢å¤å†»ç»“çŠ¶æ€
                        if head_data.get('is_frozen', False):
                            self.freeze_head(session_name)
                        
                        loaded_count += 1
                        logger.info(f"Loaded task head: {session_name} ({task_name})")
                    else:
                        logger.warning(f"Failed to create head for: {session_name}")
                        
                except Exception as e:
                    msg = f"Failed to load head '{session_name}': {e}"
                    if strict:
                        raise RuntimeError(msg)
                    else:
                        logger.warning(msg)
                        continue
            
            logger.info(f"Successfully loaded {loaded_count}/{len(heads_state)} task heads")
            return loaded_count
            
        except Exception as e:
            msg = f"Failed to load task heads from {load_path}: {e}"
            if strict:
                raise RuntimeError(msg)
            else:
                logger.error(msg)
                return 0
    
    def print_summary(self):
        """æ‰“å°ä»»åŠ¡å¤´ç®¡ç†å™¨æ‘˜è¦"""
        print("="*80)
        print("Task Head Manager Summary")
        print("="*80)
        print(f"Total registered heads: {len(self._task_heads)}")
        print(f"Current active session: {self._current_session}")
        print(f"Device: {self.device}")
        print("\nRegistered heads:")
        
        for session_name, head_info in self._task_heads.items():
            is_current = "âœ“" if session_name == self._current_session else " "
            frozen = "ğŸ”’" if head_info.is_frozen else "ğŸ”“"
            usage = self._head_usage_count.get(session_name, 0)
            
            print(f"  [{is_current}] {frozen} {session_name}")
            print(f"      Task: {head_info.task_name}")
            print(f"      Created: {head_info.created_at}")
            print(f"      Usage count: {usage}")
        
        print("="*80)
    
    def validate_head(self, session_name: str) -> tuple[bool, str]:
        """
        éªŒè¯ä»»åŠ¡å¤´æ˜¯å¦æ­£å¸¸
        
        Returns:
            (is_valid, error_message)
        """
        if session_name not in self._task_heads:
            return False, f"Head not found: {session_name}"
        
        head_info = self._task_heads[session_name]
        head = head_info.head
        
        # æ£€æŸ¥headæ˜¯å¦åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        try:
            first_param = next(head.parameters())
            if str(first_param.device) != str(self.device):
                return False, f"Head on wrong device: {first_param.device} (expected {self.device})"
        except StopIteration:
            return False, "Head has no parameters"
        
        # æ£€æŸ¥headæ˜¯å¦å¯ä»¥å‰å‘ä¼ æ’­
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šéªŒè¯é€»è¾‘
        
        return True, "OK"


def create_task_head_manager(base_model, label_embedding_manager=None, 
                             device='cuda') -> TaskHeadManager:
    """
    åˆ›å»ºä»»åŠ¡å¤´ç®¡ç†å™¨çš„å·¥å‚å‡½æ•°
    
    Args:
        base_model: åŸºç¡€æ¨¡å‹
        label_embedding_manager: æ ‡ç­¾åµŒå…¥ç®¡ç†å™¨
        device: è®¾å¤‡
        
    Returns:
        ä»»åŠ¡å¤´ç®¡ç†å™¨å®ä¾‹
    """
    return TaskHeadManager(base_model, label_embedding_manager, device)

