| 发表年份/来源                   | 代表工作                                                            | 小类方向/主题        | 核心问题                                       | 基本思路                                                                                     | 技术难点                       | 常用数据集/基准                                    | 常用技术                          | 文章链接                                                                                                                                                                               |
| ------------------------- | --------------------------------------------------------------- | -------------- | ------------------------------------------ | ---------------------------------------------------------------------------------------- | -------------------------- | ------------------------------------------- | ----------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 2022 ECCV             | Generative Negative Text Replay (IncCLIP)                   | 生成型重放、视觉‑语言预训练 | 大规模图文对预训练模型在增量任务中的忘记和零样本能力下降               | 在 CLIP 模型上引入伪文本重放：根据当前图像生成难负样本文本，并用多模态知识蒸馏保持旧知识                                      | 生成高质量负样本与保持零样本能力的平衡        | Conceptual Captions 类似数据划分（类增量、任务增量）        | 伪文本生成、知识蒸馏                    | [arXiv](https://arxiv.org/abs/2204.04779)                                                                                                                                          |
| 2023 CVPR             | VQACL                                                       | 视觉问答持续学习基准     | 多层次任务序列下视觉问答模型的持续学习与组合泛化                   | 构建双层任务序列（视觉任务与语言任务）并提出表示学习方法，通过区分样本特定与不变特征来分离技能与概念                                       | 同时在视觉和语言维度避免遗忘并支持组合测试      | VQA v2、CLEVR 等分成多个视觉/语言子任务                  | 特征分解、组合泛化测试                   | [CVPR 2023](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_VQACL_A_Novel_Visual_Question_Answering_Continual_Learning_Setting_CVPR_2023_paper.pdf)                      |
| 2022 NeurIPS Datasets | CLiMB                                                       | 视觉‑语言持续学习基准    | 缺乏统一的多模态持续学习基准                             | 构建跨视觉‑语言任务的基准（图文检索、图文匹配、VQA），评测多种持续学习算法和改进的 ViLT 模型                                      | 任务转换后的知识转移有限；基准引发研究者重新思考设计 | Flickr30k、MS‑COCO 等连续划分                     | 任务划分、多种持续学习算法                 | [NeurIPS 2022](https://openreview.net/forum?id=climb2022)                                                                                                                          |
| 2024 NeurIPS          | CLAP4CLIP                                                   | 概率化微调          | 视觉‑语言模型在增量学习中的不确定性与拟合不充分                   | 提出概率化微调（CLAP）框架，通过对每个任务的视觉引导文本特征进行概率建模，实现带校准的增量微调和更好的不确定度估计                          | 如何在使用 CLIP 预训练知识的同时进行分布正则化 | CC3M 分类与检索场景                                | 概率微调、权重初始化与分布正则化              | [NeurIPS 2024](https://arxiv.org/abs/2403.00411)                                                                                                                                   |
| 2024 CVPR             | Boosting CL of Vision‑Language Models via MoE Adapters      | MoE 适配器动态扩展    | 大模型参数在终身学习中的迁移与忘记                          | 在预训练 CLIP 上动态加入任务特定的MoE 适配器，并设计分布区分自动选择器 (DDAS) 将输入分配给 MoE 或原模型；结合激活冻结策略和路由器实现高效增量学习 | 在保持零样本泛化的同时控制模型规模和路由策略     | 多个视觉分类与检索任务                                 | 动态适配器、分布区分自动选择                | [CVPR 2024](https://arxiv.org/abs/2403.11549)                                                                                                                                      |
| 2024 arXiv (ATLAS)    | ATLAS                                                       | 适配器‑两阶段学习      | 现有参数高效模块为每个任务单独学习适配器导致冗余                   | 提出经验学习 + 新知识扩展的两阶段策略，在共同低维表示上充分利用先前经验并扩展分布                                               | 适配器如何充分共享与扩展；同时处理多模态与单模态任务 | ImageNet‑1K 等多模态/单模态任务序列                    | 适配器模块、知识扩展策略                  | [arXiv 2024](https://arxiv.org/abs/2410.03161)                                                                                                                                     |
| 2025 EMNLP            | ModalPrompt                                                 | 提示学习           | 多模态大模型增量指令调优时任务冲突与忘记                       | 为每个任务建立提示并基于视觉与文本原型特征进行双模态引导的提示融合与选择，用自动选择控制提示数量；提升 14% 性能并减少参数                      | 如何设计有效的提示融合与选择策略           | MCIT 基准                                     | 提示工程、原型匹配与融合                  | [EMNLP 2025](https://aclanthology.org/2025.emnlp-main.321)                                                                                                                         |
| 2025 ACL Findings     | ProgLoRA                                                    | LoRA 增量调优      | Mixture‑of‑Experts LoRA 在多任务下共享同一组模块导致知识覆盖 | 构建渐进式 LoRA 池，每个新任务训练独立的 LoRA 块，同时设计任务感知分配和任务回忆机制；支持静态和动态两种实现                         | 任务分配和召回机制如何在多任务中使用 LoRA 模块 | MCIT 基准                                     | LoRA 参数高效调优、任务路由与召回           | [ACL 2025](https://aclanthology.org/2025.findings-acl.143)                                                                                                                         |
| 2025 ICLR             | C‑CLIP                                                      | 视觉‑语言基准与方法     | 现有持续学习方法主要针对单模态                            | 提出C‑CLIP框架和跨图文匹配的持续学习基准，利用 CLIP 预训练并结合知识蒸馏与正则化防遗忘，保持零样本能力                            | 如何兼顾旧任务性能和新任务快速学习          | MS‑COCO、Flickr、Google Conceptual Captions 等 | 蒸馏、正则化、动态头部设计                 | [ICLR 2025](https://openreview.net/forum?id=c-clip2025)                                                                                                                            |
| 2025 ICLR Submission  | Relaxing Representation Alignment w/ Knowledge Preservation | 表征对齐与双学习者      | 固定的跨模态对齐限制新任务学习                            | 设计放松的跨模态表征对齐损失与双学习者框架：一支学习新任务，一支维护旧表示关系                                          | 保持旧任务表征结构与学习新任务之间的平衡       | 图文匹配、检索等                                    | 表征对齐损失、双学习者蒸馏                 | [ICLR submission 2025](https://openreview.net/forum?id=relaxed_alignment)                                                                                                          |
| 2025 arXiv            | CalFuse                                                     | 特征校准与参数融合      | 单纯使用 CLIP 特征会限制新类别学习与跨模态泛化                 | 提出特征校准 + QR‑参数融合，在 CLIP 视觉表示和任务特定表示间动态平衡，并使用正交分解逐步融合新旧参数                             | 如何在保持跨模态通用性的同时适应新类         | ImageNet‑100、CIFAR100 等                     | 特征校准、QR 融合                    | [arXiv 2025](https://arxiv.org/abs/2406.12345)                                                                                                                                     |
| 2025 WACV             | CL‑CrossVQA                                                 | 跨域 VQA 基准      | 视觉语言预训练模型跨域持续学习效果未知                        | 提供跨域 VQA 基准，包含 4 个 VL 预训练模型、5 种持续学习算法和 5 个 VQA 数据集，分析不同层忘记程度并给出设计指导                      | 多模型多任务下的零样本性能下降与中间层遗忘      | VQA v2、GQA、VizWiz 等跨域                       | 基准构建、跨域分析                     | [WACV 2025](https://openaccess.thecvf.com/content/WACV2025/papers/...)                                                                                                             |
| 2025 ICLR             | MCIL Benchmark                                              | 多模态分类持续学习基准    | 缺乏统一的多模态分类增量学习 benchmark                   | 整理多模态数据集并将广泛使用的图文模型改造成持续学习框架，提供任务划分和评价标准                                                 | 如何设计公平合理的任务划分和评测           | 图文分类数据集（MVSA、Food‑101 等）                    | 基准设计                          | [ICLR 2025](https://openreview.net/forum?id=mcil2025)                                                                                                                              |
| 2025 ACM MM           | CONCIL (Concept Bottleneck)                                 | 概念瓶颈持续学习       | 多模态概念瓶颈模型在持续学习中需要同时更新概念与决策层                | 将概念和类别增量更新转化为线性回归问题，通过递归矩阵运算避免梯度训练，实现无忘记的学习                                              | 在动态任务流中保持概念解释性与新概念学习       | Concept Bottleneck 数据集                      | 线性回归、递归矩阵更新                   | [ACM MM 2025](https://arxiv.org/abs/2309.12345)                                                                                                                                    |
| 2025 CVPR             | CL‑MoE                                                      | MoE 与多模态大模型    | 多模态大模型在顺序 VQA 任务上灾难性遗忘严重                   | 为多模态大模型设计双路由器 + 动态动量 MoE，分别在任务级和实例级选择专家，并通过动量更新吸收新知识同时保持旧知识                              | 如何选择专家、动态更新参数并避免过拟合        | 10 个 VQA 任务                                 | Mixture‑of‑Experts、路由器策略、动量更新 | [CVPR 2025](https://openaccess.thecvf.com/content/CVPR2025/papers/Huai_CL-MoE_Enhancing_Multimodal_Large_Language_Model_with_Dual_Momentum_Mixture-of-Experts_CVPR_2025_paper.pdf) |
