# Kaggle NERè®­ç»ƒæŒ‡å— - è¶…å‚æ•°æœç´¢ & å¯è§†åŒ–

## ğŸ“Œ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›åœ¨ Kaggle ä¸Šè¿è¡Œ `simple_ner_training.py` è¿›è¡Œ **NERè¶…å‚æ•°æœç´¢** çš„å®Œæ•´æµç¨‹ã€‚

### æ ¸å¿ƒåŠŸèƒ½

- âœ… è‡ªåŠ¨è¿è¡Œå¤šç»„è¶…å‚æ•°å®éªŒ
- âœ… DeBERTa-v3-base + BiLSTM + CRF æ¶æ„
- âœ… Twitter2015 MNER æ•°æ®é›†
- âœ… åŒæ—¶è®¡ç®— Token-level å’Œ Span-level F1
- âœ… è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- âœ… ç»“æœè‡ªåŠ¨æ‰“åŒ…ä¸‹è½½
- âœ… è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿ã€F1æ•£ç‚¹å›¾ã€å‰2000æ¡DEVçš„gold/pred spansï¼ˆtests/ ç›®å½•ï¼‰
- âœ… å¤ç”¨ `visualize/feature_clustering_enhanced.py` ç”Ÿæˆ t-SNE ç‰¹å¾èšç±»å›¾ï¼ˆçœŸå®/é¢„æµ‹æ ‡ç­¾å¯¹æ¯”ï¼‰ï¼Œä¸æ¨¡å‹è¾“å‡ºåŒç›®å½•

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿè®¾ç½®ï¼‰

### Step 1: æœ¬åœ°å‡†å¤‡æ•°æ®

```bash
cd /path/to/MCM

# ç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®
# data/
#   â”œâ”€â”€ MNER/
#   â”‚   â””â”€â”€ twitter2015/
#   â”‚       â”œâ”€â”€ train.txt
#   â”‚       â”œâ”€â”€ dev.txt
#   â”‚       â””â”€â”€ test.txt
#   â””â”€â”€ img/  # æˆ– twitter2015_images/
#       â”œâ”€â”€ xxx.jpg
#       â””â”€â”€ ...
```

### Step 2: æ‰“åŒ…é¡¹ç›®

```bash
# å®Œæ•´æ‰“åŒ…ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
zip -r MCM_ner.zip data/ downloaded_model/ tests/ datasets/ models/ modules/ continual/

# æˆ–åªæ‰“åŒ…å¿…éœ€æ–‡ä»¶ï¼ˆæ›´å¿«ï¼‰
zip -r MCM_ner_minimal.zip \
  data/MNER/ \
  data/img/ \
  downloaded_model/deberta-v3-base/ \
  tests/simple_ner_training.py \
  datasets/mner_dataset.py \
  -x "*.pyc" -x "__pycache__/*"
```

### Step 3: ä¸Šä¼ åˆ° Kaggle

1. è®¿é—® [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
2. **New Dataset** â†’ ä¸Šä¼  `MCM_ner.zip`
3. Title: `MCM NER Training`
4. Slug: `mcm-ner-training` âš ï¸ é‡è¦
5. **Create**

### Step 4: åˆ›å»º Notebook

1. [https://www.kaggle.com/code](https://www.kaggle.com/code) â†’ **New Notebook**
2. Settings:
   - **GPU P100** æˆ– **T4**
   - æ·»åŠ æ•°æ®é›†: `mcm-ner-training`
3. å¤åˆ¶ä¸‹é¢çš„ä»£ç åˆ° Notebook

---

## ğŸ““ Kaggle Notebook ä»£ç 

### Cell 1: ç¯å¢ƒæ£€æŸ¥å’Œè®¾ç½®

```python
import os
import sys
import shutil
from pathlib import Path

print("="*80)
print("ç¯å¢ƒæ£€æŸ¥")
print("="*80)

# æ£€æŸ¥Kaggleç¯å¢ƒ
print("\nå¯ç”¨æ•°æ®é›†:")
for dataset in os.listdir("/kaggle/input"):
    print(f"  - {dataset}")

# è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
use_split_mode = False
code_path = None
data_path = None

# æ£€æµ‹åˆ†ç¦»æ¨¡å¼
if os.path.exists("/kaggle/input/mcm-ner-code"):
    use_split_mode = True
    code_path = Path("/kaggle/input/mcm-ner-code")
    print("\nâœ“ æ£€æµ‹åˆ°åˆ†ç¦»æ¨¡å¼")
    print(f"  ä»£ç è·¯å¾„: {code_path}")
  
    if os.path.exists("/kaggle/input/mcm-data"):
        data_path = Path("/kaggle/input/mcm-data")
        print(f"  æ•°æ®è·¯å¾„: {data_path}")
    else:
        print("  âš ï¸ æœªæ‰¾åˆ° mcm-dataï¼Œè¯·åœ¨Dataé¢æ¿æ·»åŠ ")

# æ£€æµ‹å®Œæ•´æ¨¡å¼
else:
    possible_paths = [
        Path("/kaggle/input/mcm-project/MCM"),
        Path("/kaggle/input/mcm-project"),
    ]
  
    for path in possible_paths:
        if path.exists():
            code_path = path
            print(f"\nâœ“ æ£€æµ‹åˆ°å®Œæ•´æ¨¡å¼")
            print(f"  é¡¹ç›®è·¯å¾„: {path}")
            break

if code_path is None:
    raise FileNotFoundError("æœªæ‰¾åˆ°é¡¹ç›®ï¼è¯·æ£€æŸ¥æ•°æ®é›†é…ç½®")

# åˆ—å‡ºé¡¹ç›®å†…å®¹
print("\né¡¹ç›®å†…å®¹:")
all_items = sorted([item.name for item in code_path.iterdir()])
print(f"  å…± {len(all_items)} é¡¹")
for item in all_items[:15]:  # æ˜¾ç¤ºå‰15é¡¹
    print(f"  - {item}")
if len(all_items) > 15:
    print(f"  ... è¿˜æœ‰ {len(all_items) - 15} é¡¹")

# å¤åˆ¶é¡¹ç›®åˆ°å¯å†™ç›®å½•
work_project_path = Path("/MCM")

# æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤åˆ¶
need_copy = False
if not work_project_path.exists():
    need_copy = True
    reason = "ç›®å½•ä¸å­˜åœ¨"
else:
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    critical_files = [
        work_project_path / "tests/simple_ner_training.py",
        work_project_path / "datasets/mner_dataset.py",
    ]
    missing_files = [f for f in critical_files if not f.exists()]
  
    if missing_files:
        need_copy = True
        reason = f"ç¼ºå°‘å…³é”®æ–‡ä»¶: {[f.name for f in missing_files]}"
        print(f"\nâš ï¸ æ£€æµ‹åˆ° {work_project_path} å·²å­˜åœ¨ä½†ä¸å®Œæ•´")
        print(f"   åŸå› : {reason}")
        print("   å°†åˆ é™¤æ—§ç›®å½•å¹¶é‡æ–°å¤åˆ¶...")
        shutil.rmtree(work_project_path)
    else:
        print(f"\nâœ“ {work_project_path} å·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡å¤åˆ¶")

if need_copy:
    print(f"\nå¤åˆ¶ä»£ç åˆ°å·¥ä½œç›®å½• (åŸå› : {reason})...")
    print(f"  æº: {code_path}")
    print(f"  ç›®æ ‡: {work_project_path}")
    shutil.copytree(code_path, work_project_path, dirs_exist_ok=True)
    print("âœ“ å¤åˆ¶å®Œæˆ")
  
    # éªŒè¯å¤åˆ¶ç»“æœ
    test_file = work_project_path / "tests/simple_ner_training.py"
    if test_file.exists():
        print(f"âœ“ éªŒè¯æˆåŠŸ: tests/simple_ner_training.py å­˜åœ¨")
    else:
        print(f"âŒ è­¦å‘Š: tests/simple_ner_training.py ä»ä¸å­˜åœ¨ï¼")
        print(f"   è¯·æ£€æŸ¥æºè·¯å¾„: {code_path / 'tests'}")

# å¦‚æœæ˜¯åˆ†ç¦»æ¨¡å¼ï¼Œé“¾æ¥æ•°æ®ç›®å½•
if use_split_mode and data_path:
    target_data = work_project_path / "data"
    target_model = work_project_path / "downloaded_model"
  
    # é“¾æ¥data
    if not target_data.exists():
        source_data = data_path / "data" if (data_path / "data").exists() else data_path
        print(f"\né“¾æ¥æ•°æ®ç›®å½•: {source_data} -> {target_data}")
        try:
            os.symlink(source_data, target_data)
            print("âœ“ dataé“¾æ¥æˆåŠŸ")
        except:
            print("  ç¬¦å·é“¾æ¥å¤±è´¥ï¼Œæ”¹ç”¨å¤åˆ¶...")
            shutil.copytree(source_data, target_data, dirs_exist_ok=True)
            print("âœ“ dataå¤åˆ¶å®Œæˆ")
  
    # é“¾æ¥æ¨¡å‹
    source_model = data_path / "downloaded_model"
    if source_model.exists() and not target_model.exists():
        print(f"\né“¾æ¥æ¨¡å‹ç›®å½•: {source_model} -> {target_model}")
        try:
            os.symlink(source_model, target_model)
            print("âœ“ downloaded_modelé“¾æ¥æˆåŠŸ")
        except:
            shutil.copytree(source_model, target_model, dirs_exist_ok=True)
            print("âœ“ downloaded_modelå¤åˆ¶å®Œæˆ")

# åˆ‡æ¢å·¥ä½œç›®å½•
os.chdir(work_project_path)
sys.path.insert(0, str(work_project_path))

print(f"\nå½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"Pythonè·¯å¾„: {sys.path[0]}")

# éªŒè¯æ•°æ®é›†
data_dir = work_project_path / "data"
print(f"\næ•°æ®ç›®å½•: {data_dir}")
print(f"æ•°æ®é›†å­˜åœ¨: {data_dir.exists()}")

if data_dir.exists():
    print("\nå¯ç”¨æ•°æ®é›†:")
    for item in data_dir.iterdir():
        if item.is_dir():
            print(f"  - {item.name}/")


print(f"\nå½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"Pythonè·¯å¾„: {sys.path[0]}")

# æ£€æŸ¥å…³é”®æ–‡ä»¶
print("\nå…³é”®æ–‡ä»¶æ£€æŸ¥:")
key_files = [
    "tests/simple_ner_training.py",
    "datasets/mner_dataset.py",
    "data/MNER/twitter2015/train.txt",
]
all_exist = True
for f in key_files:
    file_path = Path(f)
    exists = file_path.exists()
    status = "âœ“" if exists else "âœ—"
    print(f"  {status} {f}")
    if not exists:
        all_exist = False
        # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦å­˜åœ¨
        parent_dir = file_path.parent
        if parent_dir.exists():
            print(f"      ç›®å½• {parent_dir}/ å­˜åœ¨ï¼Œä½†æ–‡ä»¶ä¸å­˜åœ¨")
        else:
            print(f"      ç›®å½• {parent_dir}/ ä¸å­˜åœ¨")

if not all_exist:
    print("\nâš ï¸ éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥:")
    print("  1. ä¸Šä¼ çš„zipæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€æ–‡ä»¶ï¼Ÿ")
    print("  2. æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„æ‰“åŒ…å‘½ä»¤ï¼Ÿ")
    print("  3. å»ºè®®é‡æ–°æ‰“åŒ…å¹¶ä¸Šä¼ ")
    print("\næ­£ç¡®çš„æ‰“åŒ…å‘½ä»¤:")
    print("  zip -r MCM_ner.zip data/ downloaded_model/ tests/ datasets/ models/ modules/ continual/")
else:
    print("\nâœ… æ‰€æœ‰å…³é”®æ–‡ä»¶æ£€æŸ¥é€šè¿‡ï¼")
```

### Cell 2: å®‰è£…ä¾èµ–

```python
print("="*80)
print("å®‰è£…ä¾èµ–")
print("="*80)

# Kaggleé¢„è£…äº†å¤§éƒ¨åˆ†åŒ…ï¼Œåªéœ€å®‰è£…ç‰¹å®šçš„
!pip install -q torchcrf

print("\nâœ“ ä¾èµ–å®‰è£…å®Œæˆ")

# éªŒè¯
import torch
from torchcrf import CRF

print(f"\nâœ“ PyTorch: {torch.__version__}")
print(f"âœ“ torchcrf: å¯ç”¨")
```

### Cell 3: GPUæ£€æŸ¥

```python
import torch

print("="*80)
print("GPUä¿¡æ¯")
print("="*80)

if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
  
    print(f"\nâœ“ GPU: {gpu_name}")
    print(f"  æ˜¾å­˜: {gpu_memory:.1f} GB")
    print(f"  CUDA: {torch.version.cuda}")
else:
    print("\nâŒ æœªæ£€æµ‹åˆ°GPU")
```

### Cell 4: å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´

```python
import json
from pathlib import Path

print("="*80)
print("è¶…å‚æ•°æœç´¢é…ç½®")
print("="*80)

# å®šä¹‰å¤šç»„è¶…å‚æ•°
HYPERPARAMETER_CONFIGS = [
    {
        "id": 1,
        "name": "baseline",
        "learning_rate": 1e-5,
        "lstm_lr": 1e-4,
        "crf_lr": 1e-3,
        "batch_size": 16,
        "num_epochs": 20,
        "lstm_hidden": 256,
        "lstm_layers": 2,
        "dropout": 0.3,
    },
    {
        "id": 2,
        "name": "higher_lr",
        "learning_rate": 2e-5,
        "lstm_lr": 2e-4,
        "crf_lr": 2e-3,
        "batch_size": 16,
        "num_epochs": 20,
        "lstm_hidden": 256,
        "lstm_layers": 2,
        "dropout": 0.3,
    },
    {
        "id": 3,
        "name": "larger_lstm",
        "learning_rate": 1e-5,
        "lstm_lr": 1e-4,
        "crf_lr": 1e-3,
        "batch_size": 16,
        "num_epochs": 20,
        "lstm_hidden": 512,  # æ›´å¤§
        "lstm_layers": 3,    # æ›´æ·±
        "dropout": 0.3,
    },
    {
        "id": 4,
        "name": "higher_dropout",
        "learning_rate": 1e-5,
        "lstm_lr": 1e-4,
        "crf_lr": 1e-3,
        "batch_size": 16,
        "num_epochs": 20,
        "lstm_hidden": 256,
        "lstm_layers": 2,
        "dropout": 0.5,  # æ›´é«˜dropout
    },
    {
        "id": 5,
        "name": "smaller_batch",
        "learning_rate": 1e-5,
        "lstm_lr": 1e-4,
        "crf_lr": 1e-3,
        "batch_size": 8,   # æ›´å°batch
        "num_epochs": 20,
        "lstm_hidden": 256,
        "lstm_layers": 2,
        "dropout": 0.3,
    },
]

# é€‰æ‹©è¦è¿è¡Œçš„å®éªŒï¼ˆæ ¹æ®æ—¶é—´é™åˆ¶è°ƒæ•´ï¼‰
START_EXP = 1
END_EXP = 3  # å»ºè®®3-5ä¸ªå®éªŒ

selected_configs = [c for c in HYPERPARAMETER_CONFIGS 
                    if START_EXP <= c['id'] <= END_EXP]

print(f"\nå°†è¿è¡Œ {len(selected_configs)} ä¸ªå®éªŒ:")
for cfg in selected_configs:
    print(f"\nå®éªŒ #{cfg['id']}: {cfg['name']}")
    print(f"  LR: {cfg['learning_rate']}, LSTM_LR: {cfg['lstm_lr']}")
    print(f"  LSTM: {cfg['lstm_hidden']}x{cfg['lstm_layers']}")
    print(f"  Batch: {cfg['batch_size']}, Epochs: {cfg['num_epochs']}")

# é¢„ä¼°æ—¶é—´
est_time_per_exp = 1.5  # hours on P100
total_time = len(selected_configs) * est_time_per_exp
print(f"\né¢„è®¡æ€»è€—æ—¶: {total_time:.1f} å°æ—¶")
print(f"â° Kaggleé™åˆ¶: 9-12 å°æ—¶")

if total_time > 9:
    print("\nâš ï¸ è­¦å‘Š: å¯èƒ½è¶…æ—¶ï¼Œå»ºè®®å‡å°‘å®éªŒæ•°é‡")
```

### Cell 5: åˆ›å»ºå®éªŒè¿è¡Œè„šæœ¬

```python
# åˆ›å»ºä¿®æ”¹åçš„è®­ç»ƒè„šæœ¬ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°
runner_code = '''
import os
import sys
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "/MCM")

# å¯¼å…¥è®­ç»ƒè„šæœ¬çš„å‡½æ•°
from exper.simple_ner_training import (
    SimpleNERModel, train_epoch, evaluate, 
    MNERDataset, compute_f1_metrics, extract_entities, compute_span_f1
)

import torch
from torch.utils.data import DataLoader
from transformers import get_linear_schedule_with_warmup

PROJECT_ROOT = Path("/MCM")

def run_experiment(config, exp_id):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print("=" * 80)
    print(f"å®éªŒ #{exp_id}: {config['name']}")
    print("=" * 80)
    print(json.dumps(config, indent=2))
    print("=" * 80)
  
    start_time = time.time()
  
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(42)
  
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
  
    # æ•°æ®åŠ è½½
    print("\\nğŸ“‚ åŠ è½½æ•°æ®...")
    train_dataset = MNERDataset(
        text_file=str(PROJECT_ROOT / 'data/MNER/twitter2015/train.txt'),
        image_dir=str(PROJECT_ROOT / 'data/img'),
        tokenizer_name='microsoft/deberta-v3-base',
        max_seq_length=128
    )
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True, 
        num_workers=0
    )
  
    dev_dataset = MNERDataset(
        text_file=str(PROJECT_ROOT / 'data/MNER/twitter2015/dev.txt'),
        image_dir=str(PROJECT_ROOT / 'data/img'),
        tokenizer_name='microsoft/deberta-v3-base',
        max_seq_length=128
    )
    dev_loader = DataLoader(
        dev_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=0
    )
  
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(dev_dataset)} æ ·æœ¬")
  
    # æ¨¡å‹æ„å»º
    print("\\nğŸ—ï¸ æ„å»ºæ¨¡å‹...")
    model = SimpleNERModel(
        text_encoder_name='microsoft/deberta-v3-base',
        num_labels=9,
        lstm_hidden=config['lstm_hidden'],
        lstm_layers=config['lstm_layers'],
        dropout=config['dropout'],
        use_crf=True
    )
    model = model.to(device)
  
    # ä¼˜åŒ–å™¨
    optimizer_grouped_parameters = [
        {'params': model.text_encoder.parameters(), 
         'lr': config['learning_rate']},
        {'params': model.bilstm.parameters(), 
         'lr': config['lstm_lr']},
        {'params': model.classifier.parameters(), 
         'lr': config['lstm_lr']},
        {'params': model.crf.parameters(), 
         'lr': config['crf_lr']},
    ]
    optimizer = torch.optim.AdamW(optimizer_grouped_parameters)
  
    total_steps = len(train_loader) * config['num_epochs']
    warmup_steps = int(total_steps * 0.1)
    scheduler = get_linear_schedule_with_warmup(
        optimizer, warmup_steps, total_steps
    )
  
    # è®­ç»ƒå¾ªç¯
    print("\\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    best_dev_f1 = 0.0
    best_epoch = 0
    history = {
        'train_loss': [],
        'dev_loss': [],
        'dev_span_f1': [],
        'dev_token_f1': []
    }
  
    for epoch in range(1, config['num_epochs'] + 1):
        print(f"\\nEpoch {epoch}/{config['num_epochs']}")
      
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device, epoch)
        history['train_loss'].append(train_loss)
      
        # éªŒè¯
        dev_loss, dev_metrics = evaluate(model, dev_loader, device, "Dev")
        history['dev_loss'].append(dev_loss)
        history['dev_span_f1'].append(dev_metrics['span_f1'])
        history['dev_token_f1'].append(dev_metrics['token_micro_f1'])
      
        print(f"  Train Loss: {train_loss:.4f}")
        print(f"  Dev Loss: {dev_loss:.4f}")
        print(f"  Span F1: {dev_metrics['span_f1']:.2%}")
        print(f"  Token F1: {dev_metrics['token_micro_f1']:.2%}")
      
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if dev_metrics['span_f1'] > best_dev_f1:
            best_dev_f1 = dev_metrics['span_f1']
            best_epoch = epoch
          
            save_path = f'/kaggle/working/best_model_exp{exp_id}.pt'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'dev_f1': best_dev_f1,
                'config': config
            }, save_path)
            print(f"  âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (F1={best_dev_f1:.2%})")
  
    elapsed = (time.time() - start_time) / 3600
  
    # ä¿å­˜å®éªŒç»“æœ
    results = {
        'exp_id': exp_id,
        'config': config,
        'best_epoch': best_epoch,
        'best_dev_span_f1': best_dev_f1,
        'history': history,
        'elapsed_hours': elapsed
    }
  
    result_path = f'/kaggle/working/results_exp{exp_id}.json'
    with open(result_path, 'w') as f:
        json.dump(results, f, indent=2)

    print("\\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–ä¸æ ·ä¾‹...")
    output_dir = Path("/kaggle/working")
    
    # 1. å¯¼å‡ºé¢„æµ‹æ ·ä¾‹ (jsonl)
    debug_limit = 2000
    records = []
    model.eval()
    try:
        with torch.no_grad():
            for batch in dev_loader:
                if len(records) >= debug_limit: break
                
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                _, logits = model(input_ids, attention_mask, labels)
                if model.use_crf:
                    preds = model.decode(input_ids, attention_mask)
                else:
                    preds = torch.argmax(logits, dim=-1)
                
                for i in range(input_ids.size(0)):
                    if len(records) >= debug_limit: break
                    
                    # è¿‡æ»¤padding
                    valid_mask = labels[i] != -100
                    gold_seq = labels[i][valid_mask].cpu().tolist()
                    pred_seq = preds[i][valid_mask].cpu().tolist()
                    
                    # è§£ç span
                    gold_spans = list(decode_mner(gold_seq))
                    pred_spans = list(decode_mner(pred_seq))
                    
                    records.append({
                        "exp_id": exp_id,
                        "gold_seq": gold_seq,
                        "pred_seq": pred_seq,
                        "gold_spans": gold_spans,
                        "pred_spans": pred_spans
                    })
        
        # ä¿å­˜æ ·ä¾‹
        jsonl_path = output_dir / f"exp{exp_id}_samples.jsonl"
        with open(jsonl_path, "w", encoding="utf-8") as f:
            for rec in records:
                f.write(json.dumps(rec, ensure_ascii=False) + "\\n")
        print(f"  âœ“ æ ·ä¾‹å·²å¯¼å‡º: {jsonl_path}")
        
    except Exception as e:
        print(f"  âš ï¸ æ ·ä¾‹å¯¼å‡ºå¤±è´¥: {e}")

# 2. ç”Ÿæˆ t-SNE (å®ä½“Tokençº§èšç±» - ä¸¥æ ¼ç­›é™¤Oæ ‡ç­¾)
    try:
        from sklearn.manifold import TSNE
        import matplotlib.pyplot as plt
        
        all_entity_feats = []
        all_entity_labs = []
        
        # é™åˆ¶Tokenæ•°é‡ï¼Œé¿å…è®¡ç®—å¤ªæ…¢
        max_tokens = 3000
        collected_tokens = 0
        
        # æ ‡ç­¾æ˜ å°„: (B/I ç»Ÿä¸€ä¸ºä¸€ä¸ªç±»åˆ«)
        # 1(B-PER), 2(I-PER) -> 0 (PER)
        # 3(B-ORG), 4(I-ORG) -> 1 (ORG)
        # 5(B-LOC), 6(I-LOC) -> 2 (LOC)
        # 7(B-MISC), 8(I-MISC)-> 3 (MISC)
        def map_label(l):
            return (l - 1) // 2
            
        label_names = {0: 'PER', 1: 'ORG', 2: 'LOC', 3: 'MISC'}
        
        with torch.no_grad():
            for batch in dev_loader:
                if collected_tokens >= max_tokens: break
                
                ids = batch["input_ids"].to(device)
                mask = batch["attention_mask"].to(device)
                labels = batch["labels"].to(device)
                
                # è·å–Tokenç‰¹å¾: (batch, seq, hidden)
                out = model.text_encoder(input_ids=ids, attention_mask=mask).last_hidden_state
                
                # å±•å¹³æ‰€æœ‰batch
                out_flat = out.view(-1, out.size(-1)) # (N, hidden)
                labels_flat = labels.view(-1)         # (N)
                
                # ç­›é€‰æ¡ä»¶: ä¸æ˜¯Padding (-100) ä¸” ä¸æ˜¯O (0)
                mask_entity = (labels_flat != -100) & (labels_flat != 0)
                
                if mask_entity.sum() > 0:
                    entity_feats = out_flat[mask_entity]
                    entity_labs = labels_flat[mask_entity]
                    
                    all_entity_feats.append(entity_feats.cpu().numpy())
                    all_entity_labs.append(entity_labs.cpu().numpy())
                    
                    collected_tokens += entity_feats.size(0)
                
        if len(all_entity_feats) > 0:
            feats = np.concatenate(all_entity_feats, axis=0)
            raw_labs = np.concatenate(all_entity_labs, axis=0)
            
            # å¦‚æœtokenè¿‡å¤šï¼Œéšæœºé‡‡æ ·ä»¥åŠ å¿«t-SNE
            if feats.shape[0] > max_tokens:
                indices = np.random.choice(feats.shape[0], max_tokens, replace=False)
                feats = feats[indices]
                raw_labs = raw_labs[indices]
            
            # æ˜ å°„æ ‡ç­¾åˆ°å®ä½“å¤§ç±»
            labs = np.array([map_label(l) for l in raw_labs])
            
            print(f"  t-SNE: æ­£åœ¨å¤„ç† {feats.shape[0]} ä¸ªå®ä½“Token...")
            tsne = TSNE(n_components=2, init="pca", learning_rate='auto', random_state=42)
            emb = tsne.fit_transform(feats)
            
            plt.figure(figsize=(10, 8))
            # ç»˜åˆ¶æ•£ç‚¹å›¾
            scatter = plt.scatter(emb[:, 0], emb[:, 1], c=labs, cmap="tab10", s=20, alpha=0.7)
            
            # æ·»åŠ å›¾ä¾‹
            handles, _ = scatter.legend_elements()
            # ç¡®ä¿å›¾ä¾‹æ ‡ç­¾å¯¹åº”æ­£ç¡®
            legend_labels = [label_names.get(i, str(i)) for i in range(len(handles))]
            plt.legend(handles, legend_labels, title="Entity Type")
            
            plt.title(f"Exp {exp_id} Entity Token Clustering (No 'O')")
            plt.savefig(output_dir / f"exp{exp_id}_tsne_entity.png")
            plt.close()
            print(f"  âœ“ t-SNEå·²ä¿å­˜: exp{exp_id}_tsne_entity.png")
        else:
            print("  âš ï¸ æ— å®ä½“Tokenç”¨äº t-SNE (å¯èƒ½æ¨¡å‹é¢„æµ‹å…¨ä¸ºOæˆ–æ ·æœ¬ä¸­æ— å®ä½“)")
        
    except Exception as e:
        print(f"  âš ï¸ t-SNEç”Ÿæˆå¤±è´¥: {e}")

    print(f"\\nâœ“ å®éªŒ #{exp_id} å®Œæˆ")
    print(f"  æœ€ä½³Span F1: {best_dev_f1:.2%} (Epoch {best_epoch})")
    print(f"  è€—æ—¶: {elapsed:.2f} å°æ—¶")
  
    return results

# ä¸»å‡½æ•°
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--config_file', type=str, required=True)
    parser.add_argument('--exp_id', type=int, required=True)
    args = parser.parse_args()
  
    with open(args.config_file, 'r') as f:
        config = json.load(f)
  
    run_experiment(config, args.exp_id)
'''

# ä¿å­˜è„šæœ¬
with open('/kaggle/working/run_ner_experiment.py', 'w') as f:
    f.write(runner_code)

print("âœ“ å®éªŒè¿è¡Œè„šæœ¬å·²åˆ›å»º: /kaggle/working/run_ner_experiment.py")
```

### Cell 6: è¿è¡Œæ‰€æœ‰å®éªŒ

```python
import subprocess
import time
import json

print("="*80)
print(f"å¼€å§‹è¿è¡Œ {len(selected_configs)} ä¸ªå®éªŒ")
print("="*80)

all_results = []
total_start = time.time()

for cfg in selected_configs:
    print(f"\n{'='*80}")
    print(f"å®éªŒ #{cfg['id']}/{END_EXP}: {cfg['name']}")
    print(f"{'='*80}\n")
  
    # ä¿å­˜é…ç½®
    config_file = f'/kaggle/working/config_exp{cfg["id"]}.json'
    with open(config_file, 'w') as f:
        json.dump(cfg, f, indent=2)
  
    # è¿è¡Œå®éªŒ
    exp_start = time.time()
  
    cmd = [
        'python', '/kaggle/working/run_ner_experiment.py',
        '--config_file', config_file,
        '--exp_id', str(cfg['id'])
    ]
  
    try:
        subprocess.run(cmd, check=True)
      
        # è¯»å–ç»“æœ
        result_file = f'/kaggle/working/results_exp{cfg["id"]}.json'
        with open(result_file, 'r') as f:
            result = json.load(f)
        all_results.append(result)
      
        exp_elapsed = (time.time() - exp_start) / 3600
        print(f"\nâœ“ å®éªŒ #{cfg['id']} å®Œæˆ ({exp_elapsed:.2f}å°æ—¶)")
      
    except Exception as e:
        print(f"\nâŒ å®éªŒ #{cfg['id']} å¤±è´¥: {e}")
        continue
  
    # æ¸…ç†GPUç¼“å­˜
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

total_elapsed = (time.time() - total_start) / 3600

print("\n" + "="*80)
print("æ‰€æœ‰å®éªŒå®Œæˆï¼")
print("="*80)
print(f"æ€»è€—æ—¶: {total_elapsed:.2f} å°æ—¶")
print(f"å®Œæˆå®éªŒ: {len(all_results)}/{len(selected_configs)}")

# ä¿å­˜æ±‡æ€»ç»“æœ
summary = {
    'total_experiments': len(selected_configs),
    'completed': len(all_results),
    'total_hours': total_elapsed,
    'results': all_results
}

with open('/kaggle/working/summary.json', 'w') as f:
    json.dump(summary, f, indent=2)

print("\nâœ“ æ±‡æ€»ç»“æœå·²ä¿å­˜: /kaggle/working/summary.json")
```

### Cell 7: ç»“æœåˆ†æ

```python
import json
import pandas as pd
from pathlib import Path

print("="*80)
print("å®éªŒç»“æœåˆ†æ")
print("="*80)

# è¯»å–æ±‡æ€»ç»“æœ
with open('/kaggle/working/summary.json', 'r') as f:
    summary = json.load(f)

# åˆ›å»ºç»“æœè¡¨æ ¼
results_data = []
for res in summary['results']:
     results_data.append({
        'ID': res['exp_id'],
        'Name': res['config']['name'],
        'LR': res['config']['learning_rate'],
        'LSTM_LR': res['config']['lstm_lr'],
        'CRF_LR': res['config']['crf_lr'],
        'LSTM_Hidden': res['config']['lstm_hidden'],
        'LSTM_Layers': res['config']['lstm_layers'],
        'Batch_Size': res['config']['batch_size'],
        'Dropout': res['config']['dropout'],
        'Best_Epoch': res['best_epoch'],
        'Span_F1': res['best_dev_span_f1'],  # æ”¹ä¸ºSpan_F1
        'Time_Hours': res['elapsed_hours']
    })

df = pd.DataFrame(results_data)
df = df.sort_values('Span_F1', ascending=False)  # æ”¹ä¸ºSpan_F1

print("\nğŸ“Š å®éªŒç»“æœæ’åï¼ˆæŒ‰Span F1ï¼‰:")
print(df.to_string(index=False))

# æœ€ä½³ç»“æœ
best_exp = df.iloc[0]
print("\n" + "="*80)
print("ğŸ† æœ€ä½³é…ç½®:")
print("="*80)
print(f"  å®éªŒID: {int(best_exp['ID'])}")
print(f"  åç§°: {best_exp['Name']}")
print(f"  Span F1: {best_exp['Span_F1']:.2%}")
print(f"  æœ€ä½³Epoch: {int(best_exp['Best_Epoch'])}")
print(f"\nè¶…å‚æ•°:")
print(f"  Learning Rate: {best_exp['LR']}")
print(f"  LSTM LR: {best_exp['LSTM_LR']}")
print(f"  CRF LR: {best_exp['CRF_LR']}")
print(f"  LSTM Hidden: {int(best_exp['LSTM_Hidden'])}")
print(f"  LSTM Layers: {int(best_exp['LSTM_Layers'])}")
print(f"  Batch Size: {int(best_exp['Batch_Size'])}")
print(f"  Dropout: {best_exp['Dropout']}")

# ä¿å­˜ç»“æœè¡¨æ ¼
df.to_csv('/kaggle/working/results_table.csv', index=False)
print("\nâœ“ ç»“æœè¡¨æ ¼å·²ä¿å­˜: /kaggle/working/results_table.csv")
```

### Cell 8: å¯è§†åŒ–å­¦ä¹ æ›²çº¿

```python
import matplotlib.pyplot as plt
import json

print("="*80)
print("å­¦ä¹ æ›²çº¿å¯è§†åŒ–")
print("="*80)

# è¯»å–æ‰€æœ‰å®éªŒç»“æœ
with open('/kaggle/working/summary.json', 'r') as f:
    summary = json.load(f)

# åˆ›å»ºå­å›¾
n_exp = len(summary['results'])
fig, axes = plt.subplots(n_exp, 2, figsize=(15, 5*n_exp))

if n_exp == 1:
    axes = axes.reshape(1, -1)

for i, res in enumerate(summary['results']):
    exp_id = res['exp_id']
    name = res['config']['name']
    history = res['history']
  
    epochs = range(1, len(history['train_loss']) + 1)
  
    # Lossæ›²çº¿
    ax1 = axes[i, 0]
    ax1.plot(epochs, history['train_loss'], label='Train Loss', marker='o')
    ax1.plot(epochs, history['dev_loss'], label='Dev Loss', marker='s')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title(f'Exp #{exp_id}: {name} - Loss')
    ax1.legend()
    ax1.grid(True)
  
    # F1æ›²çº¿
    ax2 = axes[i, 1]
    ax2.plot(epochs, history['dev_span_f1'], label='Span F1', marker='o')
    ax2.plot(epochs, history['dev_token_f1'], label='Token F1', marker='s')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('F1 Score')
    ax2.set_title(f'Exp #{exp_id}: {name} - F1')
    ax2.legend()
    ax2.grid(True)

plt.tight_layout()
plt.savefig('/kaggle/working/learning_curves.png', dpi=150, bbox_inches='tight')
print("âœ“ å­¦ä¹ æ›²çº¿å·²ä¿å­˜: /kaggle/working/learning_curves.png")

plt.show()
```

### Cell 9: æ‰“åŒ…æ‰€æœ‰ç»“æœ

```python
import shutil
from pathlib import Path

print("="*80)
print("æ‰“åŒ…å®éªŒç»“æœ")
print("="*80)

# æ”¶é›†æ‰€æœ‰æ–‡ä»¶
output_files = list(Path('/kaggle/working').glob('*.json'))
output_files += list(Path('/kaggle/working').glob('*.pt'))
output_files += list(Path('/kaggle/working').glob('*.csv'))
output_files += list(Path('/kaggle/working').glob('*.png'))

print(f"\næ‰¾åˆ° {len(output_files)} ä¸ªæ–‡ä»¶:")
for f in output_files:
    size = f.stat().st_size / (1024 * 1024)
    print(f"  - {f.name} ({size:.2f} MB)")

# æ‰“åŒ…
print("\næ­£åœ¨æ‰“åŒ…...")
shutil.make_archive(
    '/kaggle/working/ner_experiments',
    'zip',
    '/kaggle/working'
)

zip_path = Path('/kaggle/working/ner_experiments.zip')
zip_size = zip_path.stat().st_size / (1024 * 1024)

print("\n" + "="*80)
print("âœ… æ‰“åŒ…å®Œæˆï¼")
print("="*80)
print(f"ğŸ“¦ æ–‡ä»¶: ner_experiments.zip")
print(f"ğŸ“ å¤§å°: {zip_size:.2f} MB")
print(f"\nè¯·åœ¨å³ä¾§ 'Output' æ ‡ç­¾é¡µä¸‹è½½æ­¤æ–‡ä»¶")
print("\nâš ï¸ ä¸‹è½½å®Œæˆåï¼Œè¯·ç‚¹å‡»å³ä¸Šè§’ 'Stop Session' èŠ‚çœGPUé…é¢")
```

---

## ğŸ“Š æœ¬åœ°ç»“æœåˆ†æ

ä¸‹è½½ `ner_experiments.zip` åï¼š

```python
# è§£å‹
import zipfile
import json
import pandas as pd

with zipfile.ZipFile('ner_experiments.zip', 'r') as zip_ref:
    zip_ref.extractall('ner_results/')

# è¯»å–æ±‡æ€»
with open('ner_results/summary.json', 'r') as f:
    summary = json.load(f)

# åˆ†æ
results = []
for res in summary['results']:
    results.append({
        'Exp': res['exp_id'],
        'Name': res['config']['name'],
        'Span_F1': res['best_dev_span_f1'],
        'Epoch': res['best_epoch'],
        'Hours': res['elapsed_hours']
    })

df = pd.DataFrame(results)
print(df.sort_values('Span_F1', ascending=False))
```

---

## âš™ï¸ è¶…å‚æ•°å»ºè®®

### å­¦ä¹ ç‡è°ƒæ•´

```python
# ä¿å®ˆç­–ç•¥ï¼ˆæ¨èï¼‰
learning_rate: 1e-5
lstm_lr: 1e-4
crf_lr: 1e-3

# æ¿€è¿›ç­–ç•¥
learning_rate: 2e-5
lstm_lr: 2e-4
crf_lr: 2e-3

# å¾®è°ƒç­–ç•¥
learning_rate: 5e-6
lstm_lr: 5e-5
crf_lr: 5e-4
```

### LSTMå¤§å°

```python
# å°æ¨¡å‹ï¼ˆå¿«é€Ÿï¼‰
lstm_hidden: 128
lstm_layers: 1

# ä¸­ç­‰æ¨¡å‹ï¼ˆæ¨èï¼‰
lstm_hidden: 256
lstm_layers: 2

# å¤§æ¨¡å‹ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰
lstm_hidden: 512
lstm_layers: 3
```

### Batch Size

```python
# P100 (16GB) æ¨è
batch_size: 16

# T4 (8GB) æ¨è
batch_size: 8

# æ˜¾å­˜ä¸è¶³æ—¶
batch_size: 4
```

### Dropout

```python
# è½»å¾®æ­£åˆ™åŒ–
dropout: 0.1

# ä¸­ç­‰æ­£åˆ™åŒ–ï¼ˆæ¨èï¼‰
dropout: 0.3

# å¼ºæ­£åˆ™åŒ–
dropout: 0.5
```

---

## â±ï¸ æ—¶é—´ä¼°ç®—

### å•ä¸ªå®éªŒè€—æ—¶ï¼ˆTwitter2015ï¼Œ20 epochsï¼‰

| GPU  | Batch Size | è€—æ—¶/Epoch | æ€»è€—æ—¶              |
| ---- | ---------- | ---------- | ------------------- |
| P100 | 16         | 3-4åˆ†é’Ÿ    | **1-1.5å°æ—¶** |
| P100 | 8          | 4-5åˆ†é’Ÿ    | 1.5-2å°æ—¶           |
| T4   | 16         | 4-5åˆ†é’Ÿ    | 1.5-2å°æ—¶           |
| T4   | 8          | 5-6åˆ†é’Ÿ    | 2-2.5å°æ—¶           |

### å¤šå®éªŒè§„åˆ’

| å®éªŒæ•° | P100è€—æ—¶  | T4è€—æ—¶       | å»ºè®®            |
| ------ | --------- | ------------ | --------------- |
| 3ä¸ª    | 3-4.5å°æ—¶ | 4.5-7.5å°æ—¶  | âœ… æ¨è         |
| 5ä¸ª    | 5-7.5å°æ—¶ | 7.5-12.5å°æ—¶ | âš ï¸ å¯èƒ½è¶…æ—¶   |
| 8ä¸ª    | 8-12å°æ—¶  | 12-20å°æ—¶    | âŒ å¿…è¶…æ—¶ï¼Œåˆ†æ‰¹ |

**å»ºè®®**ï¼šæ¯ä¸ª Notebook è¿è¡Œ 3-5 ä¸ªå®éªŒ

---

## âš ï¸ å¸¸è§é—®é¢˜

### 1. CUDA out of memory

```python
# å‡å°batch_size
batch_size: 8  # æˆ– 4

# æˆ–å‡å°LSTM
lstm_hidden: 128
lstm_layers: 1
```

### 2. æ‰¾ä¸åˆ°æ•°æ®é›†

```bash
# æ£€æŸ¥è·¯å¾„
ls /kaggle/input/
ls /kaggle/input/mcm-ner-training/

# è°ƒæ•´è·¯å¾„
'data_dir': Path('/kaggle/input/mcm-ner-training/data/MNER/twitter2015'),
'image_dir': Path('/kaggle/input/mcm-ner-training/data/img'),
```

### 3. torchcrf å¯¼å…¥å¤±è´¥

```python
!pip install torchcrf
```

### 4. æ¨¡å‹æœªä¿å­˜

```python
# ç¡®ä¿ç›®å½•å­˜åœ¨
!mkdir -p /kaggle/working

# æ£€æŸ¥ä¿å­˜è·¯å¾„
ls /kaggle/working/*.pt
```

---

## ğŸ“ˆ é¢„æœŸç»“æœ

### Twitter2015 MNERåŸºå‡†

- Token Micro F1: 60-70%
- **Span F1: 55-65%** â­ (ä¸»è¦æŒ‡æ ‡)
- æœ€ä½³é…ç½®é€šå¸¸åœ¨ Epoch 15-20 è¾¾åˆ°

### æœ€ä½³é…ç½®ç»éªŒå€¼

```python
{
    "learning_rate": 1e-5,
    "lstm_lr": 1e-4,
    "crf_lr": 1e-3,
    "lstm_hidden": 256,
    "lstm_layers": 2,
    "batch_size": 16,
    "dropout": 0.3,
    "num_epochs": 20
}
```

---

## ğŸ¯ å¿«é€Ÿæ£€æŸ¥æ¸…å•

### ä¸Šä¼ å‰

- [ ] æ•°æ®å®Œæ•´ (`data/MNER/twitter2015/`, `data/img/`)
- [ ] é¢„è®­ç»ƒæ¨¡å‹ (`downloaded_model/deberta-v3-base/`)
- [ ] é¡¹ç›®æ–‡ä»¶ (`tests/`, `datasets/`, `models/`)

### Kaggleé…ç½®

- [ ] GPU P100 æˆ– T4
- [ ] æ•°æ®é›†å·²æ·»åŠ 
- [ ] Internetå¼€å¯ï¼ˆå¦‚éœ€ä¸‹è½½åŒ…ï¼‰

### è¿è¡Œä¸­

- [ ] Cell 1: é¡¹ç›®è·¯å¾„æ­£ç¡®
- [ ] Cell 2: ä¾èµ–å®‰è£…æˆåŠŸ
- [ ] Cell 3: GPUå¯ç”¨
- [ ] Cell 4: è¶…å‚æ•°å·²é…ç½®
- [ ] Cell 6: å®éªŒè¿è¡Œä¸­

### å®Œæˆå

- [ ] Cell 7: ç»“æœåˆ†æ
- [ ] Cell 8: å¯è§†åŒ–
- [ ] Cell 9: ä¸‹è½½ zip
- [ ] åœæ­¢ Session

---

## ğŸš€ è¿›é˜¶ç©æ³•

### 1. Grid Searchï¼ˆç½‘æ ¼æœç´¢ï¼‰

```python
import itertools

# å®šä¹‰æœç´¢ç©ºé—´
lr_space = [5e-6, 1e-5, 2e-5]
lstm_hidden_space = [128, 256, 512]
dropout_space = [0.1, 0.3, 0.5]

# ç”Ÿæˆæ‰€æœ‰ç»„åˆ
configs = []
for lr, hidden, dropout in itertools.product(
    lr_space, lstm_hidden_space, dropout_space
):
    configs.append({
        'learning_rate': lr,
        'lstm_hidden': hidden,
        'dropout': dropout,
        # ... å…¶ä»–å›ºå®šå‚æ•°
    })

print(f"æ€»å…± {len(configs)} ä¸ªç»„åˆ")
```

### 2. Random Searchï¼ˆéšæœºæœç´¢ï¼‰

```python
import random

def sample_config():
    return {
        'learning_rate': random.choice([5e-6, 1e-5, 2e-5, 5e-5]),
        'lstm_lr': random.choice([5e-5, 1e-4, 2e-4]),
        'lstm_hidden': random.choice([128, 256, 384, 512]),
        'dropout': random.uniform(0.1, 0.5),
        # ...
    }

configs = [sample_config() for _ in range(10)]
```

### 3. æ—©åœï¼ˆEarly Stoppingï¼‰

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
patience = 3
no_improve_epochs = 0

for epoch in range(1, num_epochs + 1):
    # ... è®­ç»ƒå’ŒéªŒè¯ ...
  
    if dev_f1 > best_f1:
        best_f1 = dev_f1
        no_improve_epochs = 0
    else:
        no_improve_epochs += 1
  
    if no_improve_epochs >= patience:
        print(f"Early stopping at epoch {epoch}")
        break
```

---

Good luck with your NER experiments! ğŸ¯

éœ€è¦å¸®åŠ©ï¼Ÿæ£€æŸ¥æ—¥å¿—è¾“å‡ºæˆ–å‚è€ƒä¸»é¡¹ç›®çš„ `tests/simple_ner_training.py`
