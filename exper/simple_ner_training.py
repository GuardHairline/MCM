#!/usr/bin/env python3
"""
å®Œæ•´çš„ç‹¬ç«‹NERè®­ç»ƒè„šæœ¬
========================================
ä»æ•°æ®è¯»å–ã€æ¨¡å‹æ„å»ºã€è®­ç»ƒåˆ°éªŒè¯çš„å®Œæ•´è¿‡ç¨‹

ä½¿ç”¨ï¼š
    python tests/simple_ner_training.py

æ¶æ„ï¼š
    DeBERTa-v3-base â†’ BiLSTM â†’ CRF
"""

import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup
from tqdm import tqdm
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
from datasets.mner_dataset import MNERDataset

from torchcrf import CRF


# ============================================================================
# 1. æ¨¡å‹å®šä¹‰
# ============================================================================

class SimpleNERModel(nn.Module):
    """
    ç®€å•çš„NERæ¨¡å‹ï¼šDeBERTa â†’ BiLSTM â†’ CRF
    
    æ¶æ„:
        - Text Encoder: DeBERTa-v3-base (768d)
        - Sequence Layer: BiLSTM (256 hidden Ã— 2 directions = 512d)
        - Output Layer: Linear (512 â†’ num_labels)
        - CRF Layer: å…¨å±€åºåˆ—ä¼˜åŒ–
    """
    
    def __init__(
        self,
        text_encoder_name: str = "microsoft/deberta-v3-base",
        num_labels: int = 9,
        lstm_hidden: int = 256,
        lstm_layers: int = 2,
        dropout: float = 0.3,
        use_crf: bool = True
    ):
        super().__init__()
        
        self.num_labels = num_labels
        self.use_crf = use_crf
        
        # Text encoder
        if text_encoder_name == "microsoft/deberta-v3-base":
            model_path = PROJECT_ROOT / "downloaded_model/deberta-v3-base"
            if not model_path.exists():
                print(f"âš ï¸ æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å‹: {text_encoder_name}")
                model_path = text_encoder_name
        else:
            model_path = text_encoder_name
        
        self.text_encoder = AutoModel.from_pretrained(model_path)
        encoder_dim = self.text_encoder.config.hidden_size  # 768
        
        # BiLSTM layer
        self.dropout = nn.Dropout(dropout)
        self.bilstm = nn.LSTM(
            input_size=encoder_dim,
            hidden_size=lstm_hidden,
            num_layers=lstm_layers,
            batch_first=True,
            bidirectional=True,
            dropout=dropout if lstm_layers > 1 else 0.0
        )
        
        # Classifier
        lstm_output_dim = lstm_hidden * 2  # åŒå‘
        self.classifier = nn.Linear(lstm_output_dim, num_labels)
        
        # CRF layer
        if use_crf:
            self.crf = CRF(num_labels, batch_first=True)
            print("âœ“ ä½¿ç”¨CRFå±‚")
        else:
            self.crf = None
            print("âœ“ ä¸ä½¿ç”¨CRFå±‚")
    
    def forward(self, input_ids, attention_mask, labels=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            input_ids: [batch, seq_len]
            attention_mask: [batch, seq_len]
            labels: [batch, seq_len] (å¯é€‰ï¼Œè®­ç»ƒæ—¶æä¾›)
        
        Returns:
            è®­ç»ƒæ—¶: (loss, logits)
            æ¨ç†æ—¶: logits
        """
        # 1. Text encoding
        text_output = self.text_encoder(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        text_features = text_output.last_hidden_state  # [batch, seq_len, 768]
        
        # 2. Dropout
        text_features = self.dropout(text_features)
        
        # 3. BiLSTM
        lengths = attention_mask.sum(dim=1).cpu()
        packed = nn.utils.rnn.pack_padded_sequence(
            text_features, lengths, batch_first=True, enforce_sorted=False
        )
        packed_output, _ = self.bilstm(packed)
        lstm_output, _ = nn.utils.rnn.pad_packed_sequence(
            packed_output, batch_first=True
        )
        lstm_output = self.dropout(lstm_output)  # [batch, seq_len, 512]
        
        # 4. Classifier
        logits = self.classifier(lstm_output)  # [batch, seq_len, num_labels]
        
        # 5. CRF (if training)
        if labels is not None:
            if self.use_crf:
                # CRF loss
                loss = self._compute_crf_loss(logits, labels, attention_mask)
                return loss, logits
            else:
                # Cross-entropy loss
                loss_fct = nn.CrossEntropyLoss(ignore_index=-100)
                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
                return loss, logits
        else:
            return logits
    
    def _compute_crf_loss(self, logits, labels, attention_mask):
        """è®¡ç®—CRF loss"""
        batch_size = logits.size(0)
        total_loss = 0.0
        valid_samples = 0
        
        for i in range(batch_size):
            # æ‰¾åˆ°æœ‰æ•ˆtokenï¼ˆlabel != -100ï¼‰
            valid_mask = (labels[i] != -100)
            if valid_mask.any():
                valid_indices = valid_mask.nonzero(as_tuple=True)[0]
                start_idx = valid_indices[0].item()
                end_idx = valid_indices[-1].item() + 1
                
                # æå–æœ‰æ•ˆèŒƒå›´
                sample_logits = logits[i:i+1, start_idx:end_idx, :]
                sample_labels = labels[i:i+1, start_idx:end_idx]
                sample_mask = torch.ones(
                    1, end_idx - start_idx, 
                    dtype=torch.bool, 
                    device=logits.device
                )
                
                # CRF forwardè¿”å›log likelihood
                log_likelihood = self.crf(
                    sample_logits, sample_labels, 
                    mask=sample_mask, reduction='sum'
                )
                total_loss += -log_likelihood  # è½¬æ¢ä¸ºNLL
                valid_samples += 1
        
        return total_loss / valid_samples if valid_samples > 0 else torch.tensor(0.0)
    
    def decode(self, input_ids, attention_mask):
        """
        Viterbiè§£ç ï¼ˆä½¿ç”¨CRFï¼‰æˆ–argmaxè§£ç 
        
        Returns:
            predictions: [batch, seq_len]
        """
        logits = self.forward(input_ids, attention_mask)
        
        if self.use_crf:
            # Viterbiè§£ç 
            batch_size, seq_len = input_ids.size()
            predictions = torch.zeros(batch_size, seq_len, dtype=torch.long, device=logits.device)
            
            for i in range(batch_size):
                valid_length = int(attention_mask[i].sum().item())
                if valid_length > 2:
                    # è·³è¿‡[CLS]å’Œ[SEP]
                    start_idx = 1
                    end_idx = valid_length - 1
                    
                    sample_logits = logits[i:i+1, start_idx:end_idx, :]
                    sample_mask = torch.ones(1, end_idx - start_idx, dtype=torch.bool, device=logits.device)
                    
                    preds = self.crf.decode(sample_logits, mask=sample_mask)[0]
                    predictions[i, start_idx:end_idx] = torch.tensor(preds, device=logits.device)
                else:
                    predictions[i] = torch.argmax(logits[i], dim=-1)
        else:
            # Argmaxè§£ç 
            predictions = torch.argmax(logits, dim=-1)
        
        return predictions


# ============================================================================
# 2. è¯„ä¼°æŒ‡æ ‡
# ============================================================================

def extract_entities(labels, label_names=None):
    """
    ä»æ ‡ç­¾åºåˆ—ä¸­æå–å®ä½“span
    
    Args:
        labels: [seq_len] - æ ‡ç­¾åºåˆ—
        label_names: æ ‡ç­¾åç§°åˆ—è¡¨
    
    Returns:
        list of tuples: [(start, end, entity_type), ...]
    """
    if label_names is None:
        label_names = ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", 
                       "B-LOC", "I-LOC", "B-MISC", "I-MISC"]
    
    entities = []
    current_entity = None
    
    for i, label_id in enumerate(labels):
        if label_id == -100:  # è·³è¿‡padding
            continue
        
        label_name = label_names[label_id] if label_id < len(label_names) else "O"
        
        if label_name.startswith("B-"):
            # å¼€å§‹æ–°å®ä½“
            if current_entity is not None:
                entities.append(current_entity)
            entity_type = label_name[2:]  # å»æ‰B-
            current_entity = (i, i, entity_type)
        elif label_name.startswith("I-"):
            # ç»§ç»­å½“å‰å®ä½“
            if current_entity is not None:
                entity_type = label_name[2:]
                if current_entity[2] == entity_type:
                    current_entity = (current_entity[0], i, entity_type)
                else:
                    # ç±»å‹ä¸åŒ¹é…ï¼Œç»“æŸå½“å‰å®ä½“ï¼Œå¼€å§‹æ–°å®ä½“
                    entities.append(current_entity)
                    current_entity = (i, i, entity_type)
            else:
                # I-æ ‡ç­¾ä½†æ²¡æœ‰B-å¼€å¤´ï¼Œå½“ä½œæ–°å®ä½“
                entity_type = label_name[2:]
                current_entity = (i, i, entity_type)
        else:
            # Oæ ‡ç­¾ï¼Œç»“æŸå½“å‰å®ä½“
            if current_entity is not None:
                entities.append(current_entity)
                current_entity = None
    
    # æ·»åŠ æœ€åä¸€ä¸ªå®ä½“
    if current_entity is not None:
        entities.append(current_entity)
    
    return entities


def compute_span_f1(pred_entities, true_entities):
    """
    è®¡ç®—Span-level F1
    
    Args:
        pred_entities: list of (start, end, type)
        true_entities: list of (start, end, type)
    
    Returns:
        dict: precision, recall, f1
    """
    pred_set = set(pred_entities)
    true_set = set(true_entities)
    
    tp = len(pred_set & true_set)
    fp = len(pred_set - true_set)
    fn = len(true_set - pred_set)
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'tp': tp,
        'fp': fp,
        'fn': fn
    }


def compute_f1_metrics(predictions, labels, num_labels=9):
    """
    è®¡ç®—NERçš„F1æŒ‡æ ‡ï¼ˆToken-levelï¼‰
    
    Args:
        predictions: [total_tokens] - é¢„æµ‹æ ‡ç­¾
        labels: [total_tokens] - çœŸå®æ ‡ç­¾
        num_labels: æ ‡ç­¾æ•°é‡ï¼ˆåŒ…æ‹¬Oï¼‰
    
    Returns:
        dict: åŒ…å«å„ç±»F1å’Œå¹³å‡F1
    """
    # æ ‡ç­¾åç§°
    label_names = [
        "O",        # 0
        "B-PER", "I-PER",   # 1, 2
        "B-ORG", "I-ORG",   # 3, 4
        "B-LOC", "I-LOC",   # 5, 6
        "B-MISC", "I-MISC"  # 7, 8
    ]
    
    # è¿‡æ»¤æ‰paddingï¼ˆ-100ï¼‰
    valid_mask = labels != -100
    predictions = predictions[valid_mask]
    labels = labels[valid_mask]
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„precision, recall, F1
    per_class_metrics = {}
    
    for label_id in range(num_labels):
        if label_id == 0:  # è·³è¿‡Oæ ‡ç­¾
            continue
        
        label_name = label_names[label_id] if label_id < len(label_names) else f"Label-{label_id}"
        
        # TP, FP, FN
        tp = ((predictions == label_id) & (labels == label_id)).sum().item()
        fp = ((predictions == label_id) & (labels != label_id)).sum().item()
        fn = ((predictions != label_id) & (labels == label_id)).sum().item()
        
        # Precision, Recall, F1
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        
        per_class_metrics[label_name] = {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'support': (labels == label_id).sum().item()
        }
    
    # Micro F1 (ä¸åŒ…æ‹¬O) - æ­£ç¡®è®¡ç®—
    entity_label_ids = [i for i in range(1, num_labels)]
    
    # åˆ¤æ–­å“ªäº›ä½ç½®é¢„æµ‹ä¸ºå®ä½“ã€çœŸå®ä¸ºå®ä½“
    is_pred_entity = torch.isin(predictions, torch.tensor(entity_label_ids, device=predictions.device))
    is_true_entity = torch.isin(labels, torch.tensor(entity_label_ids, device=labels.device))
    
    # è®¡ç®— TP, FP, FN
    tp = ((is_pred_entity) & (is_true_entity) & (predictions == labels)).sum().item()
    fp = ((is_pred_entity) & ((~is_true_entity) | (predictions != labels))).sum().item()
    fn = ((is_true_entity) & ((~is_pred_entity) | (predictions != labels))).sum().item()
    
    # è®¡ç®— Precision, Recall, F1
    micro_precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    micro_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0.0
    
    # Macro F1 (ä¸åŒ…æ‹¬O)
    f1_scores = [metrics['f1'] for metrics in per_class_metrics.values()]
    macro_f1 = np.mean(f1_scores) if f1_scores else 0.0
    
    return {
        'micro_precision': micro_precision,
        'micro_recall': micro_recall,
        'micro_f1': micro_f1,
        'macro_f1': macro_f1,
        'per_class': per_class_metrics
    }


# ============================================================================
# 3. è®­ç»ƒå’ŒéªŒè¯
# ============================================================================

def train_epoch(model, dataloader, optimizer, scheduler, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    progress_bar = tqdm(dataloader, desc=f"Epoch {epoch} [Train]")
    
    for batch in progress_bar:
        # æ•°æ®ç§»åˆ°device
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        
        # å‰å‘ä¼ æ’­
        loss, logits = model(input_ids, attention_mask, labels)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()
        
        # è®°å½•
        total_loss += loss.item()
        progress_bar.set_postfix({
            'loss': f"{loss.item():.4f}",
            'avg_loss': f"{total_loss / (progress_bar.n + 1):.4f}"
        })
    
    avg_loss = total_loss / len(dataloader)
    return avg_loss


def evaluate(model, dataloader, device, split_name="Val"):
    """è¯„ä¼°æ¨¡å‹ï¼ˆåŒæ—¶è®¡ç®—Token-levelå’ŒSpan-level F1ï¼‰"""
    model.eval()
    all_predictions = []
    all_labels = []
    all_predictions_2d = []  # ä¿æŒ2Dç»“æ„ç”¨äºspanè¯„ä¼°
    all_labels_2d = []
    total_loss = 0.0
    
    progress_bar = tqdm(dataloader, desc=f"{split_name}")
    
    with torch.no_grad():
        for batch in progress_bar:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            # å‰å‘ä¼ æ’­
            loss, logits = model(input_ids, attention_mask, labels)
            total_loss += loss.item()
            
            # è§£ç 
            if model.use_crf:
                predictions = model.decode(input_ids, attention_mask)
            else:
                predictions = torch.argmax(logits, dim=-1)
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾ï¼ˆflattenç”¨äºtoken-levelï¼‰
            all_predictions.append(predictions.cpu())
            all_labels.append(labels.cpu())
            
            # ä¿æŒ2Dç»“æ„ç”¨äºspan-levelè¯„ä¼°
            all_predictions_2d.append(predictions.cpu())
            all_labels_2d.append(labels.cpu())
    
    # æ‹¼æ¥æ‰€æœ‰batchï¼ˆ1D for token-levelï¼‰
    all_predictions_flat = torch.cat(all_predictions, dim=0).flatten()
    all_labels_flat = torch.cat(all_labels, dim=0).flatten()
    
    # è®¡ç®—Token-level F1
    token_metrics = compute_f1_metrics(all_predictions_flat, all_labels_flat)
    
    # è®¡ç®—Span-level F1
    all_pred_entities = []
    all_true_entities = []
    
    for preds, labels in zip(all_predictions_2d, all_labels_2d):
        for pred_seq, label_seq in zip(preds, labels):
            pred_entities = extract_entities(pred_seq.tolist())
            true_entities = extract_entities(label_seq.tolist())
            all_pred_entities.extend(pred_entities)
            all_true_entities.extend(true_entities)
    
    span_metrics = compute_span_f1(all_pred_entities, all_true_entities)
    
    # åˆå¹¶æŒ‡æ ‡
    metrics = {
        'token_micro_precision': token_metrics['micro_precision'],
        'token_micro_recall': token_metrics['micro_recall'],
        'token_micro_f1': token_metrics['micro_f1'],
        'token_macro_f1': token_metrics['macro_f1'],
        'span_precision': span_metrics['precision'],
        'span_recall': span_metrics['recall'],
        'span_f1': span_metrics['f1'],
        'per_class': token_metrics['per_class']
    }
    
    avg_loss = total_loss / len(dataloader)
    
    return avg_loss, metrics


# ============================================================================
# 4. ä¸»è®­ç»ƒæµç¨‹
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ç®€å•NERè®­ç»ƒè„šæœ¬")
    print("=" * 80)
    
    # ========================================
    # é…ç½®
    # ========================================
    CONFIG = {
        # æ•°æ®
        'data_dir': PROJECT_ROOT / 'data/MNER/twitter2015',
        'image_dir': PROJECT_ROOT / 'data/img',
        'train_file': 'train.txt',
        'dev_file': 'dev.txt',
        'test_file': 'test.txt',
        
        # æ¨¡å‹
        'text_encoder': 'microsoft/deberta-v3-base',
        'num_labels': 9,
        'lstm_hidden': 256,
        'lstm_layers': 2,
        'dropout': 0.3,
        'use_crf': True,
        
        # è®­ç»ƒ
        'batch_size': 16,
        'num_epochs': 20,
        'learning_rate': 1e-5,
        'lstm_lr': 1e-4,
        'crf_lr': 1e-3,
        'weight_decay': 0.01,
        'warmup_ratio': 0.1,
        'max_seq_length': 128,
        
        # å…¶ä»–
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
        'seed': 42
    }
    
    print("\nğŸ“‹ é…ç½®:")
    for key, value in CONFIG.items():
        print(f"  {key}: {value}")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(CONFIG['seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(CONFIG['seed'])
    
    # ========================================
    # 1. æ•°æ®åŠ è½½
    # ========================================
    print("\n" + "=" * 80)
    print("ğŸ“‚ 1. æ•°æ®åŠ è½½")
    print("=" * 80)
    
    # è®­ç»ƒé›†
    train_dataset = MNERDataset(
        text_file=str(CONFIG['data_dir'] / CONFIG['train_file']),
        image_dir=str(CONFIG['image_dir']),
        tokenizer_name=CONFIG['text_encoder'],
        max_seq_length=CONFIG['max_seq_length']
    )
    train_loader = DataLoader(
        train_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=True,
        num_workers=0  # Windowsä¸‹è®¾ä¸º0
    )
    print(f"âœ“ è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    
    # éªŒè¯é›†
    dev_dataset = MNERDataset(
        text_file=str(CONFIG['data_dir'] / CONFIG['dev_file']),
        image_dir=str(CONFIG['image_dir']),
        tokenizer_name=CONFIG['text_encoder'],
        max_seq_length=CONFIG['max_seq_length']
    )
    dev_loader = DataLoader(
        dev_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=False,
        num_workers=0
    )
    print(f"âœ“ éªŒè¯é›†: {len(dev_dataset)} æ ·æœ¬")
    
    # æµ‹è¯•é›†
    test_dataset = MNERDataset(
        text_file=str(CONFIG['data_dir'] / CONFIG['test_file']),
        image_dir=str(CONFIG['image_dir']),
        tokenizer_name=CONFIG['text_encoder'],
        max_seq_length=CONFIG['max_seq_length']
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=False,
        num_workers=0
    )
    print(f"âœ“ æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    
    # ========================================
    # 2. æ¨¡å‹æ„å»º
    # ========================================
    print("\n" + "=" * 80)
    print("ğŸ—ï¸ 2. æ¨¡å‹æ„å»º")
    print("=" * 80)
    
    model = SimpleNERModel(
        text_encoder_name=CONFIG['text_encoder'],
        num_labels=CONFIG['num_labels'],
        lstm_hidden=CONFIG['lstm_hidden'],
        lstm_layers=CONFIG['lstm_layers'],
        dropout=CONFIG['dropout'],
        use_crf=CONFIG['use_crf']
    )
    model = model.to(CONFIG['device'])
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\nâœ“ æ€»å‚æ•°: {total_params:,}")
    print(f"âœ“ å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # ========================================
    # 3. ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    # ========================================
    print("\n" + "=" * 80)
    print("âš™ï¸ 3. ä¼˜åŒ–å™¨é…ç½®")
    print("=" * 80)
    
    # åˆ†å±‚å­¦ä¹ ç‡ï¼ˆå…³é”®ï¼ï¼‰
    optimizer_grouped_parameters = [
        # DeBERTa (ä½å­¦ä¹ ç‡)
        {
            'params': model.text_encoder.parameters(),
            'lr': CONFIG['learning_rate'],
            'weight_decay': CONFIG['weight_decay']
        },
        # BiLSTM (ä¸­å­¦ä¹ ç‡)
        {
            'params': model.bilstm.parameters(),
            'lr': CONFIG['lstm_lr'],
            'weight_decay': CONFIG['weight_decay']
        },
        # Classifier (ä¸­å­¦ä¹ ç‡)
        {
            'params': model.classifier.parameters(),
            'lr': CONFIG['lstm_lr'],
            'weight_decay': CONFIG['weight_decay']
        }
    ]
    
    # CRF (é«˜å­¦ä¹ ç‡)
    if CONFIG['use_crf']:
        optimizer_grouped_parameters.append({
            'params': model.crf.parameters(),
            'lr': CONFIG['crf_lr'],
            'weight_decay': 0.0  # CRFä¸ä½¿ç”¨weight decay
        })
    
    optimizer = torch.optim.AdamW(optimizer_grouped_parameters)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    total_steps = len(train_loader) * CONFIG['num_epochs']
    warmup_steps = int(total_steps * CONFIG['warmup_ratio'])
    
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=warmup_steps,
        num_training_steps=total_steps
    )
    
    print(f"âœ“ ä¼˜åŒ–å™¨: AdamW")
    print(f"âœ“ DeBERTa LR: {CONFIG['learning_rate']}")
    print(f"âœ“ BiLSTM LR: {CONFIG['lstm_lr']}")
    print(f"âœ“ CRF LR: {CONFIG['crf_lr']}")
    print(f"âœ“ æ€»æ­¥æ•°: {total_steps:,}")
    print(f"âœ“ é¢„çƒ­æ­¥æ•°: {warmup_steps:,}")
    
    # ========================================
    # 4. è®­ç»ƒå¾ªç¯
    # ========================================
    print("\n" + "=" * 80)
    print("ğŸš€ 4. å¼€å§‹è®­ç»ƒ")
    print("=" * 80)
    
    best_dev_f1 = 0.0
    best_epoch = 0
    
    for epoch in range(1, CONFIG['num_epochs'] + 1):
        print(f"\n{'=' * 80}")
        print(f"Epoch {epoch}/{CONFIG['num_epochs']}")
        print(f"{'=' * 80}")
        
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, scheduler, CONFIG['device'], epoch)
        print(f"\nâœ“ è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        
        # éªŒè¯
        dev_loss, dev_metrics = evaluate(model, dev_loader, CONFIG['device'], "Dev")
        print(f"\nâœ“ éªŒè¯æŸå¤±: {dev_loss:.4f}")
        print(f"\nã€Token-levelã€‘")
        print(f"  Precision: {dev_metrics['token_micro_precision']:.2%}")
        print(f"  Recall: {dev_metrics['token_micro_recall']:.2%}")
        print(f"  Micro F1: {dev_metrics['token_micro_f1']:.2%}")
        print(f"\nã€Span-levelã€‘")
        print(f"  Precision: {dev_metrics['span_precision']:.2%}")
        print(f"  Recall: {dev_metrics['span_recall']:.2%}")
        print(f"  F1: {dev_metrics['span_f1']:.2%} â­")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆä»¥span F1ä¸ºå‡†ï¼‰
        if dev_metrics['span_f1'] > best_dev_f1:
            best_dev_f1 = dev_metrics['span_f1']
            best_epoch = epoch
            
            # ä¿å­˜æ¨¡å‹
            save_path = PROJECT_ROOT / 'tests/best_ner_model.pt'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'dev_f1': best_dev_f1,
                'config': CONFIG
            }, save_path)
            print(f"\nâœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (F1={best_dev_f1:.2%}) -> {save_path}")
    
    # ========================================
    # 5. æµ‹è¯•
    # ========================================
    print("\n" + "=" * 80)
    print("ğŸ§ª 5. æµ‹è¯•é›†è¯„ä¼°")
    print("=" * 80)
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    checkpoint = torch.load(PROJECT_ROOT / 'tests/best_ner_model.pt')
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ“ åŠ è½½æœ€ä½³æ¨¡å‹ (Epoch {checkpoint['epoch']})")
    
    # æµ‹è¯•
    test_loss, test_metrics = evaluate(model, test_loader, CONFIG['device'], "Test")
    
    print(f"\n{'=' * 80}")
    print("ğŸ“Š æœ€ç»ˆç»“æœ")
    print(f"{'=' * 80}")
    print(f"Best Epoch: {best_epoch}")
    print(f"Dev Span F1: {best_dev_f1:.2%}")
    print(f"\nTest Loss: {test_loss:.4f}")
    print(f"\nã€Token-level æŒ‡æ ‡ã€‘")
    print(f"  Precision: {test_metrics['token_micro_precision']:.2%}")
    print(f"  Recall: {test_metrics['token_micro_recall']:.2%}")
    print(f"  Micro F1 (no O): {test_metrics['token_micro_f1']:.2%}")
    print(f"  Macro F1: {test_metrics['token_macro_f1']:.2%}")
    print(f"\nã€Span-level æŒ‡æ ‡ã€‘â­")
    print(f"  Precision: {test_metrics['span_precision']:.2%}")
    print(f"  Recall: {test_metrics['span_recall']:.2%}")
    print(f"  F1: {test_metrics['span_f1']:.2%}")
    
    print(f"\n{'=' * 80}")
    print("ğŸ“ˆ å„ç±»åˆ«F1:")
    print(f"{'=' * 80}")
    for label_name, metrics in test_metrics['per_class'].items():
        print(f"{label_name:10s}: P={metrics['precision']:.2%}, R={metrics['recall']:.2%}, "
              f"F1={metrics['f1']:.2%}, Support={metrics['support']}")
    
    print(f"\n{'=' * 80}")
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print(f"{'=' * 80}\n")


def test_entity_extraction():
    """æµ‹è¯•å®ä½“æå–çš„å‡†ç¡®æ€§ï¼ˆä½¿ç”¨æ˜ç¡®çš„æµ‹è¯•ç”¨ä¾‹ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: å®ä½“æå–")
    print("=" * 80)
    
    # æµ‹è¯•ç”¨ä¾‹1: æ­£å¸¸çš„B-Iåºåˆ—
    print("\n[æµ‹è¯•1] æ­£å¸¸çš„B-Iåºåˆ—")
    labels1 = [0, 1, 2, 0, 3, 4, 0]  # O, B-PER, I-PER, O, B-ORG, I-ORG, O
    entities1 = extract_entities(labels1)
    expected1 = [(1, 2, 'PER'), (4, 5, 'ORG')]
    assert entities1 == expected1, f"âŒ å¤±è´¥: {entities1} != {expected1}"
    print(f"  âœ“ æå–å®ä½“: {entities1}")
    print(f"  âœ“ é¢„æœŸå®ä½“: {expected1}")
    
    # æµ‹è¯•ç”¨ä¾‹2: åŒ…å«padding (-100)
    print("\n[æµ‹è¯•2] åŒ…å«paddingçš„åºåˆ—")
    labels2 = [-100, 1, 2, 0, -100, -100]  # [CLS], B-PER, I-PER, O, [SEP], [PAD]
    entities2 = extract_entities(labels2)
    expected2 = [(1, 2, 'PER')]
    assert entities2 == expected2, f"âŒ å¤±è´¥: {entities2} != {expected2}"
    print(f"  âœ“ æ­£ç¡®å¿½ç•¥padding (-100)")
    print(f"  âœ“ æå–å®ä½“: {entities2}")
    
    # æµ‹è¯•ç”¨ä¾‹3: è¿ç»­å¤šä¸ªå®ä½“
    print("\n[æµ‹è¯•3] è¿ç»­å¤šä¸ªå®ä½“ï¼ˆæ— Oé—´éš”ï¼‰")
    labels3 = [1, 2, 3, 4, 5, 6]  # B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC
    entities3 = extract_entities(labels3)
    expected3 = [(0, 1, 'PER'), (2, 3, 'ORG'), (4, 5, 'LOC')]
    assert entities3 == expected3, f"âŒ å¤±è´¥: {entities3} != {expected3}"
    print(f"  âœ“ æå–å®ä½“: {entities3}")
    
    # æµ‹è¯•ç”¨ä¾‹4: ä¸å®Œæ•´åºåˆ—ï¼ˆåªæœ‰Iæ²¡æœ‰Bï¼‰
    print("\n[æµ‹è¯•4] ä¸å®Œæ•´åºåˆ—ï¼ˆIæ ‡ç­¾ä½†æ— Bå¼€å¤´ï¼‰")
    labels4 = [0, 2, 0]  # O, I-PER, O (ç¼ºå°‘B-PER)
    entities4 = extract_entities(labels4)
    expected4 = [(1, 1, 'PER')]  # åº”è¯¥å½“ä½œæ–°å®ä½“
    assert entities4 == expected4, f"âŒ å¤±è´¥: {entities4} != {expected4}"
    print(f"  âœ“ æ­£ç¡®å¤„ç†å­¤ç«‹çš„Iæ ‡ç­¾: {entities4}")
    
    # æµ‹è¯•ç”¨ä¾‹5: ç±»å‹ä¸åŒ¹é…ï¼ˆB-PERåæ¥I-ORGï¼‰
    print("\n[æµ‹è¯•5] ç±»å‹ä¸åŒ¹é…ï¼ˆB-PER + I-ORGï¼‰")
    labels5 = [1, 4, 0]  # B-PER, I-ORG, O
    entities5 = extract_entities(labels5)
    expected5 = [(0, 0, 'PER'), (1, 1, 'ORG')]  # åº”è¯¥æ‹†æˆä¸¤ä¸ªå®ä½“
    assert entities5 == expected5, f"âŒ å¤±è´¥: {entities5} != {expected5}"
    print(f"  âœ“ æ­£ç¡®å¤„ç†ç±»å‹ä¸åŒ¹é…: {entities5}")
    
    print("\nâœ… æ‰€æœ‰å®ä½“æå–æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_span_f1_calculation():
    """æµ‹è¯•Span-level F1è®¡ç®—çš„å‡†ç¡®æ€§"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: Span-level F1è®¡ç®—")
    print("=" * 80)
    
    # æµ‹è¯•ç”¨ä¾‹1: å®Œå…¨åŒ¹é…
    print("\n[æµ‹è¯•1] å®Œå…¨åŒ¹é…ï¼ˆ100% F1ï¼‰")
    pred1 = [(0, 1, 'PER'), (3, 4, 'ORG')]
    true1 = [(0, 1, 'PER'), (3, 4, 'ORG')]
    result1 = compute_span_f1(pred1, true1)
    assert result1['precision'] == 1.0, f"âŒ Precisioné”™è¯¯: {result1['precision']}"
    assert result1['recall'] == 1.0, f"âŒ Recallé”™è¯¯: {result1['recall']}"
    assert result1['f1'] == 1.0, f"âŒ F1é”™è¯¯: {result1['f1']}"
    print(f"  âœ“ P={result1['precision']:.2%}, R={result1['recall']:.2%}, F1={result1['f1']:.2%}")
    
    # æµ‹è¯•ç”¨ä¾‹2: å®Œå…¨ä¸åŒ¹é…
    print("\n[æµ‹è¯•2] å®Œå…¨ä¸åŒ¹é…ï¼ˆ0% F1ï¼‰")
    pred2 = [(0, 1, 'PER')]
    true2 = [(3, 4, 'ORG')]
    result2 = compute_span_f1(pred2, true2)
    assert result2['precision'] == 0.0, f"âŒ Precisioné”™è¯¯: {result2['precision']}"
    assert result2['recall'] == 0.0, f"âŒ Recallé”™è¯¯: {result2['recall']}"
    assert result2['f1'] == 0.0, f"âŒ F1é”™è¯¯: {result2['f1']}"
    print(f"  âœ“ P={result2['precision']:.2%}, R={result2['recall']:.2%}, F1={result2['f1']:.2%}")
    
    # æµ‹è¯•ç”¨ä¾‹3: è¾¹ç•Œé”™è¯¯
    print("\n[æµ‹è¯•3] è¾¹ç•Œé”™è¯¯ï¼ˆä½ç½®ä¸åŒï¼‰")
    pred3 = [(0, 1, 'PER')]  # é¢„æµ‹: token 0-1
    true3 = [(0, 2, 'PER')]  # çœŸå®: token 0-2ï¼ˆæ›´é•¿ï¼‰
    result3 = compute_span_f1(pred3, true3)
    assert result3['f1'] == 0.0, f"âŒ è¾¹ç•Œä¸åŒåº”è¯¥F1=0ï¼Œå®é™…: {result3['f1']}"
    print(f"  âœ“ è¾¹ç•Œä¸åŒï¼ŒF1=0%ï¼ˆä¸¥æ ¼åŒ¹é…ï¼‰")
    
    # æµ‹è¯•ç”¨ä¾‹4: ç±»å‹é”™è¯¯
    print("\n[æµ‹è¯•4] ç±»å‹é”™è¯¯ï¼ˆä½ç½®ç›¸åŒä½†ç±»å‹ä¸åŒï¼‰")
    pred4 = [(0, 1, 'PER')]
    true4 = [(0, 1, 'ORG')]  # ä½ç½®ç›¸åŒï¼Œç±»å‹ä¸åŒ
    result4 = compute_span_f1(pred4, true4)
    assert result4['f1'] == 0.0, f"âŒ ç±»å‹ä¸åŒåº”è¯¥F1=0ï¼Œå®é™…: {result4['f1']}"
    print(f"  âœ“ ç±»å‹ä¸åŒï¼ŒF1=0%ï¼ˆå¿…é¡»å®Œå…¨åŒ¹é…ï¼‰")
    
    # æµ‹è¯•ç”¨ä¾‹5: éƒ¨åˆ†åŒ¹é…ï¼ˆ2ä¸ªé¢„æµ‹ï¼Œ1ä¸ªæ­£ç¡®ï¼‰
    print("\n[æµ‹è¯•5] éƒ¨åˆ†åŒ¹é…ï¼ˆPrecision=50%, Recall=100%ï¼‰")
    pred5 = [(0, 1, 'PER'), (3, 4, 'ORG')]  # 2ä¸ªé¢„æµ‹
    true5 = [(0, 1, 'PER')]  # 1ä¸ªçœŸå®
    result5 = compute_span_f1(pred5, true5)
    expected_p = 0.5  # 1 TP / 2 pred
    expected_r = 1.0  # 1 TP / 1 true
    expected_f1 = 2 * expected_p * expected_r / (expected_p + expected_r)
    assert abs(result5['precision'] - expected_p) < 1e-6, f"âŒ Precisioné”™è¯¯"
    assert abs(result5['recall'] - expected_r) < 1e-6, f"âŒ Recallé”™è¯¯"
    assert abs(result5['f1'] - expected_f1) < 1e-6, f"âŒ F1é”™è¯¯"
    print(f"  âœ“ P={result5['precision']:.2%}, R={result5['recall']:.2%}, F1={result5['f1']:.2%}")
    
    # æµ‹è¯•ç”¨ä¾‹6: TP, FP, FNè®¡æ•°
    print("\n[æµ‹è¯•6] TP/FP/FNè®¡æ•°éªŒè¯")
    pred6 = [(0, 1, 'PER'), (3, 4, 'ORG'), (6, 7, 'LOC')]  # 3ä¸ªé¢„æµ‹
    true6 = [(0, 1, 'PER'), (3, 4, 'ORG')]  # 2ä¸ªçœŸå®
    result6 = compute_span_f1(pred6, true6)
    assert result6['tp'] == 2, f"âŒ TPåº”è¯¥=2ï¼Œå®é™…={result6['tp']}"
    assert result6['fp'] == 1, f"âŒ FPåº”è¯¥=1ï¼Œå®é™…={result6['fp']}"
    assert result6['fn'] == 0, f"âŒ FNåº”è¯¥=0ï¼Œå®é™…={result6['fn']}"
    print(f"  âœ“ TP={result6['tp']}, FP={result6['fp']}, FN={result6['fn']}")
    
    print("\nâœ… æ‰€æœ‰Span F1è®¡ç®—æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_token_f1_calculation():
    """æµ‹è¯•Token-level F1è®¡ç®—çš„å‡†ç¡®æ€§ï¼ˆä¿®å¤åçš„ç‰ˆæœ¬ï¼‰"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: Token-level F1è®¡ç®—")
    print("=" * 80)
    
    # æµ‹è¯•ç”¨ä¾‹1: å®Œç¾é¢„æµ‹ï¼ˆ100% F1ï¼‰
    print("\n[æµ‹è¯•1] å®Œç¾é¢„æµ‹ï¼ˆ100% F1ï¼‰")
    predictions = torch.tensor([0, 1, 2, 0, 0, 3, 4, 0])  # O, B-PER, I-PER, O, O, B-ORG, I-ORG, O
    labels = torch.tensor([0, 1, 2, 0, 0, 3, 4, 0])
    result1 = compute_f1_metrics(predictions, labels, num_labels=9)
    
    assert result1['micro_precision'] == 1.0, f"âŒ Precisioné”™è¯¯: {result1['micro_precision']}"
    assert result1['micro_recall'] == 1.0, f"âŒ Recallé”™è¯¯: {result1['micro_recall']}"
    assert result1['micro_f1'] == 1.0, f"âŒ F1é”™è¯¯: {result1['micro_f1']}"
    print(f"  âœ“ Precision={result1['micro_precision']:.2%}, Recall={result1['micro_recall']:.2%}, F1={result1['micro_f1']:.2%}")
    
    # æµ‹è¯•ç”¨ä¾‹2: å…¨éƒ¨é¢„æµ‹é”™è¯¯ï¼ˆ0% F1ï¼‰
    print("\n[æµ‹è¯•2] å…¨éƒ¨é¢„æµ‹é”™è¯¯ï¼ˆ0% F1ï¼‰")
    predictions2 = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0])  # å…¨éƒ¨é¢„æµ‹ä¸ºO
    labels2 = torch.tensor([0, 1, 2, 0, 0, 3, 4, 0])  # å®é™…æœ‰å®ä½“
    result2 = compute_f1_metrics(predictions2, labels2, num_labels=9)
    
    # æ²¡æœ‰é¢„æµ‹ä»»ä½•å®ä½“ï¼Œæ‰€ä»¥TP=0, FP=0, FN=4 (1,2,3,4)
    # Precision = 0/0 = 0, Recall = 0/4 = 0, F1 = 0
    assert result2['micro_precision'] == 0.0, f"âŒ Precisioné”™è¯¯: {result2['micro_precision']}"
    assert result2['micro_recall'] == 0.0, f"âŒ Recallé”™è¯¯: {result2['micro_recall']}"
    assert result2['micro_f1'] == 0.0, f"âŒ F1é”™è¯¯: {result2['micro_f1']}"
    print(f"  âœ“ Precision={result2['micro_precision']:.2%}, Recall={result2['micro_recall']:.2%}, F1={result2['micro_f1']:.2%}")
    
    # æµ‹è¯•ç”¨ä¾‹3: éƒ¨åˆ†æ­£ç¡®ï¼ˆ50% F1ï¼‰
    print("\n[æµ‹è¯•3] éƒ¨åˆ†æ­£ç¡®ï¼ˆè®¡ç®—å®é™…F1ï¼‰")
    # é¢„æµ‹: O, B-PER, I-PER, B-ORG, O, O, O, O
    # çœŸå®: O, B-PER, I-PER, O,     O, B-LOC, I-LOC, O
    predictions3 = torch.tensor([0, 1, 2, 3, 0, 0, 0, 0])
    labels3 = torch.tensor([0, 1, 2, 0, 0, 5, 6, 0])
    result3 = compute_f1_metrics(predictions3, labels3, num_labels=9)
    
    # TP: é¢„æµ‹=1ä¸”çœŸå®=1, é¢„æµ‹=2ä¸”çœŸå®=2 -> 2ä¸ª
    # FP: é¢„æµ‹=3ä½†çœŸå®=0 -> 1ä¸ª
    # FN: çœŸå®=5ä½†é¢„æµ‹=0, çœŸå®=6ä½†é¢„æµ‹=0 -> 2ä¸ª
    expected_p = 2 / (2 + 1)  # TP / (TP + FP) = 2/3 â‰ˆ 0.667
    expected_r = 2 / (2 + 2)  # TP / (TP + FN) = 2/4 = 0.5
    expected_f1 = 2 * expected_p * expected_r / (expected_p + expected_r)  # â‰ˆ 0.571
    
    assert abs(result3['micro_precision'] - expected_p) < 1e-6, f"âŒ Precisioné”™è¯¯: {result3['micro_precision']} != {expected_p}"
    assert abs(result3['micro_recall'] - expected_r) < 1e-6, f"âŒ Recallé”™è¯¯: {result3['micro_recall']} != {expected_r}"
    assert abs(result3['micro_f1'] - expected_f1) < 1e-6, f"âŒ F1é”™è¯¯: {result3['micro_f1']} != {expected_f1}"
    print(f"  âœ“ Precision={result3['micro_precision']:.2%}, Recall={result3['micro_recall']:.2%}, F1={result3['micro_f1']:.2%}")
    print(f"  âœ“ éªŒè¯: 2/(2+1)={expected_p:.3f}, 2/(2+2)={expected_r:.3f}, F1={expected_f1:.3f}")
    
    # æµ‹è¯•ç”¨ä¾‹4: åŒ…å«paddingï¼ˆåº”è¯¥è¢«å¿½ç•¥ï¼‰
    print("\n[æµ‹è¯•4] åŒ…å«paddingæ ‡è®°ï¼ˆ-100åº”è¢«å¿½ç•¥ï¼‰")
    predictions4 = torch.tensor([0, 1, 2, 0, 0, 0, 0, 0])
    labels4 = torch.tensor([-100, 1, 2, 0, 0, -100, -100, -100])  # paddingæ ‡è®°ä¸º-100
    result4 = compute_f1_metrics(predictions4, labels4, num_labels=9)
    
    # æœ‰æ•ˆä½ç½®: [1,2,0,0] (æ’é™¤-100)
    # TP: 2ä¸ªæ­£ç¡® (1, 2)
    # FP: 0ä¸ª
    # FN: 0ä¸ª
    # F1 = 100%
    assert result4['micro_f1'] == 1.0, f"âŒ åº”å¿½ç•¥paddingï¼ŒF1åº”ä¸º100%ï¼Œå®é™…: {result4['micro_f1']}"
    print(f"  âœ“ æ­£ç¡®å¿½ç•¥paddingæ ‡è®°ï¼ˆ-100ï¼‰")
    print(f"  âœ“ F1={result4['micro_f1']:.2%}ï¼ˆåŸºäºæœ‰æ•ˆtokenï¼‰")
    
    # æµ‹è¯•ç”¨ä¾‹5: éªŒè¯F1ä¸ç­‰äºRecallï¼ˆä¹‹å‰çš„bugï¼‰
    print("\n[æµ‹è¯•5] éªŒè¯F1 â‰  Recallï¼ˆä¿®å¤bugéªŒè¯ï¼‰")
    # æ•…æ„æ„é€  Precision â‰  Recall çš„æƒ…å†µ
    # é¢„æµ‹: 2ä¸ªå®ä½“ (1, 2)
    # çœŸå®: 4ä¸ªå®ä½“ (1, 2, 3, 4)
    predictions5 = torch.tensor([0, 1, 2, 0, 0, 0, 0, 0])
    labels5 = torch.tensor([0, 1, 2, 0, 0, 3, 4, 0])
    result5 = compute_f1_metrics(predictions5, labels5, num_labels=9)
    
    # TP: 2 (é¢„æµ‹1=çœŸå®1, é¢„æµ‹2=çœŸå®2)
    # FP: 0
    # FN: 2 (çœŸå®3,4æœªè¢«é¢„æµ‹)
    expected_p5 = 2 / (2 + 0)  # = 1.0
    expected_r5 = 2 / (2 + 2)  # = 0.5
    expected_f15 = 2 * expected_p5 * expected_r5 / (expected_p5 + expected_r5)  # â‰ˆ 0.667
    
    assert abs(result5['micro_precision'] - expected_p5) < 1e-6, f"âŒ Precisioné”™è¯¯"
    assert abs(result5['micro_recall'] - expected_r5) < 1e-6, f"âŒ Recallé”™è¯¯"
    assert abs(result5['micro_f1'] - expected_f15) < 1e-6, f"âŒ F1é”™è¯¯"
    
    # éªŒè¯F1ç¡®å®ä¸ç­‰äºRecallï¼ˆä¹‹å‰çš„bugï¼‰
    assert result5['micro_f1'] != result5['micro_recall'], "âŒ F1ä»ç„¶ç­‰äºRecallï¼bugæœªä¿®å¤ï¼"
    print(f"  âœ“ Precision={result5['micro_precision']:.2%} (100%)")
    print(f"  âœ“ Recall={result5['micro_recall']:.2%} (50%)")
    print(f"  âœ“ F1={result5['micro_f1']:.2%} (66.67%)")
    print(f"  âœ“ ç¡®è®¤: F1 â‰  Recallï¼ˆbugå·²ä¿®å¤ï¼ï¼‰")
    
    print("\nâœ… æ‰€æœ‰Token F1è®¡ç®—æµ‹è¯•é€šè¿‡ï¼")
    print("âœ… ä¿®å¤éªŒè¯: Token F1ç°åœ¨æ­£ç¡®è®¡ç®—ä¸º F1ï¼Œè€Œä¸æ˜¯ Recall")
    return True


def test_cls_sep_pad_handling():
    """æµ‹è¯•å¯¹[CLS], [SEP], [PAD]çš„å¤„ç†"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: [CLS]/[SEP]/[PAD]å¤„ç†")
    print("=" * 80)
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿbatchï¼ˆæ‰‹å·¥æ„é€ ï¼‰
    batch_size = 2
    seq_len = 10
    num_labels = 9
    
    # æ„é€ è¾“å…¥
    # Sequence 1: [CLS] George Zimmerman got shot [SEP] [PAD] [PAD] [PAD]
    # Labels:     -100  B-PER  I-PER       O   O    -100  -100  -100  -100
    input_ids = torch.tensor([[
        101,  # [CLS]
        3312, # George
        20758,# Zimmerman
        2288, # got
        2915, # shot
        102,  # [SEP]
        0, 0, 0, 0  # [PAD]
    ]], dtype=torch.long)
    
    attention_mask = torch.tensor([[
        1, 1, 1, 1, 1, 1, 0, 0, 0, 0
    ]], dtype=torch.long)
    
    labels = torch.tensor([[
        -100,  # [CLS] - åº”è¯¥è¢«å¿½ç•¥
        1,     # B-PER
        2,     # I-PER
        0,     # O
        0,     # O
        -100,  # [SEP] - åº”è¯¥è¢«å¿½ç•¥
        -100, -100, -100, -100  # [PAD] - åº”è¯¥è¢«å¿½ç•¥
    ]], dtype=torch.long)
    
    print("\n[æµ‹è¯•1] éªŒè¯labelåˆ†å¸ƒ")
    print(f"  Input IDs shape: {input_ids.shape}")
    print(f"  Attention mask: {attention_mask[0].tolist()}")
    print(f"  Labels: {labels[0].tolist()}")
    valid_labels = labels[labels != -100]
    print(f"  âœ“ æœ‰æ•ˆæ ‡ç­¾ï¼ˆæ’é™¤-100ï¼‰: {valid_labels.tolist()}")
    assert valid_labels.tolist() == [1, 2, 0, 0], "âŒ æœ‰æ•ˆæ ‡ç­¾ä¸æ­£ç¡®"
    
    print("\n[æµ‹è¯•2] å®ä½“æå–åº”å¿½ç•¥[CLS]/[SEP]/[PAD]")
    entities = extract_entities(labels[0].tolist())
    # å®ä½“åº”è¯¥æ˜¯: (1, 2, 'PER') - æ³¨æ„ç´¢å¼•ä»1å¼€å§‹ï¼ˆè·³è¿‡[CLS]ï¼‰
    expected_entities = [(1, 2, 'PER')]
    assert entities == expected_entities, f"âŒ å®ä½“æå–é”™è¯¯: {entities} != {expected_entities}"
    print(f"  âœ“ æå–çš„å®ä½“: {entities}")
    print(f"  âœ“ æ­£ç¡®å¿½ç•¥[CLS]ã€[SEP]ã€[PAD]")
    
    print("\n[æµ‹è¯•3] Token-level F1åº”å¿½ç•¥padding")
    # æ¨¡æ‹Ÿé¢„æµ‹ï¼šå…¨éƒ¨é¢„æµ‹ä¸ºOï¼ˆ0ï¼‰
    predictions = torch.zeros_like(labels)
    
    # è®¡ç®—F1
    pred_flat = predictions.flatten()
    label_flat = labels.flatten()
    
    # æ‰‹åŠ¨è®¡ç®—é¢„æœŸç»“æœ
    valid_mask = label_flat != -100
    valid_preds = pred_flat[valid_mask]
    valid_labels = label_flat[valid_mask]
    
    print(f"  æœ‰æ•ˆé¢„æµ‹: {valid_preds.tolist()}")
    print(f"  æœ‰æ•ˆæ ‡ç­¾: {valid_labels.tolist()}")
    
    # åº”è¯¥åªè®¡ç®—4ä¸ªtokenï¼ˆæ’é™¤[CLS], [SEP], [PAD]ï¼‰
    assert len(valid_preds) == 4, f"âŒ åº”è¯¥æœ‰4ä¸ªæœ‰æ•ˆtokenï¼Œå®é™…: {len(valid_preds)}"
    print(f"  âœ“ æ­£ç¡®è¯†åˆ«4ä¸ªæœ‰æ•ˆtokenï¼ˆæ’é™¤[CLS]/[SEP]/[PAD]ï¼‰")
    
    print("\n[æµ‹è¯•4] CRF maskåº”è¯¥æ­£ç¡®å¤„ç†")
    # å¯¹äºCRFï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿ï¼š
    # 1. [CLS] å’Œ [SEP] çš„labelæ˜¯-100
    # 2. æå–æœ‰æ•ˆèŒƒå›´æ—¶ï¼Œæ’é™¤è¿™äº›token
    valid_indices = (labels[0] != -100).nonzero(as_tuple=True)[0]
    start_idx = valid_indices[0].item()
    end_idx = valid_indices[-1].item() + 1
    
    print(f"  æœ‰æ•ˆtokenèŒƒå›´: [{start_idx}, {end_idx})")
    print(f"  æå–çš„labels: {labels[0, start_idx:end_idx].tolist()}")
    
    # éªŒè¯æå–çš„labelsä¸åŒ…å«-100
    extracted_labels = labels[0, start_idx:end_idx]
    assert (-100 not in extracted_labels), "âŒ æå–çš„labelsä»åŒ…å«-100"
    print(f"  âœ“ æå–çš„labelsä¸åŒ…å«-100")
    
    # éªŒè¯ç¬¬ä¸€ä¸ªä½ç½®ä¸æ˜¯-100ï¼ˆtorchcrfè¦æ±‚ï¼‰
    assert extracted_labels[0] != -100, "âŒ ç¬¬ä¸€ä¸ªä½ç½®æ˜¯-100ï¼ˆè¿åtorchcrfçº¦æŸï¼‰"
    print(f"  âœ“ ç¬¬ä¸€ä¸ªä½ç½®æœ‰æ•ˆï¼ˆæ»¡è¶³torchcrfçº¦æŸï¼‰")
    
    print("\nâœ… æ‰€æœ‰[CLS]/[SEP]/[PAD]å¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_crf_mask_constraints():
    """æµ‹è¯•CRF maskçš„çº¦æŸæ¡ä»¶"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: CRF maskçº¦æŸ")
    print("=" * 80)
    
    print("\n[æµ‹è¯•1] éªŒè¯torchcrfçš„maskçº¦æŸ")
    print("  torchcrfè¦æ±‚: mask[:, 0]å¿…é¡»å…¨ä¸ºTrue")
    
    # é”™è¯¯ç¤ºä¾‹ï¼šç¬¬ä¸€ä¸ªä½ç½®çš„maskæ˜¯False
    try:
        from torchcrf import CRF
        crf = CRF(9, batch_first=True)
        
        emissions = torch.randn(1, 3, 9)
        tags = torch.tensor([[1, 2, 0]])
        mask = torch.tensor([[False, True, True]])  # âŒ ç¬¬ä¸€ä¸ªæ˜¯False
        
        try:
            _ = crf(emissions, tags, mask=mask)
            print("  âŒ åº”è¯¥æŠ¥é”™ä½†æ²¡æœ‰æŠ¥é”™ï¼")
            return False
        except ValueError as e:
            print(f"  âœ“ æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {str(e)[:50]}...")
    except Exception as e:
        print(f"  âš ï¸ è·³è¿‡torchcrfçº¦æŸæµ‹è¯•: {e}")
    
    # æ­£ç¡®ç¤ºä¾‹ï¼šç¬¬ä¸€ä¸ªä½ç½®çš„maskæ˜¯True
    print("\n[æµ‹è¯•2] æ­£ç¡®çš„maskï¼ˆç¬¬ä¸€ä¸ªä½ç½®ä¸ºTrueï¼‰")
    try:
        emissions = torch.randn(1, 3, 9)
        tags = torch.tensor([[1, 2, 0]])
        mask = torch.tensor([[True, True, True]])  # âœ“ ç¬¬ä¸€ä¸ªæ˜¯True
        
        log_likelihood = crf(emissions, tags, mask=mask)
        print(f"  âœ“ Log likelihood: {log_likelihood.item():.4f}")
    except Exception as e:
        print(f"  âš ï¸ è·³è¿‡æµ‹è¯•: {e}")
    
    print("\n[æµ‹è¯•3] æˆ‘ä»¬çš„_compute_crf_losså¤„ç†")
    print("  ç­–ç•¥ï¼šæå–æœ‰æ•ˆèŒƒå›´ï¼Œç¡®ä¿ç¬¬ä¸€ä¸ªä½ç½®ä¸æ˜¯-100")
    
    # æ¨¡æ‹Ÿå®é™…åœºæ™¯
    labels_with_cls_sep = torch.tensor([[-100, 1, 2, 0, -100]])
    valid_mask = (labels_with_cls_sep[0] != -100)
    valid_indices = valid_mask.nonzero(as_tuple=True)[0]
    
    if len(valid_indices) > 0:
        start_idx = valid_indices[0].item()
        end_idx = valid_indices[-1].item() + 1
        
        extracted_labels = labels_with_cls_sep[0, start_idx:end_idx]
        print(f"  åŸå§‹labels: {labels_with_cls_sep[0].tolist()}")
        print(f"  æå–èŒƒå›´: [{start_idx}, {end_idx})")
        print(f"  æå–labels: {extracted_labels.tolist()}")
        
        # éªŒè¯
        assert extracted_labels[0] != -100, "âŒ ç¬¬ä¸€ä¸ªä½ç½®æ˜¯-100"
        assert -100 not in extracted_labels, "âŒ åŒ…å«-100"
        print(f"  âœ“ ç¬¬ä¸€ä¸ªä½ç½®æœ‰æ•ˆ: {extracted_labels[0].item()}")
        print(f"  âœ“ ä¸åŒ…å«-100")
    
    print("\nâœ… æ‰€æœ‰CRF maskçº¦æŸæµ‹è¯•é€šè¿‡ï¼")
    return True


def test_model_components():
    """æµ‹è¯•æ¨¡å‹å„ç»„ä»¶çš„æ­£ç¡®æ€§"""
    print("\n" + "=" * 80)
    print("ğŸ§ª ä¸¥æ ¼æµ‹è¯•: æ¨¡å‹ç»„ä»¶")
    print("=" * 80)
    
    TEST_CONFIG = {
        'text_encoder': 'microsoft/deberta-v3-base',
        'num_labels': 9,
        'lstm_hidden': 128,
        'lstm_layers': 1,
        'dropout': 0.3,
        'use_crf': True,
        'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    }
    
    print("\n[æµ‹è¯•1] æ¨¡å‹æ„å»º")
    model = SimpleNERModel(
        text_encoder_name=TEST_CONFIG['text_encoder'],
        num_labels=TEST_CONFIG['num_labels'],
        lstm_hidden=TEST_CONFIG['lstm_hidden'],
        lstm_layers=TEST_CONFIG['lstm_layers'],
        dropout=TEST_CONFIG['dropout'],
        use_crf=TEST_CONFIG['use_crf']
    )
    model = model.to(TEST_CONFIG['device'])
    print(f"  âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    # éªŒè¯å„ç»„ä»¶
    assert hasattr(model, 'text_encoder'), "âŒ ç¼ºå°‘text_encoder"
    assert hasattr(model, 'bilstm'), "âŒ ç¼ºå°‘bilstm"
    assert hasattr(model, 'classifier'), "âŒ ç¼ºå°‘classifier"
    assert hasattr(model, 'crf'), "âŒ ç¼ºå°‘crf"
    print(f"  âœ“ æ‰€æœ‰ç»„ä»¶å­˜åœ¨")
    
    print("\n[æµ‹è¯•2] å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰")
    # æ„é€ è¾“å…¥
    batch_size, seq_len = 2, 10
    input_ids = torch.randint(100, 1000, (batch_size, seq_len)).to(TEST_CONFIG['device'])
    attention_mask = torch.ones(batch_size, seq_len).to(TEST_CONFIG['device'])
    labels = torch.randint(0, TEST_CONFIG['num_labels'], (batch_size, seq_len)).to(TEST_CONFIG['device'])
    labels[:, 0] = -100  # [CLS]
    labels[:, -1] = -100  # [SEP]
    
    loss, logits = model(input_ids, attention_mask, labels)
    
    assert not torch.isnan(loss), "âŒ Lossæ˜¯NaN"
    assert not torch.isinf(loss), "âŒ Lossæ˜¯Inf"
    assert loss.item() > 0, "âŒ Lossåº”è¯¥>0"
    print(f"  âœ“ Loss: {loss.item():.4f}")
    print(f"  âœ“ Logits shape: {logits.shape}")
    assert logits.shape == (batch_size, seq_len, TEST_CONFIG['num_labels']), "âŒ Logits shapeé”™è¯¯"
    
    print("\n[æµ‹è¯•3] å‰å‘ä¼ æ’­ï¼ˆæ¨ç†æ¨¡å¼ï¼‰")
    with torch.no_grad():
        logits_eval = model(input_ids, attention_mask)
    print(f"  âœ“ Logits shape: {logits_eval.shape}")
    
    print("\n[æµ‹è¯•4] CRFè§£ç ")
    with torch.no_grad():
        predictions = model.decode(input_ids, attention_mask)
    print(f"  âœ“ Predictions shape: {predictions.shape}")
    assert predictions.shape == (batch_size, seq_len), "âŒ Predictions shapeé”™è¯¯"
    
    # éªŒè¯é¢„æµ‹å€¼èŒƒå›´
    assert predictions.min() >= 0, "âŒ é¢„æµ‹å€¼<0"
    assert predictions.max() < TEST_CONFIG['num_labels'], "âŒ é¢„æµ‹å€¼>=num_labels"
    print(f"  âœ“ é¢„æµ‹å€¼èŒƒå›´: [{predictions.min()}, {predictions.max()}]")
    
    print("\n[æµ‹è¯•5] åå‘ä¼ æ’­")
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    
    loss, _ = model(input_ids, attention_mask, labels)
    optimizer.zero_grad()
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    has_grad = False
    for name, param in model.named_parameters():
        if param.grad is not None:
            has_grad = True
            assert not torch.isnan(param.grad).any(), f"âŒ {name}çš„æ¢¯åº¦åŒ…å«NaN"
            assert not torch.isinf(param.grad).any(), f"âŒ {name}çš„æ¢¯åº¦åŒ…å«Inf"
    
    assert has_grad, "âŒ æ²¡æœ‰å‚æ•°æœ‰æ¢¯åº¦"
    print(f"  âœ“ åå‘ä¼ æ’­æˆåŠŸï¼Œæ¢¯åº¦æ­£å¸¸")
    
    optimizer.step()
    print(f"  âœ“ å‚æ•°æ›´æ–°æˆåŠŸ")
    
    print("\nâœ… æ‰€æœ‰æ¨¡å‹ç»„ä»¶æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_training_pipeline():
    """
    æµ‹è¯•è®­ç»ƒæµç¨‹çš„å®Œæ•´æ€§
    ä½¿ç”¨ä¸¥æ ¼çš„æµ‹è¯•ç”¨ä¾‹éªŒè¯æ¯ä¸ªç¯èŠ‚
    """
    print("=" * 80)
    print("ğŸ§ª å®Œæ•´è®­ç»ƒæµç¨‹æµ‹è¯•")
    print("=" * 80)
    
    try:
        # è¿è¡Œæ‰€æœ‰ä¸¥æ ¼æµ‹è¯•
        tests = [
            ("å®ä½“æå–", test_entity_extraction),
            ("Span F1è®¡ç®—", test_span_f1_calculation),
            ("Token F1è®¡ç®—", test_token_f1_calculation),
            ("[CLS]/[SEP]/[PAD]å¤„ç†", test_cls_sep_pad_handling),
            ("CRF maskçº¦æŸ", test_crf_mask_constraints),
            ("æ¨¡å‹ç»„ä»¶", test_model_components),
        ]
        
        passed = 0
        failed = 0
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed += 1
            except AssertionError as e:
                print(f"\nâŒ {test_name}æµ‹è¯•å¤±è´¥: {e}")
                failed += 1
            except Exception as e:
                print(f"\nâš ï¸ {test_name}æµ‹è¯•å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                failed += 1
        
        # æ€»ç»“
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        print(f"é€šè¿‡: {passed}/{len(tests)}")
        print(f"å¤±è´¥: {failed}/{len(tests)}")
        
        if failed == 0:
            print("\n" + "=" * 80)
            print("âœ… æ‰€æœ‰ä¸¥æ ¼æµ‹è¯•é€šè¿‡ï¼")
            print("=" * 80)
            print("\nå…³é”®éªŒè¯ï¼š")
            print("  âœ“ å®ä½“æå–é€»è¾‘æ­£ç¡®ï¼ˆåŒ…æ‹¬è¾¹ç•Œæƒ…å†µï¼‰")
            print("  âœ“ Span-level F1è®¡ç®—å‡†ç¡®ï¼ˆTP/FP/FNæ­£ç¡®ï¼‰")
            print("  âœ“ [CLS]/[SEP]/[PAD]æ­£ç¡®å¤„ç†")
            print("  âœ“ CRF maskçº¦æŸæ»¡è¶³torchcrfè¦æ±‚")
            print("  âœ“ æ¨¡å‹å‰å‘/åå‘ä¼ æ’­æ­£å¸¸")
            print("  âœ“ æ¢¯åº¦è®¡ç®—æ— NaN/Inf")
            print("\nå¯ä»¥å®‰å…¨è¿è¡Œå®Œæ•´è®­ç»ƒï¼š")
            print("  python tests/simple_ner_training.py")
            return True
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤")
            return False
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æµç¨‹å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•æ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        test_training_pipeline()
    else:
        main()