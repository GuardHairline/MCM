#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†æ ‡ç­¾åˆ†å¸ƒåˆ†æå·¥å…·
ç”¨äºè®¡ç®—MASCã€MNERç­‰ä»»åŠ¡çš„çœŸå®ç±»åˆ«åˆ†å¸ƒå’Œæ¨èæƒé‡
"""
import os
import json
import torch
from collections import Counter
import numpy as np
from datasets.get_dataset import get_dataset
import argparse

def analyze_dataset(task_name, dataset_name="twitter2015", split="train"):
    """åˆ†ææ•°æ®é›†çš„æ ‡ç­¾åˆ†å¸ƒ"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åˆ†æä»»åŠ¡: {task_name.upper()} | æ•°æ®é›†: {dataset_name} | åˆ†å‰²: {split}")
    print(f"{'='*80}\n")
    
    # æ„é€ æ–‡ä»¶è·¯å¾„ (ä¿®æ­£ï¼šä»»åŠ¡ç›®å½•åœ¨dataä¸‹)
    # æƒ…æ„Ÿä»»åŠ¡ï¼ˆMASC, MATE, MABSAï¼‰éƒ½ä½¿ç”¨MASCæ•°æ®ï¼ˆsentiment: -1, 0, 1ï¼‰
    # å®ä½“ä»»åŠ¡ï¼ˆMNERï¼‰ä½¿ç”¨MNERæ•°æ®ï¼ˆNERæ ‡ç­¾ï¼‰
    if task_name in ["masc", "mate", "mabsa"]:
        # æƒ…æ„Ÿç›¸å…³ä»»åŠ¡éƒ½ä½¿ç”¨MASCç›®å½•çš„æ•°æ®
        # æ³¨æ„ï¼šMASC/MATE/MABSAä½¿ç”¨train__.txtï¼ˆåŒä¸‹åˆ’çº¿ï¼‰
        base_path = f"data/MASC/{dataset_name}"
        text_file = f"{base_path}/{split}__.txt"
        image_dir = "data/img"
    elif task_name == "mner":
        # å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ä½¿ç”¨MNERç›®å½•ï¼ˆåŒä¸‹åˆ’çº¿ï¼‰
        base_path = f"data/MNER/{dataset_name}"
        text_file = f"{base_path}/{split}__.txt"
        image_dir = "data/img"
    else:
        base_path = f"data/{dataset_name}"
        text_file = f"{base_path}/{split}.txt"
        image_dir = f"{base_path}/{split}"
    
    # åˆ›å»ºç®€å•çš„argså¯¹è±¡
    args = argparse.Namespace(
        task_name=task_name,
        dataset=dataset_name,
        train_text_file=text_file,
        dev_text_file=text_file.replace("train", "dev"),
        test_text_file=text_file.replace("train", "test"),
        image_dir=image_dir,  # ä¿®å¤ï¼šæ·»åŠ image_dirå±æ€§
        text_model_name="microsoft/deberta-v3-base",
        image_model_name="openai/clip-vit-base-patch32",
        max_length=128,
        batch_size=32,
        deqa=0  # ä¸ä½¿ç”¨DEQAæ¨¡å¼
    )
    
    try:
        # åŠ è½½æ•°æ®é›†ï¼ˆä¿®å¤ï¼šå‚æ•°é¡ºåºæ˜¯ task, split, argsï¼‰
        # get_datasetè¿”å›çš„æ˜¯å•ä¸ªdatasetå¯¹è±¡ï¼Œä¸æ˜¯tuple
        dataset = get_dataset(task_name, split, args)
        
        # ç»Ÿè®¡æ ‡ç­¾
        label_counter = Counter()
        total_tokens = 0  # ç”¨äºtokençº§ä»»åŠ¡
        total_samples = len(dataset)
        
        print(f"æ•°æ®é›†å¤§å°: {total_samples} æ ·æœ¬")
        
        for i, item in enumerate(dataset):
            labels = item['labels']
            
            if task_name in ["mner", "mate", "mabsa"]:
                # Tokençº§ä»»åŠ¡ï¼šåªç»Ÿè®¡é-100çš„æ ‡ç­¾
                # labelså¯èƒ½æ˜¯tensoræˆ–list
                if isinstance(labels, torch.Tensor):
                    labels_list = labels.tolist()
                else:
                    labels_list = labels
                
                valid_labels = [l for l in labels_list if l != -100]
                label_counter.update(valid_labels)
                total_tokens += len(valid_labels)
                
                if i < 3:  # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
                    print(f"æ ·æœ¬ {i}: {len(valid_labels)} ä¸ªæœ‰æ•ˆtoken")
            else:
                # å¥çº§ä»»åŠ¡ï¼šç›´æ¥ç»Ÿè®¡
                if isinstance(labels, torch.Tensor):
                    labels = labels.item()
                label_counter[labels] += 1
        
        # è·å–æ ‡ç­¾åç§°
        from continual.label_config import get_label_manager
        label_manager = get_label_manager()
        task_config = label_manager.get_task_config(task_name)
        if task_config is None:
            print(f"âŒ æ— æ³•è·å–ä»»åŠ¡ {task_name} çš„é…ç½®")
            return None
        label_names = task_config.label_names
        num_labels = task_config.num_labels
        
        print(f"æ ‡ç­¾æ€»æ•°: {num_labels}")
        print(f"æ ‡ç­¾åç§°: {label_names}")
        
        # è®¡ç®—åˆ†å¸ƒ
        print(f"{'='*80}")
        print("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡:")
        print(f"{'='*80}")
        
        counts = [label_counter.get(i, 0) for i in range(num_labels)]
        total = sum(counts)
        
        print(f"\n{'æ ‡ç­¾ID':<8} {'æ ‡ç­¾å':<15} {'æ•°é‡':<12} {'å æ¯”':<10} {'æ¨èæƒé‡':<12}")
        print("-" * 80)
        
        weights_inverse = []
        weights_balanced = []
        weights_sqrt = []
        
        for i, (count, name) in enumerate(zip(counts, label_names)):
            if count == 0:
                print(f"{i:<8} {name:<15} {count:<12} {'0.00%':<10} {'N/A':<12}")
                weights_inverse.append(1.0)
                weights_balanced.append(1.0)
                weights_sqrt.append(1.0)
                continue
            
            pct = 100 * count / total
            
            # è®¡ç®—å¤šç§æƒé‡ç­–ç•¥
            # 1. é€†é¢‘ç‡æƒé‡ (Inverse Frequency)
            inv_weight = total / (num_labels * count)
            weights_inverse.append(inv_weight)
            
            # 2. å¹³è¡¡æƒé‡ (Balanced)
            balanced_weight = (total - count) / count
            weights_balanced.append(balanced_weight)
            
            # 3. å¹³æ–¹æ ¹é€†é¢‘ç‡ (sqrt inverse)
            sqrt_weight = np.sqrt(total / count)
            weights_sqrt.append(sqrt_weight)
            
            print(f"{i:<8} {name:<15} {count:<12} {pct:<9.2f}% {inv_weight:<12.2f}")
        
        # å½’ä¸€åŒ–æƒé‡ï¼ˆä½¿æœ€å°å€¼ä¸º1.0ï¼‰
        def normalize_weights(weights):
            min_w = min(w for w in weights if w > 0)
            return [w / min_w for w in weights]
        
        weights_inverse_norm = normalize_weights(weights_inverse)
        weights_balanced_norm = normalize_weights(weights_balanced)
        weights_sqrt_norm = normalize_weights(weights_sqrt)
        
        # æ‰“å°æ¨èæƒé‡
        print(f"{'='*80}")
        print("ğŸ’¡ æ¨èç±»åˆ«æƒé‡é…ç½®:")
        print(f"{'='*80}\n")
        
        print("æ–¹æ³•1: é€†é¢‘ç‡æƒé‡ (Inverse Frequency) - é€‚ç”¨äºæåº¦ä¸å¹³è¡¡")
        print(f'"{task_name}": {[round(w, 1) for w in weights_inverse_norm]},')
        
        print("\næ–¹æ³•2: å¹³è¡¡æƒé‡ (Balanced) - é€‚ç”¨äºä¸­ç­‰ä¸å¹³è¡¡")
        print(f'"{task_name}": {[round(w, 1) for w in weights_balanced_norm]},')
        
        print("\næ–¹æ³•3: å¹³æ–¹æ ¹é€†é¢‘ç‡ (Sqrt Inverse) - æ¸©å’Œå¹³è¡¡ï¼Œæ¨èä½¿ç”¨")
        print(f'"{task_name}": {[round(w, 1) for w in weights_sqrt_norm]},')
        
        # ç‰¹æ®Šæ¨èï¼šå¯¹äºMASCå’ŒMNER
        if task_name == "masc":
            # MASCé€šå¸¸æ˜¯3åˆ†ç±»ï¼šnegative, neutral, positive
            # NEUé€šå¸¸å å¤šæ•°
            max_count = max(counts)
            custom_weights = [max_count / max(c, 1) for c in counts]
            custom_weights_norm = normalize_weights(custom_weights)
            print("\næ–¹æ³•4: è‡ªå®šä¹‰MASCæƒé‡ï¼ˆæ¨èï¼‰")
            print(f'"{task_name}": {[round(w, 1) for w in custom_weights_norm]},')
        
        if task_name == "mner":
            # MNERçš„Oæ ‡ç­¾é€šå¸¸å ç»å¤§å¤šæ•°
            # å»ºè®®å¯¹Oä½¿ç”¨è¾ƒå°æƒé‡ï¼Œå¯¹å®ä½“ç±»å‹ä½¿ç”¨è¾ƒå¤§æƒé‡
            custom_weights = weights_sqrt_norm.copy()
            if counts[0] > sum(counts[1:]):  # å¦‚æœOæ ‡ç­¾æ˜¯ç¬¬ä¸€ä¸ªä¸”å å¤šæ•°
                custom_weights[0] = 0.1  # Oæ ‡ç­¾ä½¿ç”¨å¾ˆå°çš„æƒé‡
            print("\næ–¹æ³•5: è‡ªå®šä¹‰MNERæƒé‡ï¼ˆæ¨èï¼‰")
            print(f'"{task_name}": {[round(w, 2) for w in custom_weights]},')
        
        print(f"{'='*80}\n")
        
        return {
            'label_names': label_names,
            'counts': counts,
            'total': total,
            'weights_inverse': weights_inverse_norm,
            'weights_balanced': weights_balanced_norm,
            'weights_sqrt': weights_sqrt_norm,
        }
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """åˆ†ææ‰€æœ‰ä»»åŠ¡çš„æ ‡ç­¾åˆ†å¸ƒ"""
    parser = argparse.ArgumentParser()
    parser.add_argument("--task", type=str, default="all", 
                       help="ä»»åŠ¡åç§°: masc, mner, mate, mabsa, æˆ– all")
    parser.add_argument("--dataset", type=str, default="twitter2015",
                       help="æ•°æ®é›†åç§°")
    parser.add_argument("--split", type=str, default="train",
                       help="æ•°æ®åˆ†å‰²: train, dev, test")
    args = parser.parse_args()
    
    if args.task == "all":
        tasks = ["masc", "mner", "mate", "mabsa"]
    else:
        tasks = [args.task]
    
    results = {}
    for task in tasks:
        result = analyze_dataset(task, args.dataset, args.split)
        if result:
            results[task] = result
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶å»ºè®®
    print("="*80)
    print("ğŸ“ å®Œæ•´é…ç½®å»ºè®®ï¼ˆå¤åˆ¶åˆ° continual/label_config.pyï¼‰:")
    print("="*80 + "\n")
    print("weights = {")
    for task, result in results.items():
        if result:
            weights = result['weights_sqrt']
            print(f'    "{task}": {[round(w, 1) for w in weights]},')
    print("}")


if __name__ == "__main__":
    main()

