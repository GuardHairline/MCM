#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç‰¹å¾èšç±»å¯è§†åŒ–æ¨¡å—
ç”¨äºè§‚å¯ŸæŒç»­å­¦ä¹ è¿‡ç¨‹ä¸­çš„è¡¨ç¤ºå˜åŒ–å’Œç±»åˆ«åˆ†å¸ƒ

åŠŸèƒ½ï¼š
1. æå–æ¨¡å‹ä¸­é—´å±‚ç‰¹å¾ï¼ˆèåˆåçš„ç‰¹å¾ï¼‰
2. ä½¿ç”¨t-SNE/UMAPé™ç»´åˆ°2D
3. å¯è§†åŒ–èšç±»æƒ…å†µï¼ˆæŒ‰ç±»åˆ«å’Œä»»åŠ¡ç€è‰²ï¼‰
4. è§‚å¯ŸæŒç»­å­¦ä¹ ä¸­çš„é—å¿˜æƒ…å†µ
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional
import logging
from pathlib import Path
from collections import defaultdict
import json

logger = logging.getLogger(__name__)

# è®¾ç½®é»˜è®¤å­—ä½“ï¼ˆæ— éœ€ä¸­æ–‡æ”¯æŒï¼‰
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False


def extract_features_and_labels(
    model,
    task_name: str,
    split: str,
    device: torch.device,
    args,
    max_samples: int = 2000
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    æå–ç‰¹å¾å’Œæ ‡ç­¾
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        task_name: ä»»åŠ¡åç§° (e.g., "mate", "mabsa")
        split: æ•°æ®é›†åˆ’åˆ† ("train", "dev", "test")
        device: è®¾å¤‡
        args: å‚æ•°
        max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
        
    Returns:
        features: (N, hidden_dim) æå–çš„ç‰¹å¾
        labels: (N,) æ ‡ç­¾
        task_ids: (N,) ä»»åŠ¡IDï¼ˆç”¨äºè·¨ä»»åŠ¡å¯è§†åŒ–ï¼‰
    """
    from datasets.get_dataset import get_dataset
    from modules.train_utils import is_sequence_task
    
    logger.info(f"ğŸ“Š æå–ç‰¹å¾: task={task_name}, split={split}, max_samples={max_samples}")
    
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ä»»åŠ¡å¤´
    if hasattr(model, 'set_active_head') and hasattr(args, 'session_name'):
        try:
            model.set_active_head(args.session_name, strict=False)
        except Exception as e:
            logger.warning(f"Failed to set active head: {e}")
    
    # ç¡®ä¿base_modelçš„modeæ­£ç¡®è®¾ç½®
    if hasattr(model, 'base_model') and hasattr(model.base_model, 'mode'):
        current_mode = getattr(args, 'mode', 'multimodal')
        model.base_model.mode = current_mode
    
    # åŠ è½½æ•°æ®é›†
    dataset = get_dataset(task_name, split, args)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)
    
    is_seq_task = is_sequence_task(task_name)
    
    all_features = []
    all_labels = []
    sample_count = 0
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(loader):
            if sample_count >= max_samples:
                break
                
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            token_type_ids = batch.get("token_type_ids", None)
            if token_type_ids is not None:
                token_type_ids = token_type_ids.to(device)
            image_tensor = batch["image_tensor"].to(device)
            labels = batch["labels"]
            
            # æå–èåˆåçš„ç‰¹å¾ï¼ˆåœ¨ä»»åŠ¡å¤´ä¹‹å‰ï¼‰
            if is_seq_task:
                # Tokençº§åˆ«ä»»åŠ¡ï¼šè¿”å›åºåˆ—ç‰¹å¾
                fused_feat = model.base_model(
                    input_ids, attention_mask, token_type_ids, image_tensor,
                    return_sequence=True
                )  # (batch_size, seq_len, hidden_dim)
                
                # å±•å¹³åºåˆ—ï¼Œåªä¿ç•™æœ‰æ•ˆtokenï¼ˆépaddingï¼‰
                batch_size, seq_len, hidden_dim = fused_feat.shape
                fused_feat = fused_feat.view(-1, hidden_dim)  # (batch_size * seq_len, hidden_dim)
                labels = labels.view(-1)  # (batch_size * seq_len,)
                
                # è¿‡æ»¤æ‰paddingï¼ˆlabel=-100ï¼‰
                valid_mask = labels != -100
                fused_feat = fused_feat[valid_mask]
                labels = labels[valid_mask]
                
            else:
                # å¥å­çº§åˆ«ä»»åŠ¡ï¼šè¿”å›CLSç‰¹å¾
                fused_feat = model.base_model(
                    input_ids, attention_mask, token_type_ids, image_tensor,
                    return_sequence=False
                )  # (batch_size, hidden_dim)
            
            # è½¬ä¸ºnumpyå¹¶ä¿å­˜
            all_features.append(fused_feat.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
            sample_count += fused_feat.shape[0]
            
            if (batch_idx + 1) % 10 == 0:
                logger.info(f"  å·²å¤„ç† {batch_idx + 1}/{len(loader)} batches, {sample_count} samples")
    
    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    features = np.concatenate(all_features, axis=0)[:max_samples]
    labels = np.concatenate(all_labels, axis=0)[:max_samples]
    
    logger.info(f"âœ“ ç‰¹å¾æå–å®Œæˆ: shape={features.shape}, unique_labels={len(np.unique(labels))}")
    
    return features, labels


def get_label_names_for_task(task_name: str) -> Dict[int, str]:
    """
    è·å–ä»»åŠ¡çš„å®é™…æ ‡ç­¾åç§°
    
    Args:
        task_name: ä»»åŠ¡åç§°
        
    Returns:
        label_names: {label_id: label_name}
    """
    try:
        from continual.label_config import get_label_manager
        
        manager = get_label_manager()
        config = manager.get_task_config(task_name)
        
        if config is None:
            logger.warning(f"Task {task_name} not found in label manager, using generic names")
            return {}
        
        # è¿”å›æ ‡ç­¾IDåˆ°æ ‡ç­¾åçš„æ˜ å°„
        label_names = {}
        for idx, name in enumerate(config.label_names):
            label_names[idx] = name
        
        return label_names
    except Exception as e:
        logger.warning(f"Failed to get label names: {e}, using generic names")
        return {}


def plot_tsne(
    features: np.ndarray,
    labels: np.ndarray,
    task_name: str,
    save_path: str,
    title: str = None,
    perplexity: int = 30,
    n_iter: int = 1000
):
    """
    ä½¿ç”¨t-SNEé™ç»´å¹¶ç»˜åˆ¶2Dæ•£ç‚¹å›¾ï¼ˆä½¿ç”¨å®é™…æ ‡ç­¾åï¼‰
    
    Args:
        features: (N, hidden_dim)
        labels: (N,)
        task_name: ä»»åŠ¡åç§°
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
        perplexity: t-SNE perplexityå‚æ•°
        n_iter: t-SNEè¿­ä»£æ¬¡æ•°
    """
    logger.info(f"ğŸ¨ å¼€å§‹t-SNEé™ç»´: perplexity={perplexity}, n_iter={n_iter}")
    
    # è·å–å®é™…æ ‡ç­¾å
    label_names = get_label_names_for_task(task_name)
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)
    features_2d = tsne.fit_transform(features)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(1, 1, figsize=(12, 9))
    
    # è·å–å”¯ä¸€æ ‡ç­¾
    unique_labels = np.unique(labels)
    n_classes = len(unique_labels)
    
    # ç”Ÿæˆé¢œè‰²æ˜ å°„
    colors = plt.cm.get_cmap('tab10' if n_classes <= 10 else 'tab20')(range(n_classes))
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶æ•£ç‚¹
    for idx, label in enumerate(unique_labels):
        mask = labels == label
        
        # ä½¿ç”¨å®é™…æ ‡ç­¾åæˆ–é»˜è®¤åç§°
        if label_names and label in label_names:
            label_text = label_names[label]
        else:
            label_text = f'Class {label}'
        
        ax.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[colors[idx]],
            label=label_text,  # ä½¿ç”¨å®é™…æ ‡ç­¾å
            alpha=0.6,
            s=30,
            edgecolors='k',
            linewidths=0.3
        )
    
    # è®¾ç½®æ ‡é¢˜å’Œå›¾ä¾‹
    if title is None:
        title = f't-SNE: {task_name.upper()} (Ground Truth)'
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('t-SNE Dimension 1', fontsize=12)
    ax.set_ylabel('t-SNE Dimension 2', fontsize=12)
    ax.legend(loc='best', fontsize=10, ncol=2 if n_classes > 5 else 1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"âœ“ t-SNEå›¾å·²ä¿å­˜: {save_path}")


def plot_umap(
    features: np.ndarray,
    labels: np.ndarray,
    task_name: str,
    save_path: str,
    title: str = None,
    n_neighbors: int = 15,
    min_dist: float = 0.1
):
    """
    ä½¿ç”¨UMAPé™ç»´å¹¶ç»˜åˆ¶2Dæ•£ç‚¹å›¾ï¼ˆä½¿ç”¨å®é™…æ ‡ç­¾åï¼‰
    
    Args:
        features: (N, hidden_dim)
        labels: (N,)
        task_name: ä»»åŠ¡åç§°
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
        n_neighbors: UMAP n_neighborså‚æ•°
        min_dist: UMAP min_distå‚æ•°
    """
    try:
        import umap
    except ImportError:
        logger.warning("âš ï¸  UMAPæœªå®‰è£…ï¼Œè·³è¿‡UMAPå¯è§†åŒ–ã€‚è¯·è¿è¡Œ: pip install umap-learn")
        return
    
    logger.info(f"ğŸ¨ å¼€å§‹UMAPé™ç»´: n_neighbors={n_neighbors}, min_dist={min_dist}")
    
    # è·å–å®é™…æ ‡ç­¾å
    label_names = get_label_names_for_task(task_name)
    
    # UMAPé™ç»´
    reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=min_dist, random_state=42)
    features_2d = reducer.fit_transform(features)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(1, 1, figsize=(12, 9))
    
    # è·å–å”¯ä¸€æ ‡ç­¾
    unique_labels = np.unique(labels)
    n_classes = len(unique_labels)
    
    # ç”Ÿæˆé¢œè‰²æ˜ å°„
    colors = plt.cm.get_cmap('tab10' if n_classes <= 10 else 'tab20')(range(n_classes))
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶æ•£ç‚¹
    for idx, label in enumerate(unique_labels):
        mask = labels == label
        
        # ä½¿ç”¨å®é™…æ ‡ç­¾åæˆ–é»˜è®¤åç§°
        if label_names and label in label_names:
            label_text = label_names[label]
        else:
            label_text = f'Class {label}'
        
        ax.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[colors[idx]],
            label=label_text,  # ä½¿ç”¨å®é™…æ ‡ç­¾å
            alpha=0.6,
            s=30,
            edgecolors='k',
            linewidths=0.3
        )
    
    # è®¾ç½®æ ‡é¢˜å’Œå›¾ä¾‹
    if title is None:
        title = f'UMAP: {task_name.upper()} (Ground Truth)'
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('UMAP Dimension 1', fontsize=12)
    ax.set_ylabel('UMAP Dimension 2', fontsize=12)
    ax.legend(loc='best', fontsize=10, ncol=2 if n_classes > 5 else 1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"âœ“ UMAPå›¾å·²ä¿å­˜: {save_path}")


def plot_continual_learning_evolution(
    task_features: Dict[str, Tuple[np.ndarray, np.ndarray]],
    save_dir: str,
    method: str = 'tsne'
):
    """
    ç»˜åˆ¶æŒç»­å­¦ä¹ è¿‡ç¨‹ä¸­æ‰€æœ‰ä»»åŠ¡çš„ç‰¹å¾æ¼”è¿›å›¾
    
    Args:
        task_features: {task_name: (features, labels)} æ‰€æœ‰ä»»åŠ¡çš„ç‰¹å¾
        save_dir: ä¿å­˜ç›®å½•
        method: é™ç»´æ–¹æ³• ('tsne' æˆ– 'umap')
    """
    logger.info(f"ğŸ¨ ç»˜åˆ¶æŒç»­å­¦ä¹ æ¼”è¿›å›¾: {len(task_features)} ä¸ªä»»åŠ¡, method={method}")
    
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆå¹¶æ‰€æœ‰ä»»åŠ¡çš„ç‰¹å¾
    all_features = []
    all_labels = []
    all_task_ids = []
    
    task_names = list(task_features.keys())
    for task_idx, task_name in enumerate(task_names):
        features, labels = task_features[task_name]
        all_features.append(features)
        all_labels.append(labels)
        all_task_ids.append(np.full(len(labels), task_idx))
    
    all_features = np.concatenate(all_features, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)
    all_task_ids = np.concatenate(all_task_ids, axis=0)
    
    logger.info(f"  åˆå¹¶åç‰¹å¾: {all_features.shape}")
    
    # é™ç»´
    if method == 'tsne':
        from sklearn.manifold import TSNE
        reducer = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)
        features_2d = reducer.fit_transform(all_features)
    elif method == 'umap':
        try:
            import umap
            reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)
            features_2d = reducer.fit_transform(all_features)
        except ImportError:
            logger.warning("UMAPæœªå®‰è£…ï¼Œå›é€€åˆ°t-SNE")
            from sklearn.manifold import TSNE
            reducer = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)
            features_2d = reducer.fit_transform(all_features)
            method = 'tsne'
    else:
        raise ValueError(f"Unknown method: {method}")
    
    # åˆ›å»ºä¸¤ä¸ªå­å›¾ï¼š(1) æŒ‰ä»»åŠ¡ç€è‰²  (2) æŒ‰ç±»åˆ«ç€è‰²
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
    
    # === å­å›¾1: æŒ‰ä»»åŠ¡ç€è‰² ===
    task_colors = plt.cm.get_cmap('Set1')(range(len(task_names)))
    for task_idx, task_name in enumerate(task_names):
        mask = all_task_ids == task_idx
        ax1.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[task_colors[task_idx]],
            label=f'{task_name.upper()}',
            alpha=0.6,
            s=15,
            edgecolors='k',
            linewidths=0.2
        )
    
    ax1.set_title(f'{method.upper()}: Colored by Task', fontsize=14, fontweight='bold')
    ax1.set_xlabel(f'{method.upper()} Dimension 1', fontsize=12)
    ax1.set_ylabel(f'{method.upper()} Dimension 2', fontsize=12)
    ax1.legend(loc='best', fontsize=10)
    ax1.grid(True, alpha=0.3)
    
    # === å­å›¾2: æŒ‰ç±»åˆ«ç€è‰² ===
    unique_labels = np.unique(all_labels)
    n_classes = len(unique_labels)
    label_colors = plt.cm.get_cmap('tab20' if n_classes > 10 else 'tab10')(range(n_classes))
    
    for idx, label in enumerate(unique_labels):
        mask = all_labels == label
        ax2.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[label_colors[idx]],
            label=f'Class {label}',
            alpha=0.6,
            s=15,
            edgecolors='k',
            linewidths=0.2
        )
    
    ax2.set_title(f'{method.upper()}: Colored by Label', fontsize=14, fontweight='bold')
    ax2.set_xlabel(f'{method.upper()} Dimension 1', fontsize=12)
    ax2.set_ylabel(f'{method.upper()} Dimension 2', fontsize=12)
    if n_classes <= 15:
        ax2.legend(loc='best', fontsize=9, ncol=2)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = save_dir / f'continual_learning_evolution_{method}.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"âœ“ æ¼”è¿›å›¾å·²ä¿å­˜: {save_path}")


def visualize_task_after_training(
    model,
    task_name: str,
    session_name: str,
    device: torch.device,
    args,
    save_dir: str,
    split: str = 'dev',
    max_samples: int = 2000,
    use_both_methods: bool = True,
    config_name: Optional[str] = None  # æ–°å¢ï¼šé…ç½®æ–‡ä»¶åç§°å‰ç¼€
):
    """
    åœ¨ä»»åŠ¡è®­ç»ƒå®Œæˆåè¿›è¡Œå¯è§†åŒ–
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        task_name: ä»»åŠ¡åç§°
        session_name: ä¼šè¯åç§°
        device: è®¾å¤‡
        args: å‚æ•°
        save_dir: ä¿å­˜ç›®å½•
        split: æ•°æ®é›†åˆ’åˆ† (æ¨èä½¿ç”¨'dev')
        max_samples: æœ€å¤§æ ·æœ¬æ•°
        use_both_methods: æ˜¯å¦åŒæ—¶ä½¿ç”¨t-SNEå’ŒUMAP
        config_name: é…ç½®æ–‡ä»¶åç§°ï¼ˆç”¨äºåŒºåˆ†ä¸åŒé…ç½®çš„å¯è§†åŒ–ç»“æœï¼‰
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # æ„å»ºæ–‡ä»¶åå‰ç¼€ï¼ˆé¿å…ä¸åŒé…ç½®äº’ç›¸è¦†ç›–ï¼‰
    if config_name:
        file_prefix = f"{config_name}_{session_name}"
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š å¼€å§‹ç‰¹å¾èšç±»å¯è§†åŒ–")
        logger.info(f"  é…ç½®: {config_name}")
        logger.info(f"  ä»»åŠ¡: {task_name}")
        logger.info(f"  ä¼šè¯: {session_name}")
        logger.info(f"  æ•°æ®é›†: {split}")
        logger.info(f"  ä¿å­˜ç›®å½•: {save_dir}")
        logger.info(f"  æ–‡ä»¶å‰ç¼€: {file_prefix}")
        logger.info(f"{'='*60}\n")
    else:
        file_prefix = session_name
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š å¼€å§‹ç‰¹å¾èšç±»å¯è§†åŒ–")
        logger.info(f"  ä»»åŠ¡: {task_name}")
        logger.info(f"  ä¼šè¯: {session_name}")
        logger.info(f"  æ•°æ®é›†: {split}")
        logger.info(f"  ä¿å­˜ç›®å½•: {save_dir}")
        logger.info(f"{'='*60}\n")
    
    # 1. æå–ç‰¹å¾
    features, labels = extract_features_and_labels(
        model, task_name, split, device, args, max_samples
    )
    
    # 2. t-SNEå¯è§†åŒ–
    tsne_path = save_dir / f'{file_prefix}_{split}_tsne.png'
    plot_tsne(
        features, labels, task_name, str(tsne_path),
        title=f't-SNE: {task_name.upper()} ({split})'
    )
    
    # 3. UMAPå¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    if use_both_methods:
        umap_path = save_dir / f'{file_prefix}_{split}_umap.png'
        plot_umap(
            features, labels, task_name, str(umap_path),
            title=f'UMAP: {task_name.upper()} ({split})'
        )
    
    # 4. ä¿å­˜ç‰¹å¾åˆ°æ–‡ä»¶ï¼ˆç”¨äºåç»­è·¨ä»»åŠ¡åˆ†æï¼‰
    feature_save_path = save_dir / f'{file_prefix}_{split}_features.npz'
    np.savez(feature_save_path, features=features, labels=labels)
    logger.info(f"âœ“ ç‰¹å¾å·²ä¿å­˜: {feature_save_path}")
    
    logger.info(f"âœ“ å¯è§†åŒ–å®Œæˆ!\n")
    
    return features, labels


def visualize_all_tasks_evolution(
    save_dir: str,
    split: str = 'dev',
    method: str = 'tsne'
):
    """
    åŠ è½½æ‰€æœ‰å·²ä¿å­˜çš„ä»»åŠ¡ç‰¹å¾ï¼Œç»˜åˆ¶æ¼”è¿›å›¾
    
    Args:
        save_dir: ç‰¹å¾ä¿å­˜ç›®å½•
        split: æ•°æ®é›†åˆ’åˆ†
        method: é™ç»´æ–¹æ³•
    """
    save_dir = Path(save_dir)
    
    # æŸ¥æ‰¾æ‰€æœ‰ç‰¹å¾æ–‡ä»¶
    feature_files = list(save_dir.glob(f'*_{split}_features.npz'))
    
    if len(feature_files) == 0:
        logger.warning(f"âš ï¸  æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶: {save_dir}/*_{split}_features.npz")
        return
    
    logger.info(f"ğŸ“Š æ‰¾åˆ° {len(feature_files)} ä¸ªä»»åŠ¡çš„ç‰¹å¾æ–‡ä»¶")
    
    # åŠ è½½æ‰€æœ‰ç‰¹å¾
    task_features = {}
    for feature_file in sorted(feature_files):
        # ä»æ–‡ä»¶åæå–ä»»åŠ¡å
        task_name = feature_file.stem.replace(f'_{split}_features', '')
        
        # åŠ è½½ç‰¹å¾
        data = np.load(feature_file)
        features = data['features']
        labels = data['labels']
        
        task_features[task_name] = (features, labels)
        logger.info(f"  âœ“ åŠ è½½: {task_name} - {features.shape[0]} samples")
    
    # ç»˜åˆ¶æ¼”è¿›å›¾
    plot_continual_learning_evolution(task_features, str(save_dir), method=method)


if __name__ == '__main__':
    """
    ç¤ºä¾‹ç”¨æ³•
    """
    print("ç‰¹å¾èšç±»å¯è§†åŒ–æ¨¡å—")
    print("è¯·åœ¨è®­ç»ƒè„šæœ¬ä¸­è°ƒç”¨ç›¸å…³å‡½æ•°")

