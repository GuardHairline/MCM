#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆç‰¹å¾èšç±»å¯è§†åŒ–æ¨¡å—

æ–°åŠŸèƒ½ï¼š
1. ä½¿ç”¨å®é™…æ ‡ç­¾åï¼ˆNEG/NEU/POSç­‰ï¼‰è€Œä¸æ˜¯Class 0/1/2
2. åŒæ—¶æ˜¾ç¤ºçœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
3. æ ‡è®°é¢„æµ‹é”™è¯¯çš„æ ·æœ¬
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple, Optional
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

# è®¾ç½®é»˜è®¤å­—ä½“ï¼ˆæ— éœ€ä¸­æ–‡æ”¯æŒï¼‰
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False


def get_label_names(task_name: str) -> Dict[int, str]:
    """
    è·å–ä»»åŠ¡çš„å®é™…æ ‡ç­¾åç§°
    
    Args:
        task_name: ä»»åŠ¡åç§°
        
    Returns:
        label_names: {label_id: label_name}
    """
    from continual.label_config import get_label_manager
    
    manager = get_label_manager()
    config = manager.get_task_config(task_name)
    
    if config is None:
        logger.warning(f"Task {task_name} not found in label manager")
        return {}
    
    # è¿”å›æ ‡ç­¾IDåˆ°æ ‡ç­¾åçš„æ˜ å°„
    label_names = {}
    for idx, name in enumerate(config.label_names):
        label_names[idx] = name
    
    return label_names


def extract_features_labels_and_predictions(
    model,
    task_name: str,
    split: str,
    device: torch.device,
    args,
    max_samples: int = 2000,
    extract_predictions: bool = True
) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:
    """
    æå–ç‰¹å¾ã€çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        task_name: ä»»åŠ¡åç§°
        split: æ•°æ®é›†åˆ’åˆ†
        device: è®¾å¤‡
        args: å‚æ•°
        max_samples: æœ€å¤§æ ·æœ¬æ•°
        extract_predictions: æ˜¯å¦æå–é¢„æµ‹æ ‡ç­¾
        
    Returns:
        features: (N, hidden_dim) èåˆåçš„ç‰¹å¾
        true_labels: (N,) çœŸå®æ ‡ç­¾ï¼ˆground truthï¼‰
        pred_labels: (N,) é¢„æµ‹æ ‡ç­¾ï¼ˆå¦‚æœextract_predictions=Trueï¼‰
    """
    from datasets.get_dataset import get_dataset
    from modules.train_utils import is_sequence_task
    
    logger.info(f"ğŸ“Š æå–ç‰¹å¾å’Œæ ‡ç­¾: task={task_name}, split={split}")
    
    model.eval()
    
    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ä»»åŠ¡å¤´
    if hasattr(model, 'set_active_head') and hasattr(args, 'session_name'):
        try:
            model.set_active_head(args.session_name, strict=False)
        except Exception as e:
            logger.warning(f"Failed to set active head: {e}")
    
    # ç¡®ä¿base_modelçš„modeæ­£ç¡®è®¾ç½®
    if hasattr(model, 'base_model') and hasattr(model.base_model, 'mode'):
        current_mode = getattr(args, 'mode', 'multimodal')
        model.base_model.mode = current_mode
    
    dataset = get_dataset(task_name, split, args)
    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)
    
    is_seq_task = is_sequence_task(task_name)
    
    all_features = []
    all_true_labels = []
    all_pred_labels = [] if extract_predictions else None
    sample_count = 0
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(loader):
            if sample_count >= max_samples:
                break
            
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            token_type_ids = batch.get("token_type_ids", None)
            if token_type_ids is not None:
                token_type_ids = token_type_ids.to(device)
            image_tensor = batch["image_tensor"].to(device)
            true_labels = batch["labels"]
            
            # 1. æå–èåˆç‰¹å¾
            if is_seq_task:
                fused_feat = model.base_model(
                    input_ids, attention_mask, token_type_ids, image_tensor,
                    return_sequence=True
                )
                
                # 2. è·å–é¢„æµ‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if extract_predictions:
                    logits = model.head(fused_feat)  # (batch, seq_len, num_classes)
                    predictions = torch.argmax(logits, dim=-1)  # (batch, seq_len)
                    predictions = predictions.view(-1)
                
                # å±•å¹³
                batch_size, seq_len, hidden_dim = fused_feat.shape
                fused_feat = fused_feat.view(-1, hidden_dim)
                true_labels = true_labels.view(-1)
                
                # è¿‡æ»¤padding
                valid_mask = true_labels != -100
                fused_feat = fused_feat[valid_mask]
                true_labels = true_labels[valid_mask]
                if extract_predictions:
                    predictions = predictions[valid_mask]
            else:
                fused_feat = model.base_model(
                    input_ids, attention_mask, token_type_ids, image_tensor,
                    return_sequence=False
                )
                
                # 2. è·å–é¢„æµ‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if extract_predictions:
                    logits = model.head(fused_feat)  # (batch, num_classes)
                    predictions = torch.argmax(logits, dim=-1)
            
            # ä¿å­˜
            all_features.append(fused_feat.cpu().numpy())
            all_true_labels.append(true_labels.cpu().numpy())
            if extract_predictions:
                all_pred_labels.append(predictions.cpu().numpy())
            
            sample_count += fused_feat.shape[0]
            
            if (batch_idx + 1) % 10 == 0:
                logger.info(f"  å·²å¤„ç† {batch_idx + 1}/{len(loader)} batches, {sample_count} samples")
    
    # åˆå¹¶
    features = np.concatenate(all_features, axis=0)[:max_samples]
    true_labels = np.concatenate(all_true_labels, axis=0)[:max_samples]
    pred_labels = np.concatenate(all_pred_labels, axis=0)[:max_samples] if extract_predictions else None
    
    if extract_predictions:
        accuracy = np.mean(true_labels == pred_labels) * 100
        logger.info(f"âœ“ ç‰¹å¾æå–å®Œæˆ: shape={features.shape}, accuracy={accuracy:.2f}%")
    else:
        logger.info(f"âœ“ ç‰¹å¾æå–å®Œæˆ: shape={features.shape}")
    
    return features, true_labels, pred_labels


def plot_tsne_with_label_names(
    features: np.ndarray,
    labels: np.ndarray,
    task_name: str,
    save_path: str,
    label_names: Optional[Dict[int, str]] = None,
    title: str = None,
    perplexity: int = 30,
    n_iter: int = 1000
):
    """
    ä½¿ç”¨å®é™…æ ‡ç­¾åç»˜åˆ¶t-SNEå›¾
    
    Args:
        features: (N, hidden_dim)
        labels: (N,) æ ‡ç­¾ID
        task_name: ä»»åŠ¡åç§°
        save_path: ä¿å­˜è·¯å¾„
        label_names: {label_id: label_name} æ ‡ç­¾åæ˜ å°„
        title: å›¾è¡¨æ ‡é¢˜
        perplexity: t-SNEå‚æ•°
        n_iter: è¿­ä»£æ¬¡æ•°
    """
    logger.info(f"ğŸ¨ å¼€å§‹t-SNEé™ç»´å¹¶ç»˜å›¾: perplexity={perplexity}, n_iter={n_iter}")
    
    # å¦‚æœæ²¡æœ‰æä¾›label_namesï¼Œè‡ªåŠ¨è·å–
    if label_names is None:
        label_names = get_label_names(task_name)
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)
    features_2d = tsne.fit_transform(features)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(1, 1, figsize=(12, 9))
    
    # è·å–å”¯ä¸€æ ‡ç­¾
    unique_labels = np.unique(labels)
    n_classes = len(unique_labels)
    
    # ç”Ÿæˆé¢œè‰²æ˜ å°„
    colors = plt.cm.get_cmap('tab10' if n_classes <= 10 else 'tab20')(range(n_classes))
    
    # ä¸ºæ¯ä¸ªç±»åˆ«ç»˜åˆ¶æ•£ç‚¹
    for idx, label in enumerate(unique_labels):
        mask = labels == label
        
        # è·å–æ ‡ç­¾å
        if label_names and label in label_names:
            label_text = label_names[label]
        else:
            label_text = f'Class {label}'
        
        ax.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[colors[idx]],
            label=label_text,  # ä½¿ç”¨å®é™…æ ‡ç­¾å
            alpha=0.6,
            s=30,
            edgecolors='k',
            linewidths=0.3
        )
    
    # è®¾ç½®æ ‡é¢˜å’Œå›¾ä¾‹
    if title is None:
        title = f't-SNE: {task_name.upper()} (Ground Truth Labels)'
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('t-SNE Dimension 1', fontsize=12)
    ax.set_ylabel('t-SNE Dimension 2', fontsize=12)
    ax.legend(loc='best', fontsize=10, ncol=2 if n_classes > 5 else 1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"âœ“ t-SNEå›¾å·²ä¿å­˜: {save_path}")


def plot_tsne_comparison(
    features: np.ndarray,
    true_labels: np.ndarray,
    pred_labels: np.ndarray,
    task_name: str,
    save_path: str,
    label_names: Optional[Dict[int, str]] = None,
    perplexity: int = 30,
    n_iter: int = 1000
):
    """
    ç»˜åˆ¶å¯¹æ¯”å›¾ï¼šçœŸå®æ ‡ç­¾ vs é¢„æµ‹æ ‡ç­¾
    
    Args:
        features: (N, hidden_dim)
        true_labels: (N,) çœŸå®æ ‡ç­¾
        pred_labels: (N,) é¢„æµ‹æ ‡ç­¾
        task_name: ä»»åŠ¡åç§°
        save_path: ä¿å­˜è·¯å¾„
        label_names: æ ‡ç­¾åæ˜ å°„
        perplexity: t-SNEå‚æ•°
        n_iter: è¿­ä»£æ¬¡æ•°
    """
    logger.info(f"ğŸ¨ ç»˜åˆ¶çœŸå®æ ‡ç­¾ vs é¢„æµ‹æ ‡ç­¾å¯¹æ¯”å›¾")
    
    # å¦‚æœæ²¡æœ‰æä¾›label_namesï¼Œè‡ªåŠ¨è·å–
    if label_names is None:
        label_names = get_label_names(task_name)
    
    # t-SNEé™ç»´ï¼ˆåªåšä¸€æ¬¡ï¼‰
    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)
    features_2d = tsne.fit_transform(features)
    
    # åˆ›å»ºä¸¤ä¸ªå­å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 9))
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(true_labels == pred_labels) * 100
    correct_mask = true_labels == pred_labels
    
    # è·å–å”¯ä¸€æ ‡ç­¾
    unique_labels = np.unique(true_labels)
    n_classes = len(unique_labels)
    colors = plt.cm.get_cmap('tab10' if n_classes <= 10 else 'tab20')(range(n_classes))
    
    # === å­å›¾1: çœŸå®æ ‡ç­¾ ===
    for idx, label in enumerate(unique_labels):
        mask = true_labels == label
        label_text = label_names.get(label, f'Class {label}') if label_names else f'Class {label}'
        
        ax1.scatter(
            features_2d[mask, 0],
            features_2d[mask, 1],
            c=[colors[idx]],
            label=label_text,
            alpha=0.6,
            s=30,
            edgecolors='k',
            linewidths=0.3
        )
    
    ax1.set_title(f'Ground Truth Labels\n(Expected Distribution)', fontsize=13, fontweight='bold')
    ax1.set_xlabel('t-SNE Dimension 1', fontsize=11)
    ax1.set_ylabel('t-SNE Dimension 2', fontsize=11)
    ax1.legend(loc='best', fontsize=9, ncol=2 if n_classes > 5 else 1)
    ax1.grid(True, alpha=0.3)
    
    # === å­å›¾2: é¢„æµ‹æ ‡ç­¾ï¼ˆæ ‡è®°é”™è¯¯ï¼‰===
    # å…ˆç»˜åˆ¶æ­£ç¡®é¢„æµ‹çš„ç‚¹
    for idx, label in enumerate(unique_labels):
        mask = (pred_labels == label) & correct_mask
        label_text = label_names.get(label, f'Class {label}') if label_names else f'Class {label}'
        
        if np.any(mask):
            ax2.scatter(
                features_2d[mask, 0],
                features_2d[mask, 1],
                c=[colors[idx]],
                label=label_text,
                alpha=0.6,
                s=30,
                edgecolors='k',
                linewidths=0.3
            )
    
    # å†ç»˜åˆ¶é”™è¯¯é¢„æµ‹çš„ç‚¹ï¼ˆç”¨Xæ ‡è®°ï¼‰
    if np.any(~correct_mask):
        ax2.scatter(
            features_2d[~correct_mask, 0],
            features_2d[~correct_mask, 1],
            c='red',
            label=f'Errors ({np.sum(~correct_mask)})',
            alpha=0.8,
            s=60,
            marker='x',
            linewidths=2
        )
    
    ax2.set_title(f'Predicted Labels (Accuracy: {accuracy:.2f}%)\n(Model Predictions)', 
                  fontsize=13, fontweight='bold')
    ax2.set_xlabel('t-SNE Dimension 1', fontsize=11)
    ax2.set_ylabel('t-SNE Dimension 2', fontsize=11)
    ax2.legend(loc='best', fontsize=9, ncol=2 if n_classes > 5 else 1)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"âœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    logger.info(f"  å‡†ç¡®ç‡: {accuracy:.2f}%, é”™è¯¯æ ·æœ¬æ•°: {np.sum(~correct_mask)}")


def visualize_task_enhanced(
    model,
    task_name: str,
    session_name: str,
    device: torch.device,
    args,
    save_dir: str,
    split: str = 'dev',
    max_samples: int = 2000,
    show_predictions: bool = True,
    config_name: Optional[str] = None  # æ–°å¢ï¼šé…ç½®æ–‡ä»¶åç§°å‰ç¼€
):
    """
    å¢å¼ºç‰ˆå¯è§†åŒ–ï¼šä½¿ç”¨å®é™…æ ‡ç­¾åï¼Œå¹¶å¯¹æ¯”çœŸå®vsé¢„æµ‹
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        task_name: ä»»åŠ¡åç§°
        session_name: ä¼šè¯åç§°
        device: è®¾å¤‡
        args: å‚æ•°
        save_dir: ä¿å­˜ç›®å½•
        split: æ•°æ®é›†åˆ’åˆ†
        max_samples: æœ€å¤§æ ·æœ¬æ•°
        show_predictions: æ˜¯å¦ç”Ÿæˆé¢„æµ‹å¯¹æ¯”å›¾
        config_name: é…ç½®æ–‡ä»¶åç§°ï¼ˆç”¨äºåŒºåˆ†ä¸åŒé…ç½®çš„å¯è§†åŒ–ç»“æœï¼‰
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # æ„å»ºæ–‡ä»¶åå‰ç¼€ï¼ˆé¿å…ä¸åŒé…ç½®äº’ç›¸è¦†ç›–ï¼‰
    if config_name:
        file_prefix = f"{config_name}_{session_name}"
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š å¢å¼ºç‰ˆç‰¹å¾èšç±»å¯è§†åŒ–")
        logger.info(f"  é…ç½®: {config_name}")
        logger.info(f"  ä»»åŠ¡: {task_name}")
        logger.info(f"  ä¼šè¯: {session_name}")
        logger.info(f"  æ•°æ®é›†: {split}")
        logger.info(f"  æ–‡ä»¶å‰ç¼€: {file_prefix}")
        logger.info(f"{'='*60}\n")
    else:
        file_prefix = session_name
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š å¢å¼ºç‰ˆç‰¹å¾èšç±»å¯è§†åŒ–")
        logger.info(f"  ä»»åŠ¡: {task_name}")
        logger.info(f"  ä¼šè¯: {session_name}")
        logger.info(f"  æ•°æ®é›†: {split}")
        logger.info(f"{'='*60}\n")
    
    # 1. æå–ç‰¹å¾ã€çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾
    features, true_labels, pred_labels = extract_features_labels_and_predictions(
        model, task_name, split, device, args, max_samples, 
        extract_predictions=show_predictions
    )
    
    # 2. è·å–æ ‡ç­¾å
    label_names = get_label_names(task_name)
    logger.info(f"âœ“ æ ‡ç­¾åæ˜ å°„: {label_names}")
    
    # 3. ç»˜åˆ¶çœŸå®æ ‡ç­¾å›¾ï¼ˆä½¿ç”¨å®é™…æ ‡ç­¾åï¼‰
    tsne_path = save_dir / f'{file_prefix}_{split}_tsne_true.png'
    plot_tsne_with_label_names(
        features, true_labels, task_name, str(tsne_path),
        label_names=label_names,
        title=f't-SNE: {task_name.upper()} - Ground Truth ({split})'
    )
    
    # 4. ç»˜åˆ¶å¯¹æ¯”å›¾ï¼ˆçœŸå® vs é¢„æµ‹ï¼‰
    if show_predictions and pred_labels is not None:
        comparison_path = save_dir / f'{file_prefix}_{split}_tsne_comparison.png'
        plot_tsne_comparison(
            features, true_labels, pred_labels, task_name, str(comparison_path),
            label_names=label_names
        )
    
    # 5. ä¿å­˜ç‰¹å¾
    feature_save_path = save_dir / f'{file_prefix}_{split}_features_enhanced.npz'
    np.savez(feature_save_path, 
             features=features, 
             true_labels=true_labels, 
             pred_labels=pred_labels if pred_labels is not None else np.array([]),
             label_names=np.array(list(label_names.items()), dtype=object))
    logger.info(f"âœ“ ç‰¹å¾å·²ä¿å­˜: {feature_save_path}")
    
    logger.info(f"âœ“ å¢å¼ºç‰ˆå¯è§†åŒ–å®Œæˆ!\n")
    
    return features, true_labels, pred_labels


if __name__ == '__main__':
    print("å¢å¼ºç‰ˆç‰¹å¾èšç±»å¯è§†åŒ–æ¨¡å—")
    print("æ–°åŠŸèƒ½ï¼š")
    print("  1. ä½¿ç”¨å®é™…æ ‡ç­¾åï¼ˆNEG/NEU/POSç­‰ï¼‰")
    print("  2. å¯¹æ¯”çœŸå®æ ‡ç­¾ vs é¢„æµ‹æ ‡ç­¾")
    print("  3. æ ‡è®°é¢„æµ‹é”™è¯¯çš„æ ·æœ¬")

